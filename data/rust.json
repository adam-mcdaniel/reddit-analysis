{"name":"rust","description":"A place for all things related to the Rust programming language—an open-source systems language that emphasizes performance, reliability, and productivity.","subscribers":207805,"posts":[{"title":"Hey Rustaceans! Got a question? Ask here! (46/2022)!","not_safe_for_work":false,"locked":false,"body":"Mystified about strings? Borrow checker have you in a headlock? Seek help here! There are no stupid questions, only docs that haven't been written yet.\n\nIf you have a [StackOverflow](http://stackoverflow.com/) account, consider asking it there instead! StackOverflow shows up much higher in search results, so having your question there also helps future Rust users (be sure to give it [the \"Rust\" tag](http://stackoverflow.com/questions/tagged/rust) for maximum visibility). Note that this site is very interested in question quality. I've been asked to read a RFC I authored once. If you want your code reviewed or review other's code, there's a [codereview stackexchange](https://codereview.stackexchange.com/questions/tagged/rust), too. If you need to test your code, maybe [the Rust playground](https://play.rust-lang.org) is for you.\n\nHere are some other venues where help may be found:\n\n[/r/learnrust](https://www.reddit.com/r/learnrust) is a subreddit to share your questions and epiphanies learning Rust programming.\n\nThe official Rust user forums: [https://users.rust-lang.org/](https://users.rust-lang.org/).\n\nThe official Rust Programming Language Discord: [https://discord.gg/rust-lang](https://discord.gg/rust-lang)\n\nThe unofficial Rust community Discord: [https://bit.ly/rust-community](https://bit.ly/rust-community)\n\nAlso check out [last weeks' thread](https://reddit.com/r/rust/comments/yofx14/hey_rustaceans_got_an_easy_question_ask_here/) with many good questions and answers. And if you believe your question to be either very complex or worthy of larger dissemination, feel free to create a text post.\n\nAlso if you want to be mentored by experienced Rustaceans, tell us the area of expertise that you seek. Finally, if you are looking for Rust jobs, the most recent thread is [here](https://www.reddit.com/r/rust/comments/ymepy8/official_rrust_whos_hiring_thread_for_jobseekers).","score":23,"comments":[{"body":"what do fn generic params mean in terms of monomorphization?\nlike if i have function:\n```rust\nfn unfold&lt;T, F, Fut&gt;(init: T, f: F)\nwhere\n    F: FnMut(T) -&gt; Fut,\n    Fut: Future&lt;Output = T&gt;,\n{}\n```\ndoes that function monomorhpize for every unique triple (T, F, Fut)?\nbut F is closure that has some unique type so it seems sufficient to monomorphize only for every F?","score":2,"comments":[]},{"body":"I have another run in with the borrow checker :D  \nI am trying to tokenize a string and maybe save some data  the tokens should contain. A Token is a struct with a field `pub data: Option&lt;&amp;'static dyn Display&gt;`. The issue is, that I cannot seem to be able to get a substring containing the required data from the string whose lifetime is long enough to satisfy `'static` and I do not know enough about lifetimes to be able to \"introduce a named lifetime parameter\" as the compiler says. Shouldn't I just be able to somehow clone the string and have an immutable string on the heap that lives as long as I want it to?\nThe code is [here](https://git.cdaut.de/CDaut/rust-lcc/-/blob/master/src/lexer/lexer.rs) in line 33. Thanks!","score":2,"comments":[{"body":"Oh it looks like you pushed a commit changing it to a `String` to fix things which certainly works. I definitely think that some string based type makes a lot more sense than a `dyn Display` for a `Token`. Other options would be\n\nUsing a `&amp;str`. This would involve changing your token to something like\n\n    struct Token&lt;'input&gt; {\n        pub token_type: TokenType,\n        pub data: Option&lt;&amp;'input str&gt;\n    }\n\nwhich would also involve changing the signature of `lex` to tie the lifetime of the input to the tokens, like so\n\n    pub fn lex&lt;'input&gt;(code: &amp;'input str) -&gt; Result&lt;Vec&lt;Token&lt;'input&gt;&gt;, &amp;'static str&gt; {\n\n(Disclaimer: I haven't taken the time to test this, so there may still be other issues)\n\nUsing a reference to the input doesn't allow for modifying `data`. If this was needed then you can do something very similar to the above, but using a [`Cow&lt;'input, str&gt;`](https://doc.rust-lang.org/std/borrow/enum.Cow.html) which holds either a reference to the original data (`Cow::Borrow`), or some owned string that could differ from the original input (`Cow::Owned`). This works best when the value is often the `Cow::Borrowed` variant\n\n&gt; Shouldn't I just be able to somehow clone the string and have an immutable string on the heap that lives as long as I want it to\n\nSure! This is something very similar to the `String` that you currently have. What you're describing is a `Box&lt;str&gt;` which `String` has a convenient method for converting into (aka [`String::into_boxed_str()`](https://doc.rust-lang.org/std/string/struct.String.html#method.into_boxed_str)). There isn't much benefit here, but, as [dtolnay mentions](https://users.rust-lang.org/t/use-case-for-box-str-and-string/8295/4), this is smaller than a `String` which matters if you're using **a lot** of strings","score":1,"comments":[]}]},{"body":"I have a run in with the borrow checker...   \nI am trying to modify a string using `Regex::replace`. Now this returns a `Cow&lt;&amp;str&gt;` that I turn into a `&amp;str` using `as_ref()`. However when I do this I get a \"temporary value dropped while still in use\"\nThe project is [here](https://git.cdaut.de/CDaut/rust-lcc/-/blob/master/src/lexer/lexer.rs). Issue in line 32. Thanks!","score":2,"comments":[{"body":"The issue is that your `code_mut` variable has a lifetime attached to the parameter of the function, but the borrowed string from your `Cow&lt;str&gt;` has a shorter lifetime than that.\n\nLooking at your code, it kind of seems like you shouldn't be using replace at all. Just use `find` instead of `is_match` and slice the string to start at the end of the match.\n\nAlso... If your regexes are known at compile time (and it looks like they are), build them once. See the regex README.","score":2,"comments":[]}]},{"body":"Is there a way to declare a variable as `impl X`? And if not: why isn't it possible (without Box)? What is the difference when I call a function that returns an `impl X` and declare the result in a variable, which is possible?\n\n    let x: impl MyTrait = ... // illegal\n    let x = function_that_returns_impl_MyTrait() // legal\n\n\n\n\n  \nOther question: for rust-analyzer in VSCode is there a way to 1) set cargo nextest as default test runner and 2) can I disable type hints after every line? Working with chumsky my eyes start hurting because the types are sooo long...","score":2,"comments":[{"body":"If the length of the types is the problem, you can have your own `type X = ...` to shorten the types. Otherwise you can use [on stack dynamic dispatch](https://rust-unofficial.github.io/patterns/idioms/on-stack-dyn-dispatch.html), but that requires a reference. Or you just omit the types (unless your functions are generic over their return type).\n\nAlso you can edit the settings.json in VSCode and add `\"editor.inlayHints.enabled\": \"offUnlessPressed\",` which will cease to display the hints unless you press alt-ctrl.","score":2,"comments":[{"body":"Thanks! Length is not the problem, compiler inference is. This unfortunately doesn’t answer my question **why** its not possible one way but the other. My problem is when calling functions that are generic where every function can have differing types but always return the same type. It’s tiresome to always write ::&lt;Input1, Input2&gt;()","score":2,"comments":[]}]}]},{"body":"Might be a dumb question, but I have binary that is supposed to be written in Rust.\n\nThere is no file extension. What is the file extension for rust binaries?","score":3,"comments":[{"body":"Binarys don't necessarily have an extension per se. On Windows a binary might be indicated by having a .exe extension on Unix it's quite common for binarys to have no extension.","score":2,"comments":[]},{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"Official /r/rust \"Who's Hiring\" thread for job-seekers and job-offerers [Rust 1.65]","not_safe_for_work":false,"locked":false,"body":"Welcome once again to the official r/rust Who's Hiring thread!\n\nBefore we begin, job-seekers should also remember to peruse the [prior thread](https://www.reddit.com/r/rust/comments/xldzbl/official_rrust_whos_hiring_thread_for_jobseekers/).\n\nThis thread will be periodically stickied to the top of r/rust for improved visibility.  \nYou can also find it again via the \"Latest Megathreads\" list, which is a dropdown at the top of the page on new Reddit, and a section in the sidebar under \"Useful Links\" on old Reddit.\n\nThe thread will be refreshed and posted anew when the next version of Rust releases in six weeks.\n\nPlease adhere to the following rules when posting:\n\n### Rules for individuals:\n\n- Don't create top-level comments; those are for employers.\n\n- Feel free to reply to top-level comments with on-topic questions.\n\n- Anyone seeking work should reply to my stickied top-level comment.\n\n- Meta-discussion should be reserved for the distinguished comment at the very bottom.\n\n### Rules for employers:\n\n- **The ordering of fields in the template has been revised to make postings easier to read. If you are reusing a previous posting, please update the ordering as shown below.**\n\n- **Remote positions: see bolded text for new requirement.**\n\n- To find individuals seeking work, see the replies to the stickied top-level comment; you will need to click the \"more comments\" link at the bottom of the top-level comment in order to make these replies visible.\n\n- To make a top-level comment you must be hiring directly; no third-party recruiters.\n\n- One top-level comment per employer. If you have multiple job openings, please consolidate their descriptions or mention them in replies to your own top-level comment.\n\n- Proofread your comment after posting it and edit it if necessary to correct mistakes.\n\n- To share the space fairly with other postings and keep the thread pleasant to browse, we ask that you try to limit your posting to either 50 lines or 500 words, whichever comes first.  \n  **We reserve the right to remove egregiously long postings.** However, this only applies to the content of this thread; you can link to a job page elsewhere with more detail if you like.\n\n- Please base your comment on the following template:\n\nCOMPANY: _[Company name; optionally link to your company's website or careers page.]_\n\nTYPE: _[Full time, part time, internship, contract, etc.]_\n\nLOCATION: _[Where are your office or offices located? If your workplace language isn't English-speaking, please specify it.]_\n\nREMOTE: _[Do you offer the option of working remotely? **Please state clearly if remote work is restricted to certain regions or time zones, or if availability within a certain time of day is expected or required.**]_\n\nVISA: _[Does your company sponsor visas?]_\n\nDESCRIPTION: _[What does your company do, and what are you using Rust for? How much experience are you seeking and what seniority levels are you hiring for? The more details the better.]_\n\nESTIMATED COMPENSATION: _[Be courteous to your potential future colleagues by attempting to provide at least a rough expectation of wages/salary.  \nIf you are listing several positions in the \"Description\" field above, then feel free to include this information inline above, and put \"See above\" in this field.  \nIf compensation is negotiable, please attempt to provide at least a base estimate from which to begin negotiations. If compensation is highly variable, then feel free to provide a range.  \nIf compensation is expected to be offset by other benefits, then please include that information here as well. \nIf you don't have firm numbers but do have relative expectations of candidate expertise (e.g. entry-level, senior), then you may include that here.  \nIf you truly have no information, then put \"Uncertain\" here.  \nYou **must** state clearly in your posting if you are planning to compensate employees partially or fully in **something other than fiat currency** (e.g. cryptocurrency, stock options, equity, etc).  \nDo **not** put just \"Uncertain\" in this case as the default assumption is that the compensation will be 100% fiat.  \nPostings that fail to comply with this addendum **will be removed**.\nThank you.]_\n\nCONTACT: _[How can someone get in touch with you?]_","score":206,"comments":[{"body":"This is the top-level comment for individuals looking for work. Reply here if you would like employers to contact you. You don't need to follow a strict template, but consider the relevant sections of the employer template. For example, mention whether you're looking for full-time work or freelancing or etc., briefly describe your experience (not a full resume; send that after you've been contacted), mention whether you care about location/remote/visa, and list the technologies you're skilled with.","score":1,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"COMPANY: ColuxChain  \nTYPE: Full Time  \nLOCATION: Remote (US, Canada, Netherlands, Spain, Austria, Ireland, Chile, France, Sweden, Croatia, Portugal, Denmark, Norway,  \nREMOTE: Yes!  \nVISA: No  \nDESCRIPTION: Offering blockchain solutions to businesses.  \nESTIMATED COMPENSATION: $150-240k base, equity+tokens offered.","score":1,"comments":[{"body":"any email ?","score":1,"comments":[]},{"body":"&gt;ColuxChain\n\nHello I am interested","score":1,"comments":[]}]},{"body":"COMPANY: NXLog, Ltd ([nxlog.co](https://nxlog.co))\n\nTYPE: Full time\n\nDESCRIPTION: [Job description](https://application.nxlog.org/jobs/detail/rust-developer-39).\n\nLog collection and centralization tool. We are currently looking for a seasoned systems programmer with good Rust programming skills (middle-level or higher), preferably with C/C++ background.\n\nLOCATION: Fully remote.\n\nESTIMATED COMPENSATION: €50-70k\n\nREMOTE: Fully remote, Europe time zones are preferred.\n\nVISA: No\n\nCONTACT: [Job application page](https://application.nxlog.org/jobs/detail/rust-developer-39) or DM with technical questions.","score":3,"comments":[{"body":"Reddit shows that your username doesn't exist. So I'll just ask here, are also you looking for interns / working students?","score":1,"comments":[]}]},{"body":"**COMPANY**: [Hilti](https://www.hilti.com)\n\n**TYPE**: Internship or working student\n\n**LOCATION**: Kaufering, Germany\n\n**REMOTE**: No, but it's possible to work from home several days a week\n\n**VISA**: No\n\n**DESCRIPTION**: The Hilti Group supplies the construction and energy industries worldwide with technologically leading products, system solutions, software and services. In short, we develop a huge variety of products from electric screwdrivers to demolition hammers and measuring systems. For example, this is one of our products: [video](https://www.youtube.com/watch?v=hu8E140zZGE).\n\nIn the team for electric motors and motor control, you can work together with our experts on refining our algorithms for drive selection. We're working on a collection of internal software tools that can calculate the performance and power consumption of the drive train even before the development starts. You could say, the software gives us a head start into the development process.\n\nWe recently moved our entire code base from Matlab to Rust and are extremely happy with the performance and stability we gained during this process.\n\nYour tasks include\n\n* Implementation of graphical user interfaces (e.g. with egui)\n* Integrating a database for managing simulation data\n* Refining existing simulation models\n\n**ESTIMATED COMPENSATION**: Roughly 13€ to 15€ per hour\n\n**CONTACT**: If you have questions, you can contact me on Reddit. [Apply here](https://careers.hilti.group/de-de/stellenangebote/35391-de/werkstudent-praktikum-im-bereich-systemsimulation-elektrischer-antriebe-m-w-d/) (the official job description is written in German, but speaking German is not a requirement).","score":4,"comments":[]},{"body":"**COMPANY:** Skippr ([skippr.com](https://skippr.com) for more info)\n\n**TYPE:** Full time\n\n**LOCATION:** London, UK\n\n**REMOTE:** Up to 3 days a week from home.\n\n**VISA:** No\n\n**DESCRIPTION:** We are looking to advance the productivity and creativity of product designers by creating a new category - Augmented Design. For this we are building the next generation of tools for creative teams, infused with the latest advancements in DesignOps, UX/UI, AI and Machine Learning. While the company is still in stealth mode, we are seed-funded by tier-one VCs and angel investors. We're looking for seasoned, hacker-hearted Rust developers with an affinity for design to join our founding team. As we are in the early stages, this is the opportunity to take a chance and create a large impact. More details can be found [here](https://skippr.notion.site/Principal-Software-Engineer-b4e7d4c36e1c446a98301144f81aa942).\n\n**ESTIMATED COMPENSATION:** £80K-£110K, 0.1-1% equity\n\n**CONTACT:** Please apply for \"Principal Software Engineer\" [here](https://airtable.com/shrrO25phpN1i1DC2) or DM me","score":-2,"comments":[]},{"body":"**Company:** [Vivint](https://www.vivint.com/)\n\n**Job Posting:** [https://vivint.wd5.myworkdayjobs.com/vivintjobs/job/Lehi-UT/Principal-Software-Engineer\\_R119891](https://vivint.wd5.myworkdayjobs.com/vivintjobs/job/Lehi-UT/Principal-Software-Engineer_R119891)\n\n**Type:** Full time\n\n**Location:** Lehi, Utah or Remote - We are open to remote in USA except from California.\n\n**Description:** We are searching for an individual who will join us to work on our embedded security cameras which features a 24/7 DVR experience we call Playback. We’re looking for people who have a demonstrated ability to learn and grow and get stuff done. Work is focused on embedded Linux systems and will include working with our hardware vendors to determine which hardware chipsets we want to include in our next generation cameras. We primarily use Rust and C++.\n\n**Visa:** No\n\n**Estimate Compensation:** Negotiable, $160K+ DOE, + bonus and benefits\n\n**Contact:** Email: [matt.stone@vivint.com](mailto:matt.stone@vivint.com)","score":3,"comments":[]},{"body":"","score":0,"comments":[]}]},{"title":"Rust audio library","not_safe_for_work":false,"locked":false,"body":"Hey all; I'm rebuilding one of my projects, an audiobook player, in rust and need a way to play most/all common audio formats. My previous solution was to rely on a web browsers for that functionality, although that is still possible using tauri, I would like to find a solution that provided me the functionality in rust. \n\nIs there any ready to go libraries?\n\nBonus points for a library that provides metadata parsing too","score":84,"comments":[{"body":"If you want pure rust, you will jeed to use multiple different crates. Symphonia is a good starting point for many encodings though!","score":38,"comments":[{"body":"this is what I was afraid of; posted the post to see if i had missed anything, guess not","score":6,"comments":[{"body":"Yeah, I mean playing back \"most/all\" common audio formats is *a lot* to ask. ffmpeg is literally the only single library in the world I can think of that does this.\n\nEdit: But there are quite a few pure rust libraries that are doing a great job decoding different audio formats. As I said, look into symphonia first and if you are missing a specific format (or metadata), pull in another crate for that.\nlofty is a very solid library for tags! id3 is also great, but obviously only for id3-tags.","score":29,"comments":[{"body":"The image crate kinda does that for images. It wraps a bunch of pure Rust creates for various formats and presents them via a single unified API.\n\nThat'd work well for other kinds of media as well.","score":7,"comments":[{"body":"","score":0,"comments":[]}]}]},{"body":"Not sure if this is helpful, but I built a music player with symphonia so maybe taking some of the code as reference will be helpful. https://github.com/kamiyaa/dizi","score":9,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"You're probably looking for either ffmpeg (ffmpeg-next crate) or gstreamer (gstreamer crate). gstreamer also comes with sinks that will play your music through the speakers. It's a big topic though.","score":17,"comments":[]},{"body":"I've had good experience with https://crates.io/crates/kira","score":10,"comments":[]},{"body":"ffmpeg","score":9,"comments":[{"body":"any good wrapper recommendations? there seems to be a lot of them","score":6,"comments":[]}]},{"body":"`rodio` is the easiest library for audio playback, imo. Although i don't personally like it, i would recommend it for really basic stuff.","score":7,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"What is your favorite standard library function?","not_safe_for_work":false,"locked":false,"body":"For me, it's [`std::mem::take`](https://doc.rust-lang.org/std/mem/fn.take.html). It somehow enables nice one-liners whenever I use it.","score":231,"comments":[{"body":"Everything that makes manipulating string a pleasure. Every time I have to go back to C++ or C at work it reminds me how ergonomic Rust strings are!","score":154,"comments":[{"body":"Rust strings are particularly nice compared to other languages.\n\nC++ deals with strings the most obnoxious way possible, much worse than any other language except those without actual string types like C. How they did manage to create such a complex generic system that solves absolutely no problem at all is beyond me. At least we got std::format now.","score":58,"comments":[{"body":"The fact that `string::starts_with` is in **C++20** is mind-boggling.","score":53,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"`.parse::&lt;T&gt;()` my beloved","score":81,"comments":[{"body":"","score":0,"comments":[]}]}]},{"body":"I think `split_at_mut` is cool, since it allows us to safely partition exclusive slice-references. This allows us to parallelize algorithms working on large slices and implement various divide-and-conquer algorithms (e.g. quicksort) in safe code.","score":70,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"[`std::str::strip_prefix`](https://doc.rust-lang.org/std/primitive.str.html#method.strip_prefix). This is very awkward to write in other languages and usually even needs a copy of the remaining string.\n\n    if let Some(remainder) = s.strip_prefix(\"foo\") {\n        // …\n    }\n\nThe same in JavaScript:\n\n    const prefix = \"foo\";\n    if (s.slice(0, prefix.length) === prefix) {\n        const remainder = s.slice(prefix.length);\n        // …\n    }","score":43,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"[`Vec::extend_from_within`](https://doc.rust-lang.org/stable/std/vec/struct.Vec.html#method.extend_from_within) because I made the case for adding it, and someone actually went ahead and [did it](https://github.com/rust-lang/rust/pull/79015).","score":37,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"Great question. For some reason, I just really love [flat_map()](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.flat_map).\n\nI love being able compose nested iterators and then just say *squish it all down to the results i want* and a collection poops out ready to go.\n\nI also think [collect()](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.collect) is just incredible. Being able to collect into *anything* that implements `FromIterator` is just dope.\n\nEDIT: ya i think it’s probably collect()","score":103,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"https://doc.rust-lang.org/core/mem/fn.drop.html\n\nThe definition of that function is mind-blown-meme. Oh yeah, you say to yourself when you understand, *of course* that's how it works. That's what I want from my programming language.","score":148,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"```Result::and_then()```. Basically, using Result as a monad.\n\nWhat I love about Rust is that it is truly a multi-paradigm language. \n\nC is procedural, forcing you to explicitly describe operations in terms of memory allocation, mutation, and freeing. Rust can do that too, but safely, by using T::new(), &amp;mut references, and ownership.\n\nC++ is object-oriented, requiring that you declare classes to contain state data, with methods that get, set, and use that state data. Rust can do that too, except better, because structs with traits are so much more ergonomic than inheritance, especially once you start including packages in your ecosystem.\n\nHaskell is functional, letting you string functions together in sequence to create beautifully flowing logic chains, with functors and monads to condense branching if/else statements, or iterations over a list, into a single conceptual flow. Rust can do that too, except better, because it doesn't require strict immutability and doesn't invent a bazillion new operators like &lt;*&gt; or &lt;$&gt; or &gt;&gt;=.\n\nAnd because Rust supports all of these styles at once, you can switch between them whenever it would make your code more readable. That's what ```Result::and_then()``` represents--the ability to use functional-style error handling, represented syntactically as an object-oriented-style method chain, while retaining all of the low-level memory control of a procedural language.","score":32,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"Rust naming: shortened identifiers conventions","not_safe_for_work":false,"locked":false,"body":"I came to Rust from Java where very long and verbose identifiers are the norm. In Rust everything is much more chill, but are there any convention about what good contractions are?\n\nFor example, I have seen Ty* instead of Type* in rustc, and Arc, Rc, and other names in the standard library. However, are there any official or semiofficial documents which describe this?\n\nFor example, is it ok to shorten Reference to Ref, Make to Mk, Target to Tgt, or Context to Ctx?","score":21,"comments":[{"body":"Types and traits that are used rarely should be as long as they need to be in order to make their purpose clear. Types and traits that are used frequently can have shortened names because if it's really that common then people will learn and remember what it does even if the name is abbreviated. For example, `Vec` is very common, so it gets a shortened name. This can vary based on codebase, so your example of `Type` in rustc's codebase being shortened to `Ty` is because it's an extremely common abbreviation in that context.\n\nUse your best judgment, but err on the side of being descriptive and unambiguous.","score":68,"comments":[]},{"body":"In general I would say my opinion is that a good name is a good name regardless of the language: use as many characters as it takes to make your intentions clear, and if that's too many characters then maybe that's a sign the intentions are too complex.\n\nFor stuff like `Arc`, `Rc`, and `ref`, I don't consider it an issue because those are not obscure parts of the standard library. Smart pointers are such an integral part of Rust that I don't find shortened syntax for them to be any harder to understand than the `*` syntax for \"dumb\" pointers in, e.g., C. Everyone who knows Rust will know what those short names mean.\n\nIf I'm writing my own library, I will usually not shorten names because the domain knowledge required to understand them would be \"familiarity with my code\" instead of \"familiarity with Rust in general\".","score":24,"comments":[{"body":"&gt; For stuff like Arc, Rc, and ref, I don't consider it an issue because those are not obscure parts of the standard library. Smart pointers are such an integral part of Rust that I don't find shortened syntax for them to be any harder to understand than the * syntax for \"dumb\" pointer\n\nNot to mention that those names [began as sigils like `@` alongside `*` and `&amp;`](https://pcwalton.github.io/_posts/2013-06-02-removing-garbage-collection-from-the-rust-language.html) so it was important to keep them short when they were un-special-cased.","score":12,"comments":[]}]},{"body":"Don't know about Make, but Reference is shortened to Ref in the standard library and language itself (The `ref` keyword) so I guess it is the preferred way?","score":9,"comments":[]},{"body":"If an abbreviation is common enough it's fine, otherwise spell it out.\n\nCtx and Ref are the only ones you listed I'd accept, and ref with the caveat that it has to be a part of a larger name because `ref` is a keyword. Ty instead of Type kind of makes sense because `type` is also a keyword. I use typ instead though","score":7,"comments":[]},{"body":"A lot of it will be due to repetition. I often elide characters for temporary variables. In match statements where the same variable appears in the inner and outer contexts this kind of thing happens:\n\n    let foobar = match frobinate(foo, bar) {\n        Ok(f) =&gt; f.into(),\n        Err(e) =&gt; {\n            log_error!(e);\n            e\n        }\n    }?;\n\nThe type context and pattern matching tell you all you need to know about the variable, so giving it more letters is just more typing without increased clarity.","score":7,"comments":[]},{"body":"You can check the std library; `Ref` is used for reference,  `cx` for context, but only identifier, not for type names (see `Future` docs).  I think `Target` is always written out, as well as `make`.\n\nUsually type names are full words (with some exceptions, like `Ref`), and identifiers are shortened words.  Most of the time acronyms and initialisms should be avoided unless it would be abnoxiously unweildy without (`Arc`, `Gui`, etc).  I also think keeping type names down to 2 or 3 words at maximum is ideal, less is better.  Similarly, for identifiers, one or two words is the ideal length.  Short words aren't abbreviated (Like `make`, `with`, etc.).  Long identifier names can be shortened with an acronym or initialism if no better alternative single-word name or shortened word is obvious, where I would add a comment with it spelled out above the `let` statement.  A lot of that is my own personal rules, but I think they're generally used throughout the Rust ecosystem.","score":5,"comments":[]},{"body":"Some useful heuristics:\n - more common names can have more aggressive abbreviations\n   - since they are typed more, you save more keystrokes than if it was used less often\n   - since they are seen more, people learn what they mean quicker\n - ambiguity is bad. `vec` only ever means vector, so it. `ctx` is a better abbreviation for `context` than `con` because `con` could feasibly be `connection`\n - reuse existing abbreviations - if your name has a well-known abbreviation already, it's more likely to be sensible\n - abbreviations are context-sensitive - the same abbreviation can mean different things in different contexts,l. For example `pg` means \"postgres\" in database code, but is mostly meaningless in linear algebra code","score":2,"comments":[]},{"body":"&gt; In Rust everything is much more chill\n\nThere was a missed opportunity with `Option` and `Result` though. We could've had `Opt` and `Res`.\n\nWell, technically you *can* write aliases, but it would make your code look alien.","score":2,"comments":[]},{"body":"Don't use short names, regardless of the language.\n\n&gt; For example, is it ok to shorten Reference to Ref, Make to Mk, Target to Tgt, or Context to Ctx?\n\nMy personal opinion is a strong no. Spell things out.","score":-1,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"How to approach the progress indication of io operations?","not_safe_for_work":false,"locked":false,"body":"Web dev/devops by day, learning Rust by night, keep running into things I never had to consider before.\n\nI'm writing a program to make some image processing with image crate on a few files. I'd like to present a user with a progress bar of some kind. I have a few image::open calls, then I have some operations performed, and finally calling save.\n\nI know I can use `fs::metadata.len()` to get the byte count of my images, but how do I show the process of them getting into memory in real-time? Something like indicatif can draw a bar for me, but how do I pass current state of reading(or saving for that matter) to a function like `inc` or `set_position`?\n\nHow would you approach showing a progress bar for overall progress of computation over multiple files in this case?","score":16,"comments":[{"body":"If you call `read` on anything implementing `std::io::Read` and provide a fixed sized buffer it will read only that many bytes (or less) before returning. Using this, you can break up the read operations into chunks and update your progress bar incrementally, however it will be much slower overall due to requiring an additional system call each time you call `read`.","score":22,"comments":[{"body":"\"much\" entirely depends on the buffer size. For any size operation 4mb+ buffers should be negligible. You probably won't hurt performance too much as long as you don't go below 512KB, but depends on the drive etc. But for batch image processing the time here is likely dominated processing not loading.\n\nThe simplest thing for multiple file processing is chunk the progress bar by file count, so 40 files the progress bar counts to 40 to be full, as each one completes. You can process with multiple threads and update an atomic \"completed count\" read by your UI component or notify or something for it to update.","score":20,"comments":[{"body":"&gt;\"much\" entirely depends on the buffer size. For any size operation 4mb+ buffers should be negligible. You probably won't hurt performance too much as long as you don't go below 512KB, but depends on the drive etc.\n\nWell sure, but images aren't usually that big. A progress bar with 10 increments would be a 40 MB image... The average 4K image is only 24 MB uncompressed, and less than 4 MB compressed.","score":5,"comments":[{"body":"Agreed. I think I updated my comment while you were replying. It's probably better for op to think about progress at the \"whole file done\" level, as loading a single image and processing it can't take more than 3 seconds on average in which case a busy spinner UI would be sufficient.\n\nThe idea of updating progress by \"read position\" is really only worth it for processing video.","score":1,"comments":[{"body":"&gt; The idea of updating progress by \"read position\" is really only worth it for processing video.\n\nIt depends. I've run into situations where I was working with 60MB images before... though the problem with those is that, to get properly meaningful \"doesn't hang for a bit at 100%\" progress indication, you really want to be able to hook into the `image` crate's PNG/JPEG/whatever decoder for progress indication and then let it drive the `Read`ing as it needs to.","score":3,"comments":[{"body":"You're right, by video i really mean \"processing larger than 50mb media\". I would assume 60mb+ pics to be fairly niche, but then again at the same time any software specializing in those to be extra polished and subsequently expensively priced to warrant the extra UI.","score":1,"comments":[{"body":"I've made hobby edits of such images using The GIMP and I don't think I had to configure it to be greedier with my RAM.","score":1,"comments":[]}]}]}]}]}]}]},{"body":"`indicatif` has a method for this, [`ProgressBar::wrap_read`](https://docs.rs/indicatif/latest/indicatif/struct.ProgressBar.html#method.wrap_read). It returns a new readable that automatically updates the progress bar.\n\nUnder the hood it just [looks at the return value of `Read::read()`](https://docs.rs/indicatif/0.17.2/src/indicatif/iter.rs.html#146-170). The usual ways of reading a file typically call `read()` in a loop, see the documentation of [`Read::read_to_end()`](https://doc.rust-lang.org/std/io/trait.Read.html#method.read_to_end). You can write such a loop yourself for fine control.","score":9,"comments":[]}]},{"title":"Resources on Lifetimes","not_safe_for_work":false,"locked":false,"body":"Hello,\n\nI have been going through \"The Rust Programming Language\". thanks to the writing style, up until now, I haven't had many problems understanding the concepts explained. However, Lifetimes are the one area where I feel that I could do with another explanation. Would you guys be able to recommend, videos or articles, that kind of \"dumb it down\" ?  \nMany Thanks","score":10,"comments":[{"body":"[https://www.youtube.com/watch?v=rAl-9HwD858](https://www.youtube.com/watch?v=rAl-9HwD858)\n\nThis video from Jon Gjengset was the sort of \"lynchpin\" that really got me to where I could grok lifetimes.  cc /u/76P3UGqFL9VJbk","score":2,"comments":[]},{"body":"I'm on the same boat, struggling to understand lifetimes, have read two times the chapter from The Book but could not get it yet.  \n\n\nI understand what they do but not how to think about it.","score":1,"comments":[]}]},{"title":"GitHub Actions for Clippy","not_safe_for_work":false,"locked":false,"body":"I like Clippy and want it to integrate into CI easily, so I'm creating clippy-action for fun. If you're interested, I'd be happy to use it.\n\n[https://github.com/marketplace/actions/run-clippy-with-reviewdog](https://github.com/marketplace/actions/run-clippy-with-reviewdog) [https://github.com/giraffate/clippy-action](https://github.com/giraffate/clippy-action)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/ytg5aicsgv0a1.png?width=1886&amp;format=png&amp;auto=webp&amp;s=804c636586b74a3e424b1e9f5c80b5c76f841688","score":66,"comments":[{"body":"Thank you for the work you and your team are putting into clippy!","score":15,"comments":[]},{"body":"Why submit reviews instead of using annotations?","score":6,"comments":[{"body":"Pull requests from outside contributors don’t have permission to annotate, unfortunately.","score":3,"comments":[]}]},{"body":"This looks great. I will definitely give it a try.\n\nAre you aware of any alternatives and how do they compare to yours?","score":3,"comments":[]},{"body":"There is also [`clippy-sarif`](https://crates.io/crates/clippy-sarif)","score":1,"comments":[{"body":"Got an example of how sarif is rendered in a PR?","score":1,"comments":[]}]}]},{"title":"Why does Rust have parameters on impl?","not_safe_for_work":false,"locked":false,"body":"I am working on implementing a programming language inspired partly from Rust, and wondering why Rust chose to have parameters on `impl`. In [alloc/vec](https://web.mit.edu/rust-lang_v1.26.0/arch/amd64_ubuntu1404/share/doc/rust/html/src/alloc/vec.rs.html#302-305) in Rust, we have `impl` usages like these:\n\n    pub struct Vec&lt;T&gt; {\n      buf: RawVec&lt;T&gt;,\n      len: usize,\n    }\n\n    impl&lt;T&gt; Vec&lt;T&gt; {\n      pub fn new() -&gt; Vec&lt;T&gt; {\n        Vec {\n          buf: RawVec::new(),\n          len: 0,\n        }\n      }\n\n      // ...\n    }\n\n    impl&lt;T: Clone&gt; Vec&lt;T&gt; {\n      pub fn resize(&amp;mut self, new_len: usize, value: T) {\n        let len = self.len();\n\n        if new_len &gt; len {\n          self.extend_with(new_len - len, ExtendElement(value))\n        } else {\n          self.truncate(new_len);\n        }\n      }\n\n      // ...\n    }\n\n    struct ExtendElement&lt;T&gt;(T);\n    impl&lt;T: Clone&gt; ExtendWith&lt;T&gt; for ExtendElement&lt;T&gt; {\n      fn next(&amp;self) -&gt; T { self.0.clone() }\n      fn last(self) -&gt; T { self.0 }\n    }\n\n    impl&lt;T: Clone&gt; Clone for Vec&lt;T&gt; {\n      fn clone(&amp;self) -&gt; Vec&lt;T&gt; {\n        &lt;[T]&gt;::to_vec(&amp;**self)\n      }\n    }\n\n    impl&lt;T, I&gt; Index&lt;I&gt; for Vec&lt;T&gt;\n    where\n      I: ::core::slice::SliceIndex&lt;[T]&gt;,\n    {\n      type Output = I::Output;\n\n      fn index(&amp;self, index: I) -&gt; &amp;Self::Output {\n        Index::index(&amp;**self, index)\n      }\n    }\n\n    impl&lt;T: Default&gt; Vec&lt;T&gt; {\n      // ...\n    }\n\n    impl&lt;T: Clone&gt; Clone for Reverse&lt;T&gt; {\n        #[inline]\n        fn clone(&amp;self) -&gt; Reverse&lt;T&gt; {\n            Reverse(self.0.clone())\n        }\n\n        #[inline]\n        fn clone_from(&amp;mut self, other: &amp;Self) {\n            self.0.clone_from(&amp;other.0)\n        }\n    }\n\nIn [alloc/vec/mod](https://doc.rust-lang.org/src/alloc/vec/mod.rs.html#400) we have similar things:\n\n\n    impl&lt;T, A: Allocator&gt; Vec&lt;T, A&gt; {\n      // ...\n    }\n\n    impl&lt;'a, T, A: core::alloc::Allocator&gt; Drop for FillGapOnDrop&lt;'a, T, A&gt; {\n      // ...\n    }\n\n    impl&lt;T, A: Allocator, const N: usize&gt; Vec&lt;[T; N], A&gt; {\n      // ...\n    }\n\n    struct ExtendFunc&lt;F&gt;(F);\n    impl&lt;T, F: FnMut() -&gt; T&gt; ExtendWith&lt;T&gt; for ExtendFunc&lt;F&gt; {\n      fn next(&amp;mut self) -&gt; T {\n        (self.0)()\n      }\n      fn last(mut self) -&gt; T {\n        (self.0)()\n      }\n    }\n\nIs that `impl` used with type parameters simply to scope it and reduce duplication across the trait and structs? I could see doing it these other ways if we were to reimplement Rust (or do a similar thing in another custom programming language):\n\n    impl Vec&lt;T&gt; {\n      // ...\n    }\n\n    impl Vec&lt;T: Clone&gt; { /* ... */ }\n\n    // impl&lt;T: Clone&gt; ExtendWith&lt;T&gt; for ExtendElement&lt;T&gt; {}\n    // some duplication here, maybe that's why it was done?\n    impl ExtendWith&lt;T: Clone&gt; for ExtendElement&lt;T: Clone&gt; {}\n    // could get by with a `where` perhaps, something like\n    impl ExtendWith&lt;T&gt; for ExtendElement&lt;T&gt; where T: Clone {}\n\n    impl Clone for Vec&lt;T: Clone&gt; {}\n\n    // impl&lt;T, I&gt; Index&lt;I&gt; for Vec&lt;T&gt;\n    // where I: ::core::slice::SliceIndex&lt;[T]&gt;,\n    impl Index&lt;I: ::core::slice::SliceIndex&lt;[T]&gt;&gt; for Vec&lt;T&gt; {}\n\n    impl Vec&lt;T: Default&gt; {}\n\n    impl Vec&lt;T, A: Allocator&gt; {}\n\n    impl Drop for FillGapOnDrop&lt;'a, T, A: core::alloc::Allocator&gt; {}\n\n    // here, types stretch over both the trait and the struct\n    // so maybe having impl just centralized everything?\n    impl ExtendWith&lt;T&gt; for ExtendFunc&lt;F: FnMut() -&gt; T&gt; {}","score":20,"comments":[{"body":"The parameterisation is necessary for the same reason why it's necessary for functions: it disambiguates, because you can `impl` on a \"fully applied\" generic type e.g.\n\n    impl Foo&lt;usize&gt; {\n        fn test(&amp;self) {}\n    }\n\nwill define  a method `test` *only* on `Foo&lt;usize&gt;`, not on `Foo&lt;u8&gt;` or `Foo&lt;String&gt;`.\n\nNow the \"bare\" form `impl T&lt;U&gt; {}` is not super used right now I think, but this is already useful for specific implementations of traits e.g. `AsRef&lt;str&gt; for str` (which with your scheme wouldn't work as `str` would be a generic type).\n\nIt's also critical with specialization (which is used in the stdlib though not stable) as the entire point is to provide a, well, specialized `impl`. This requires distinguishing between \"generic\" and \"specific\" impls, as usually you provide a default \"blanket\" implementation, then you provide specialized implementations for a few specific types.\n\nIt's also a hook point for generic bounds, which is not entirely necessary (as you can use `where` clauses instead), but can be a useful shortcut, especially for simpler bounds (e.g. single short trait, or lifetime bounds).","score":45,"comments":[]},{"body":"Short motivational example: \n\n    struct Pair&lt;U, V&gt; { fst: U, snd: V }\n    \n    impl&lt;T&gt; Pair&lt;T, T&gt; {\n        fn flip(&amp;mut self) {\n            std::mem::swap(&amp;mut self.fst, &amp;mut self.snd)\n        }\n    }","score":39,"comments":[{"body":"Similarly:\n\n    impl&lt;T&gt; Foo&lt;Vec&lt;T&gt;&gt; { ... }\n\nC++ has a similar pre-declaration of template parameters (with the `template` keyword) and for the same reasons.","score":16,"comments":[]},{"body":"But here, even without `impl&lt;T&gt;`, the Rust compiler could, in principle, figure out that the method is only implemented for two parameters of the same type since both generic parameters share the same name, or am I missing something?","score":2,"comments":[{"body":"Simply introducing a type T would break that, wouldn't it?","score":1,"comments":[{"body":"Yes, so the need for `impl&lt;T&gt;` is precisely given because one must also be able to implement some functionality for a specific type `T`, as opposed to a generic type `T`.","score":1,"comments":[]}]}]},{"body":"Beautifully concise.","score":0,"comments":[]}]},{"body":"Short answer: because [Chalk](https://rust-lang.github.io/chalk/book/what_is_chalk.html) is not yet ready and Rust needed generics years ago.\n\nThese arguments are not, really, needed, but they simplify the logic: you know which variables are “inputs” and which are “outputs” just from the syntax.\n\nThis doesn't work 100%, reliably, of course, and can produce [strange results](https://github.com/rust-lang/rust/issues/41756), but doing things properly is hard thus Rust cheats a bit.","score":0,"comments":[]}]},{"title":"Man, Rust has me addicted!","not_safe_for_work":false,"locked":false,"body":"So I finally decided to learn Rust and long story short it's all I can think about at the moment.\n\nI'm a seasoned developer with roots in microcontroller programming with C who spent the better part of the last decade as a fullstack developer (Java, TypeScript).\n\nI always had the itch to do some C/C++ again but whenever I tried I was taken aback by the poor developer experience (compared to what I was used to in webdev). A lot of manual setup and decisions. I didn't want to deal with that, time's changed, bar's raised. Not to mention that I work cross platform.\n\nRust on the other hand just works. Install Rust and you get a package manager, test runner, all cross platform and easy to use.\n\nHowever I was actually getting frustrated writing Rust code in the beginning. As I had experience with C and its concepts I expected to progress faster but the compiler kept complaining A LOT.\n\nIt still complains but now I have a much better understanding what the reason might be.\n\nBut it's just a joy working with the language. When it compiles and runs it often does what I wanted, I never had this experience in other languages.\n\nIt's gotten to the point where it's all I can think about currently. I wake up and I think about the problem I had last night. At work I still keep thinking about it and how I would solve it in the evening. I haven't had this drive in a very long time!\n\nIt's also gotten to the point where I no feel a little disgusted when I have to think how I would have written the same code in other languages. The amount of effort needed to make the code as resilient, which in the end you won't do so you end up with a less resilient version.\n\nIdk, I just wanted to share my experience with Rust so far, as I didn't expect to grab me like this.","score":448,"comments":[{"body":"&gt;It's also gotten to the point where I no feel a little disgusted when I have to think how I would have written the same code in other languages. \n\nI started in Python and loved it. Going back made me feel so dirty. Writing a function without knowing its return type seems so insane now.","score":178,"comments":[{"body":"&gt;\tWriting a function without knowing its return type seems so insane now.\n\nI know it’s only used by linters, but I’ve started using the `typing` library for this exact reason.  Helps cut down on the bugs for sure. \n\nSimilar approach for JS; I use Typescript for most webby things now instead of ES.","score":48,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"Python's type annotations are really improving. It's never going to be Rust, but it's a far bit better than it was before.","score":75,"comments":[{"body":"Yeah, but Python's type annotations are more like \"Trust me, bro. This function returns a string! At least it did when we added the annotation back in the day...\"","score":75,"comments":[{"body":"mypy or pyright will actually statically check for you! its a bit of a rough road given that types are more or less duct taped on top of everything, but you can get pretty decent type safety with everything set up!","score":60,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]}]},{"body":"","score":0,"comments":[]}]},{"body":"&gt; but the compiler kept complaining A LOT.\n\n&gt; It still complains but now I have a much better understanding what the reason might be.\n\n\nBeginning to program in Rust is like learning to drive from your father: the old man will annoy the shit out of you with every little thing he can think off. But, after a while, you begin to accept that he is right.","score":157,"comments":[{"body":"And after you think you've got it, go ahead and enable all possible warnings in clippy...","score":44,"comments":[{"body":"Isn’t clippy more along the lines of - this could be more idiomatic - rather than - this code is incorrect?","score":24,"comments":[{"body":"yes and it makes things so much cleaner ❤️","score":40,"comments":[]},{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"Replace rust with a name of a person. This sounds like you are in love!","score":17,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"Branching based on the return type of a function/closure argument","not_safe_for_work":false,"locked":false,"body":"So I have a function that takes in another function or closure as an argument. What I want to do is basically have a logical branching based on the return type of f. Specifically when f doesn't return anything ie: \n\n```\nfn foo&lt;F, T&gt;(f: F) \n    where \n    F: Fn() -&gt; T \n{\n    if T is () {\n        do something here\n    } else {\n        do something else here\n    }\n}\n```\n\nIs this actually possible in rust?","score":7,"comments":[{"body":"https://doc.rust-lang.org/std/any/struct.TypeId.html - something like this maybe? \n\nhttps://github.com/pacak/bpaf/blob/master/src/from_os_str.rs - a concrete example","score":4,"comments":[]},{"body":"Yes you can do something like that using enums. For example you could use 'Option&lt;T&gt;'","score":3,"comments":[]},{"body":"I would write different functions for the different types. Generics are useful if you need the same function for a bunch of different types. If you need different functions for different types, I'd recommend just writing different funcs.","score":3,"comments":[]},{"body":"You should create a trait that has a method and require that `T::your_trait`. Then implement the trait for types the way the should work.\n\nThis kind of reflection on the types isn't possible in rust without hacks","score":1,"comments":[]}]},{"title":"References confuse me","not_safe_for_work":false,"locked":false,"body":"Ye, couldn't come up with a better title for this one.\n\nFor context, I'm currently trying to implement Hindley-Milner type-inference for a stack-based language by kind-of translating [this ML code](https://github.com/jfecher/algorithm-j) and now I've hit the following roadblock:\n\nI have the following type:\n\n    pub enum Type {\n        Kind(String, Vec&lt;Type&gt;),\n        Variable(String, VarContent)\n    }\n\nand say I have the following Vec's:\n\n    vec![\n        Kind(\"string\", vec![]),\n        Variable(\"A\", None),\n        Variable(\"A\", None)\n    ]\n    \n    vec![\n        Variable(\"A\", None)\n    ]\n\nNow, if I change one occurence of the variable A, I want ALL occurences to change. I tried to define `VarContent` like this\n\n    type VarContent = Rc&lt;RefCell&lt;Option&lt;Type&gt;&gt;&gt;;\n\n... which panics when I try to `replace` the content, as the value is borrowed by all other occurences of the variable.\n\nI know this is the \"classic\" situation where Rust tries to safeguard you from mutating things while you have borrowed.\n\nWelp, I'm pretty new to Rust so... what's the best practice for such a case?\n\nSide Note: I'd rather not use a `HashMap` because variables with the same name may have different values depending on the context. The implementation would be far more complex, I think.\n\n\\--- EDIT ---\n\nAfter actually using a debugger I found the problematic code fragment:\n\n    if let Some(inner) = varcontent.borrow().as_ref() {\n        // (1)\n        // Perform computations\n    }\n    else {\n        // (2)\n        varcontent.replace(Some(somevalue));\n    }\n\nThe panic occurs when the code enters block (2). I would expect, that after borrowing the `RefCell`, the reference will be dropped before entering (2) - because I cannot access `inner` in (2) anyway. For some reason that's not the case, can somebody help me out?","score":6,"comments":[{"body":"Your `Rc` solution should be fine, it will only panic if you borrow its contents and keep it borrowed while you want to do the mutation.  Hard to say how to fix this without more code, but try to only ever borrow the RefCell temporarily.","score":5,"comments":[]},{"body":"Using an `Rc` and `RefCell` should work as long as you keep your borrows short. I prefer using arenas for this sort of situation because they are more ergonomic and probably faster. You can implement an arena yourself by just giving out the current length of the `Vec` as the id and then pushing to the `Vec`. You can also use a crate like [la-arena](https://crates.io/crates/la-arena)","score":3,"comments":[{"body":"True, I've heard of arenas before, I'll try it using one if I cannot fix my approach","score":1,"comments":[]}]},{"body":"I had a very similar issue in a project I've been working on recently. In my case, I had a collection of structs (call them `Thing`) which had an attribute `names: Vec&lt;String&gt;`, but I wanted to use a `HashMap&lt;String, Vec&lt;Thing&gt;&gt;` for each name to make lookup on a name to get all `Thing`s associated to that name fast. However, that required cloning the `Thing` for each insertion.\n\nI ended up creating a wrapper struct and keeping the owned objects in a `Vec&lt;Thing&gt;` and then upon insertion to the `Vec`, inserting an **index** to them in a separate field called `name_lookup: HashMap&lt;String, Vec&lt;usize&gt;&gt;`. It ended up being great because I had other attributes I wanted quick lookup on. I initially tried this by inserting references (i.e., `HashMap&lt;String, Vec&lt;&amp;Thing&gt;&gt;`) but I didn't realize how bad that is because if the `Vec` is realloc'd then that would invalidate those refs. Luckily the borrow checker was having none of that, so that's what lead me to using indices.","score":1,"comments":[]}]},{"title":"Regex101.com needs help getting a small Rust WASM binary","not_safe_for_work":false,"locked":false,"body":"Chances are many of you have used [regex101.com](https://regex101.com/) to help debug regex queries - it’s amazing. Unfortunately, Rust is notably missing from the language list (it's very similar to Golang, but not exact).\n\nThe maintainer of the website is open to adding a Rust flavor, but it seems like there has been some difficulty getting the size of the generated wasm down to ideally &lt;500kB (rough requirement set by the author). Current sizes are closer to 3 MB: link to the discussion: https://github.com/firasdib/Regex101/issues/1208\n\nI know there are a ton of nuanced ways to optimize wasm (different allocators, somewhat hidden compiler options and such) and I know there are a lot of people here who know how to use them correctly. If you are one of those people and have the time, try your hand at making the smallest possible Regex binary. Just join in the discussion above if you’re successful, or have ideas for what to try. The entire Rust community will thank you!\n\nI _think_ that all that is needed is a way to accept an input string and flags, map those flags to `RegexBuilder` options, and return the expanded results of `captures_iter()`. A simple wrapper to call `replace_all()` would work for the replacer section of the site.\n\n(I am not associated with the site at all, just somebody who’s missed the Rust option and stumbled across the discussion about it)\n\nEdit: great news! u/colorfulchew was able to do some tweaks that got under the 500kB limit so we’re all set! Little bit more work in the thread and we came up with a rough API at 430kB total, so we’ll see what the maintainer has to say","score":291,"comments":[{"body":"I've done this sort of WASM golf before so I gave it a shot and got a wasm just under 500KB with some shenanigans. Responded on the PR, but thanks for the call for attention!","score":236,"comments":[{"body":"Awesome work! That’s what the community is about, probably 20 minutes of time and your work will help thousands. Thank you!","score":94,"comments":[{"body":"Thanks, I definitely have wondered why Regex101 didn't support Rust before, so I'm more than happy to help contribute!","score":63,"comments":[]}]},{"body":"Looks like I got nerd-sniped as well... There are potential savings (depending on what you want/can sacrifice) to get it to ~150KB (findings documented here: https://github.com/firasdib/Regex101/issues/1208#issuecomment-1320865433)","score":27,"comments":[{"body":"","score":0,"comments":[]}]}]},{"body":"That’s an 11/10 website right there","score":54,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"In my project, to generate wasm files in the 100Kb-150Kb range I use the release profile below plus post-processing\n\n```\r\n[workspace.profile.release]\ndebug = false\nlto = true\ncodegen-units = 1\nopt-level = 's' # Optimize for size\npanic = 'abort' # About unwinding code\nstrip = \"debuginfo\"\n```\r\n\nI have experimented with application of post-processing tools and eventually settled on applying thus:\n\n- wasm-gc -o\n- wasm-snip -o\n- wasm-gc -o (yes! Applying again!)\n- wasm-opt -O4 --dce -o\n\nIf you supply a generated wasm file from the build we could play with post-processing tools and report back results.","score":16,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"FYI: It's no Regex101 in terms of features, but with https://rustexp.lpil.uk/ there is an existing website that utilizes the `regex` crate, which can be used for interactive testing.","score":10,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"Presumably they're using the regex crate? Perhaps /u/burntsushi has a suggestion?","score":32,"comments":[{"body":"How do they do other regex engines, like Go's? Is that also WASM?\n\nAnyway, I dunno. There are perf features that can be disabled that will shrink binary size a bit without impacting functionality, and perhaps some of the Unicode features could be disabled. But none of that requires any specialized knowledge of the regex crate.\n\nIt isn't totally clear whether the regex crate is the biggest problem here. I don't have much experience with WASM, so I'm probably not the right person to ask.","score":44,"comments":[{"body":"According to [this comment](https://github.com/firasdib/Regex101/issues/1208#issuecomment-1195353084) they’re apparently compiled to WASM, but I kind of have some questions about that. Python and PHP WASM binaries? I didn’t think that was possible.\n\nI don’t think any of the changes to be made here have anything to do with the Regex crate (though maybe the no_std version would be helpful), more about what it’s built with. I keep on seeing posts here about shrinking WASM binaries with things like different allocators, so figured I’d post this and see if anybody is able to connect some of the dots. (Am also not too familiar with WASM)","score":17,"comments":[{"body":"","score":0,"comments":[]}]}]},{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"[Media] Any neovim users here? Can you help me figure out why I'm getting this popup error when opening a rust file? nvim 0.8.1, rust-analyzer 0.0.0 (ba28e19b7 2022-10-29, tree-sitter 0.20.7. (there's no error in the code/rust file; it worked before something got updated; not sure what).","not_safe_for_work":false,"locked":false,"body":"","score":13,"comments":[{"body":"I think you need to add your rs file as a mod within either lib.rs or main.rs","score":8,"comments":[{"body":"exactly, and the LSP provides a code action for that so you don't have to manually do that.\n\nI use  \"&lt;space&gt;ca\" to open those suggestions and add it there.","score":3,"comments":[]}]}]},{"title":"Slint app as display server","not_safe_for_work":false,"locked":false,"body":"Can you use a Slint app as display server? Spoiler: yes you can. This example shows a separate app drawn inside of a window in a Slint app. Frame buffer and events exchanged through inter process communication (IPC). Source code follows soon.  \n\n\nhttps://reddit.com/link/yzmhrt/video/ad1wf0dw5z0a1/player","score":2,"comments":[]},{"title":"Blog Post: If a Tree Falls in a Forest, Does It Overflow the Stack?","not_safe_for_work":false,"locked":false,"body":"","score":150,"comments":[{"body":"I think this is known as Morris Tree Traversal, which is actually linear time.\n\nEDIT: and here is my implementation of a more direct Morris Traversal\n\n    impl&lt;T&gt; Drop for Node&lt;T&gt; {\n        fn drop(&amp;mut self) {\n            loop {\n                if let Some(mut left) = self.left.take() {\n                    std::mem::swap(self, left.as_mut());\n                    let mut left_visitor = &amp;mut self.right;\n                    loop {\n                        if left_visitor.is_some() {\n                            left_visitor = &amp;mut left_visitor.as_mut().unwrap().right;\n                        } else {\n                            left_visitor.replace(left);\n                            break;\n                        }\n                    }\n                } else if let Some(right) = self.right.take() {\n                    *self = *right;\n                } else {\n                    break;\n                }\n            }\n        }\n    }","score":55,"comments":[{"body":"TIL, thanks!","score":17,"comments":[{"body":"A proof sketch of linear time and constant stack space:\n\nObserve recursing to the only left child is conceptually equivalent to a right rotation, so let's say we always do right rotation when there is a left child. Then observe that every right rotation adds one node to the right-chain of the tree (the chain of nodes by following right-pointers) without removing any. Each node can only be added to the right-chain at most once. So the number of right rotation is bounded by the number of nodes, which is linear.\n\nMoreover, a node is dropped if and only if it is the current root of right-chain with no left child, hence no node can be dropped by implicit drop call, which proves constant stack space.","score":3,"comments":[]}]}]},{"body":"I love that insight that you can just restructure the tree because this is *the* destructor so who cares if you mess it up.","score":36,"comments":[]},{"body":"Maybe I'm too tired, but in the last piece of code why can we assume every child node is in a contiguous range? Shouldn't we just assume that it's a Vec of indices?","score":6,"comments":[{"body":"I think you can always order the nodes of a tree in such a way. Nothing stops you from having\n\n1. root\n2. child 1 of root (a)\n3. child 2 of root (b)\n4. child 1 of a (aa)\n5. child 2 of a (ab)\n6. child 3 of a (ac)\n7. child 1 of b (ba)\n8. child 1 of ac\n9. child 2 of ac\n\nin a vector.","score":4,"comments":[{"body":"Yeah, but that implies that your insertion is O(n), as you have to move nodes in the Vec **and** you have to update the corresponding ranges of each node in the Vec. And I'd find that pretty weird, as you can just use a Vec of indices and have O(depth) insertion with a simpler algorithm","score":4,"comments":[{"body":"I think it wasn't a super fleshed-out example, you could imagine using a bit vector (or vector of indicies, or whatever) instead.","score":2,"comments":[{"body":"","score":0,"comments":[]}]}]}]}]},{"body":"I once fixed my solution to an ACM ICPC problem by just stopping trying to clean up my nodes.  Success!","score":5,"comments":[]},{"body":"I love the article name.","score":6,"comments":[]},{"body":"","score":0,"comments":[]}]},{"title":"How to return buffer in a struct from fn?","not_safe_for_work":false,"locked":false,"body":"I'm a Rust newbie.  Working with some NT APIs that require a UNICODE\\_STRING struct.  Thought it would make sense to implement it as a trait.  The struct contains members for the size of the buffer and the buffer itself.  The problem is that returning the struct doesn't return the buffer (it's null):  \n\n\n\\`\\`\\`rust  \ntrait UnicodeString{\n\nfn to\\_unicode\\_string(&amp;self) -&gt; Box&lt;UNICODE\\_STRING&gt;;\n\n}\n\n&amp;#x200B;\n\nimpl UnicodeString for String {\n\nfn to\\_unicode\\_string&lt;'a&gt;(&amp;self) -&gt; Box&lt;UNICODE\\_STRING&gt;{\n\nlet mut unicode\\_buffer: Vec&lt;u16&gt; = self.encode\\_utf16().collect();\n\nunicode\\_buffer.push(0); // terminating null\n\nBox::new(UNICODE\\_STRING {\n\n// Length does not include the terminating null and is in bytes\n\nLength: ((unicode\\_buffer.len() - 1) \\* size\\_of::&lt;u16&gt;()) as u16,\n\nMaximumLength: (unicode\\_buffer.len() \\* size\\_of::&lt;u16&gt;()) as u16,\n\nBuffer: unicode\\_buffer.as\\_mut\\_ptr(),\n\n})\n\n}\n\n}  \n\\`\\`\\`  \n\n\nI thought putting it in a Box would work, but doesn't include the buffer.  Help?","score":3,"comments":[{"body":"The way you wrote this, the Vec&lt;u16&gt; is dropped when the function returns. If you really want to do it this way you can std::mem::forget() the Vec so it doesn't get dropped. That will be a memory leak. Otherwise you need to make a struct that holds that Vec&lt;u16&gt; and give it a method that returns an &amp;UNICODE_STRING. This way the lifetime of the Unicode struct is tied to the lifetime of the Vec. You could also just make a free fn/trait impled for Vec&lt;u16&gt; if you don't want to make a wrapping struct","score":4,"comments":[{"body":"Thanks, I'll give that a try  \n\n\nedit: thinking about this, wouldn't the method on the Vec&lt;u16&gt; returning a UNICODE\\_STRING have the same problem?  It seems like I can just allocate a buffer for the entire struct populating the elements correctly and return that as a UNICODE\\_STRING?  It just doesn't feel like the right way to do it.","score":1,"comments":[{"body":"Honestly the real problem is the UNICODE_STRING struct. It shouldn't be exposing a pointer field, but a reference. It should also at least have a lifetime associated with it.","score":1,"comments":[{"body":"Yeah, I realized after trying something it won't work because UNICODE\\_STRING has a pointer.  Seems like I either create a new struct like you suggested or just inline the UNICODE\\_STRING usage.  Thought I was doing it right by implementing a trait, but passing a buffer with a pointer is the problem.  Wrapping it with a struct doesn't seem to make the usage of it any simpler.  Thanks anyways, I feel I did learn something here :)","score":1,"comments":[]}]}]}]},{"body":"I think you should try accomplishing what you want using https://doc.rust-lang.org/std/ffi/index.html#conversions. I'd be surprised if OsStr doesn't have some way to do what you are attempting","score":1,"comments":[{"body":"Unfortunately, UNICODE\\_STRING is a Windows c struct that has two members indicating size and the problem is the last member is a pointer and no the buffer itself.","score":1,"comments":[{"body":"I would make using this safer by doing something like this \n\n    pub struct UnicodeStringHolder&lt;'a&gt;(UNICODE_STRING);\n\n    impl &lt;'a&gt; UnicodeStringHolder&lt;'a&gt; {\n        pub fn from_slice(slice: &amp;'a[u16]) -&gt; Self {\n            Self(UNICODE_STRING {  })\n        }\n    }\nThis way you can safely make UNICODE_STRINGs from any slice, and have the compiler check the lifetimes for you.","score":2,"comments":[{"body":"That’s interesting, will try that.  Thanks!","score":1,"comments":[]}]}]}]}]},{"title":"MIRI error with variable payload structs","not_safe_for_work":false,"locked":false,"body":"There's a winapi type [TOKEN_GROUPS](https://docs.rs/winapi/latest/winapi/um/winnt/struct.TOKEN_GROUPS.html) that's used as a struct with a [variable size payload](https://learn.microsoft.com/en-us/windows/win32/api/winnt/ns-winnt-token_groups).\n\nI tried to find a way to use this pattern in a way that satisfies MIRI, but it seems like there's missing provenance info (am I using that word correctly?).\n\nAm I doing something wrong or is this a (known?) issue in MIRI?\n\nEdit: fixed playground link to add `#[repr(C)]`\n\nPlayground link (simplified TOKEN_GROUPS for ease of testing):\nhttps://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=83477b9b30449c7749d2747db4a601ca","score":0,"comments":[{"body":"The layout of structs in rust is unspecified. If you need a specific layout you can add `#[repr(c)]`.","score":2,"comments":[{"body":"Thanks for catching that mistake; unfortunately it doesn't seem to help with the MIRI checks:\n\nhttps://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=83477b9b30449c7749d2747db4a601ca","score":1,"comments":[]}]}]},{"title":"Whats the best way to make a simple client server application? Are web frameworks the way to go?","not_safe_for_work":false,"locked":false,"body":"I want to make a multiplayer board/card game as a project. For a while I thought that making a web application was the way to go to achieve this considering how popular web frameworks are (I started learning axum), but then it got me thinking about games and even apps (tauri?) do it. I would assume that they use more direct TCP instead of bothering with HTTP, and that learning loads of axum for just sending small amounts of data back and forth might be overkill.\n\nDoes anybody have opinions on how to achieve this? I did some research but there were barely any resources on client server applications.","score":0,"comments":[{"body":"If you want to get a deep dive, check https://gafferongames.com/categories/game-networking/\n\nFor your use-case, yeah, I'd probably go for raw TCP to get started.","score":2,"comments":[]}]},{"title":"Writing a CLI in Rust","not_safe_for_work":false,"locked":false,"body":"","score":2,"comments":[{"body":"- How come you log manually rather than using `log` and `env_logger`\n- How come you use trailing var args rather than an external subcommand?","score":2,"comments":[{"body":"* I wanted a `success!` and `waiting!` with conditional coloring too so I figured I might as well define the others\n* This seemed simplest out of [your suggestions](https://github.com/clap-rs/clap/issues/4428#issuecomment-1295071158) and a good teaching experience","score":1,"comments":[{"body":"Interestingly I published a crate a while ago for basically this reason.\n\n`clout` is for command line output. Let me know if the API would work for you.\n\ncrates.io/crates/clout","score":1,"comments":[{"body":"Oh very cool! Yup we wanted basically the same thing","score":0,"comments":[]}]}]}]}]},{"title":"How to create trait with function that mutates the struct that implement that trait?","not_safe_for_work":false,"locked":false,"body":"I have diffirent types of struct of type 'Register'.\n\nRegister struct contains u8 value, called 'flags'.\n\nEach register has associated enum with it (one enum per bit, so 8 enums in total used for a single register).\n\nEach register has the same 2 functions (only diffirence is type of enum for 'bit' parameter):\n\n    pub fn set(&amp;mut self, bit: ProcessorStatusRegisterBits, value: bool) {\n    \tlet index = bit.value();\n    \tif value {\n    \t\tself.flags |= 1 &lt;&lt; index;\n    \t} else {\n    \t\tself.flags &amp;= !(1 &lt;&lt; index);\n    \t}\n    }\n    \n    pub fn get(&amp;self, bit: ProcessorStatusRegisterBits) -&gt; bool {\n    \tlet index = bit.value();\n    \tself.flags &amp; (1 &lt;&lt; index) != 0\n    }\n\nThe only diffirence is the Enum type: ProcessorStatusRegisterBits.\n\nThis code is duplicated around 6-8 times in my code.\n\n&amp;#x200B;\n\nFor diffirent register, the only thing that changed is the Enum type ('bit').\n\nHow would I go about implement a trait that has 2 functions 'get' and 'set' that do the same thing as above, but so I don't have to duplicate my code for each diffirent enum type?\n\n&amp;#x200B;\n\nExample enum in the example above:\n\n    pub enum ProcessorStatusRegisterBits {\n    \tCARRY,\n    \tZERO,\n    \tINTERRUPT_DISABLE,\n    \tDECIMAL,\n    \tBREAK,\n    \tUNUSED,\n    \tOVERFLOW,\n    \tNEGATIVE\n    }\n    impl ProcessorStatusRegisterBits {\n    \tfn value(&amp;self) -&gt; usize {\n    \t\tmatch *self {\n    \t\t\tCARRY \t\t\t\t=&gt; 0,\n    \t\t\tZERO \t\t\t\t=&gt; 1,\n    \t\t\tINTERRUPT_DISABLE \t        =&gt; 2,\n    \t\t\tDECIMAL \t\t\t=&gt; 3,\n    \t\t\tBREAK \t\t\t\t=&gt; 4,\n    \t\t\tUNUSED \t\t\t\t=&gt; 5,\n    \t\t\tOVERFLOW \t\t\t=&gt; 6,\n    \t\t\tNEGATIVE \t\t\t=&gt; 7\n    \t\t}\n    \t}\n    }\n    pub struct ProcessorStatusRegister {\n    \tflags: u8\n    }\n\n&amp;#x200B;","score":1,"comments":[{"body":"Your `bit` type would be an associated type of the trait.\n\nSomething that could work:\n```\ntrait Register {\n    type Bit;\n\n    fn get(&amp;self, bit: Bit) -&gt; bool;\n    fn set(&amp;mut self, bit: Bit, value: bool);\n}\n```\n\nSide notes:\n\n- enum variants are typically written in `PascalCase` and not in `COBRA_CASE`. If you use Clippy it'll warn you about it.\n- You don't need to manually write this `fn value` function for your enum. Just annotate it with `#[repr(u8)]` and then (I believe) you can safely do `my_enum as usize`.","score":1,"comments":[{"body":"Thanks for your points.\n\nHowever, I would still need to implement the same function over and over again, even though its the same logic.","score":1,"comments":[{"body":"Wait, you have 6-8 different register structures that all just have a `flags` field?\n\nMaybe you could have only one `Register` struct, and use the newtype pattern if necessary?\n\nThe newtype pattern is making a struct that just wraps around another one: `struct SpecificRegister(Register);`","score":1,"comments":[{"body":"Wow, thanks! I'll read about that.\n\nYes, I have 8 different registers, their logic is exactly the same, only the name is diffirent (and their bit flags). Wrapping struct is exactly what I need :)","score":1,"comments":[]}]}]}]}]},{"title":"YTerMusic 0.0.6 - A full rust Youtube music TUI with local music caching for offline use.","not_safe_for_work":false,"locked":false,"body":"","score":100,"comments":[{"body":"Actually usefull and cool looking, nice ! Good job","score":11,"comments":[{"body":"Thanks 🙏 if you have any suggestions on how to improve ytermusic reach out!","score":8,"comments":[]}]},{"body":"Super nice! I was wondering how to deal with YT music's API for a project of mine so this will definitely be very helpful :)","score":10,"comments":[{"body":"Maybe I'll improve to make the API crate publicly available so there is an easy way of using YouTube music api","score":10,"comments":[{"body":"That sounds like a neat idea. If I ever find myself building a project where I need to make an API for something, chances are I'd make the API a separate crate and include it as a library in the main project. That way, it's ready for use out-of-the-box for anyone who needs an API with a similar functionality.","score":6,"comments":[{"body":"Technically it is already the case. But the API is kind of raw and only supports things I use so I don't have to maintain unused things. But it people are interested I could improve it.\n\n[https://github.com/ccgauche/ytermusic/tree/master/ytpapi](https://github.com/ccgauche/ytermusic/tree/master/ytpapi)","score":6,"comments":[]}]},{"body":"saving post just for this! you're a godsend","score":3,"comments":[]}]}]},{"body":"awesome...I am making a gui music player and want to allow ability to play from YouTube... particularly want to allow shuffling a particular users channel. Great work here","score":4,"comments":[{"body":"Thanks! I haven't implemented radios from channels but will in the future for sure. Don't forget to give your impressions and ideas to improve it and star the repo :)","score":4,"comments":[]}]},{"body":"Looks awesome👏👏","score":3,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"The author of the Mold linker has created a website to buy a non-AGPL version of the mold linker and is considering to change macOS Mold to a source-available license","not_safe_for_work":false,"locked":false,"body":"","score":269,"comments":[{"body":"We have allowed several threads about this topic recently, which would already be a bit of a stretch for topics that were inarguably relevant to Rust, let alone projects like Mold which, while useful, are only tangentially relevant to Rust. In general we cannot support such a quantity of threads for every decision made by every project that any Rust user might be interested in.\n\nI will allow this thread, but please let this be the last Mold-related thread for quite a while.","score":1,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"The name of the commercial version is both hilarious and on point","score":146,"comments":[{"body":"What did they settle on?","score":21,"comments":[{"body":"`sold` ;)","score":104,"comments":[]}]}]},{"body":"Some other recent `mold` news is that [Uber is pitching in some money now](https://twitter.com/rui314/status/1593464571586830336).\n\nThe current price of `sold` is actually pretty affordable too. With a software company obviously looking puppy eyed at enterprise users i was expecting it to be way out of a normal person's price point, but no, it's eight or ten bucks per user per month lol, even for business. People pay more than that for stuff on Patreon all the time and at this time there's no license keys or crap to manage either. It's low enough that I don't know if that's enough $ to meet his goals, but I imagine he's thought about it for a bit.","score":109,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"From Mold v1.7.1 release notes:\n\n&gt;My comment in the last release notes about a possible license change caused an overwhelming response. Thank you guys for taking care of the software and its ecosystem. We will reconsider our plan based on the feedback. We may still want to change the license of mold/macOS, but we are not going to change the license of mold/Unix at least in a next few releases.  \n&gt;  \n&gt;On this occasion, I want to say something. We are not a big evil corp who are trying to squeeze as much money as possible from users. This is mostly a one-person project, and what we are trying to do is to create better tools and make them publicly available to improve programmers' productivity worldwide. If you think of the number of developers who are using compiled languages and how many person-minutes we can save every year with better tools, the sum is a huge saving. We'd like to get a small chunk of it as a return. I believe we are doing good job at creating better tools but struggling to establish a way to get a return from it.  \n&gt;  \n&gt;Please keep in mind that there are always people behind an open-source project. Some feedback to my comment were honestly too harsh and disrespectful. Open-source is as much as about people as it is about software. Please respect each other even if you have a different opinion.  \n&gt;  \n&gt;By the way, for those who wish to obtain a copy of the mold linker in a different license than AGPL, we finally set up our company web site. You can purchase a license of the \"sold\" linker (which is a rebranded mold linker) using credit card. Unlike mold, sold is available under a usual per-user, per-month license. We believe this is a good option for some organizations, so please visit our website at bluewhale.systems to check it out.","score":90,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"I think having mold Linux be foss and mold macOS/windows be paid enterprise is a good compromise.\n\nIt reminds me of docker and docker desktop. Only the development tools require a corporate license cause the ci/prod environments are almost definitely Linux","score":55,"comments":[{"body":"Especially since the default macOS linker has a reputation for being slow.","score":16,"comments":[]},{"body":"And that’s exactly why more and more people are migrating to podman","score":27,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"I suppose the same would be true for mold for Windows?","score":6,"comments":[]},{"body":"","score":0,"comments":[]}]},{"title":"EDOM, an immediate mode web frontend library written in Rust","not_safe_for_work":false,"locked":false,"body":"As I was looking at what web frameworks are available for Rust, I fell in love with the simplicity of EGUI, an immediate mode GUI, as it has direct access to all Rust variables similar to how I can access Javascript variables in Svelte, even though the two systems work very differently under the hood.\n\n&amp;#x200B;\n\nAs an experiment in the past weeks I was working on a web frontend framework that mimics the immediate mode by creating a vdom. I already made enough optimizations to make it as fast as yew (although yew is not the fastest Rust web framework), but I have a lot of ideas for improvements. Still, I'm more interested in what the Rust community thinks and feels about this direction for developing software for the web.\n\n[https://crates.io/crates/edom](https://crates.io/crates/edom)","score":27,"comments":[{"body":"This looks like a great alternative API for a Rust VDOM library! I like the ergonomics. \n\nA few comments:\n1) Your get_attribute is going to panic on things with a \"value\" that are not input elements (for example, a select?)\n2) I’d recommend string interning for tag names and attribute names at least, as the cost of copy these over from Wasm to JS is pretty high\n3) I’m curious how this would scale to larger applications… VDOM libraries typically minimize the scope of what has to be diffed by memoizing along component boundaries, but I’m not sure how that would work here.\n4) The js-framework-benchmark run you have posted in your Readme is pretty sus. If you compare it to the official results, you’ll see that yours has vanillajs much slower, Wasm-bindgen much faster, Yew faster, Sycamore and Dominator reversed, and an old version of Sycamore. As someone who’s spent a LOT of time with this benchmark that raises both eyebrows for me. I’d suggest submitting to the actual benchmark and posting official results, or making sure your results are at least vaguely similar to the actual results, before using them to make claims about performance.\n\nEdit: one more on the benchmark— not having looked in too much detail I wonder whether yours might actually fall into the non-keyed category? ForEach seems like it might be diffing by index? If so you should know these perform very differently than the keyed ones and are kind of apples to oranges for the benchmark comparison.","score":4,"comments":[{"body":"Thanks for the comments!\n\n1. You're right, that's a bug, I'll fix it.\n2. Thanks, I was thinking about it, but didn't know how important it is. Generally the same code runs 10x slower in the browser for me than in the unit test benchmark suite, and I'm not yet good at debugging wasm\n3. The VDOM implementation has this data structure (in vdom.rs):\n\n&amp;#8203;\n\n    \n    pub enum Node&lt;EN&gt; where EN:dom::ElementNode {\n        Text(Rc&lt;String&gt;, Option&lt;EN::TextNode&gt;),\n        Element(Element&lt;EN&gt;),\n        ForEach(Vec&lt;(u64, Element&lt;EN&gt;)&gt;),\n        RenderIfElement(RenderIfState, Element&lt;EN&gt;)\n    }\n    \n    #[derive(Clone, PartialEq)]\n    pub enum RenderIfState {\n        NotRendered,\n        Hidden,\n        Visible\n    }\n\nVisitor:: render\\_element\\_if function is doing conditional rendering with a callback. First if rendering is turned off, the element is in NotRendered state. Then it gets to Visible, after that Hidden (which means that the DOM nodes are kept).\n\nIt's a simple wrapper function to destroy the DOM elements when the state changes to Hidden, so having 1000 conditional rendering in the code wouldn't be a problem at all.\n\n4. The benchmark is here:\n\n[https://github.com/adamritter/js-framework-benchmark/tree/release](https://github.com/adamritter/js-framework-benchmark/tree/release)\n\nIt's a fork of the  krausest benchmark. I was running it on my M1 laptop. I'll submit it, but I had to wait for a cargo version that I can reference before I could submit to the benchmark. It used old versions of other frameworks, that's why I compared with them, but you're right that it's only fair to compare with newer ones.\n\n\\+1 The    ForEach(Vec&lt;(u64, Element&lt;EN&gt;)&gt;) node type uses 64 bit hashes as an index for keyed enumeration (64 bit could be changed to 128 bit, but for 10-50k items the chance of collision is very low). A part of the todo list that shows how to use it:\n\n                ul.for_each(todolist.iter_mut(), |item| item.id, \"li\", |item,li| {\n                    li.style(\"display: flex; ; margin: 0; padding: 0;\");\n                    li.checkbox(&amp;mut item.done);\n                 }\n    \n\nAs you can see you can use mutable iterators and change the todo items on-the-fly.","score":2,"comments":[{"body":"Thanks for the detailed reply! I was assuming the u64 was an index but the hash makes more sense.","score":2,"comments":[]}]}]},{"body":"How exactly did you manage to make the DOM immediate mode? Do you build an entire new tree every frame?\n\nThe point of immediate mode GUIs is that you control the renderer, so you simply re-render the state every frame, which you'd already be doing anyway in a game, or other soft-real-time application, and in modern GPU pipelines this comes down to updating a few uniform variables, which is very fast.\n\nThe DOM is naturally a retained mode UI, and there are a lot of steps between building the tree and it being rendered (parsing stylesheets, calculating layouts, transforming layouts into geometry, building the GPU buffers for this geometry, etc) so replacing the tree every frame would require the browser's renderer to do all that redundant work every time. That's why reactive frameworks focus most of the work into finding the minimal sub-tree to replace.\n\nThis looks like a cool learning project, but unfortunately, I don't think you'll be able to make it efficient without turning it into another reactive framework, not immediate mode.","score":6,"comments":[{"body":"The questions are great, it builds a tree only in the first frame, then updates it by having 1 VDOM for comparision to minimize the DOM operations. I know it's not the same as having a GUI output, so it's a hybrid between immediate mode and reactive mode, I don't know the exact name for it.\n\nAbout the performance, I knew that that is the hardest part, so I tried to minimize the number of memory allocations while building the framework. I was fighting lifetimes for a week, trying to understand how I can efficiently have recursive datastructures with references. I still have many things to do, but I got to a point where it's faster than yew in the geometric average of the js benchmark (I updated [https://github.com/adamritter/edom](https://github.com/adamritter/edom) ).\n\nAll tags are passed as static string references, the strings are reference counted, so if you have a table of many rows, no new strings are created in the clones of the tree rows. Also the DOM nodes are cloned with deep\\_clone and then attached only when necessary.\n\nThere are still lot of optimizations to make to get the right mix of bump allocation and changability, but I think the current speed is good enough for production use, and stability and ergonomics of the system is as important as speed.\n\nIf you look at the code example, it's an exact copy of the EGUI demo, that's why I was brave enough to call this immediate mode, even though you are right (it's a hybrid). I think it's much easier to use than message passing and callbacks that other frameworks do:\n\n```\nuse edom;\nuse wasm_bindgen::prelude::wasm_bindgen;\n\n#[wasm_bindgen(start)]\npub fn demo() {\n    let mut name = \"Arthur\".to_string();\n    let mut age:f64 = 42.0;\n    edom::wasm::render(move |mut root| {\n        root.h1().text(\"My edom application\");\n        root.div(|div| {\n            div.text(\"Your name: \");\n            div.text_input(&amp;mut name);\n        });\n        root.div(|div| {\n            div.range_input(&amp;mut age, 0.0, 120.0);\n            div.number_input(&amp;mut age).min(0.0).max(120.0);\n            div.text(\"age\");\n        });\n        if root.button(\"Click each year\").clicked() {\n            age+=1.0;\n        }\n        root.br();\n        root.text(format!(\"Hello '{}', age {}\", name, age).as_str());\n    });\n}\n\n```","score":3,"comments":[{"body":"Fixed formatting for you (for old reddit):\n\n    use edom;\n    use wasm_bindgen::prelude::wasm_bindgen;\n\n    #[wasm_bindgen(start)]\n    pub fn demo() {\n        let mut name = \"Arthur\".to_string();\n        let mut age: f64 = 42.0;\n        edom::wasm::render(move |mut root| {\n            root.h1().text(\"My edom application\");\n            root.div(|div| {\n                div.text(\"Your name: \");\n                div.text_input(&amp;mut name);\n            });\n            root.div(|div| {\n                div.range_input(&amp;mut age, 0.0, 120.0);\n                div.number_input(&amp;mut age).min(0.0).max(120.0);\n                div.text(\"age\");\n            });\n            if root.button(\"Click each year\").clicked() {\n                age += 1.0;\n            }\n            root.br();\n            root.text(format!(\"Hello '{}', age {}\", name, age).as_str());\n        });\n    }","score":4,"comments":[]},{"body":"Interesting approach, thanks for explaining.","score":3,"comments":[]}]}]}]},{"title":"Calling Apple built-in (Swift) APIs from Rust","not_safe_for_work":false,"locked":false,"body":"So I've looked at a few of the Rust/Swift bridging libraries and found lots of examples of how to invoke \\_my own\\_ Swift code from Rust, but that isn't what I want to do.\n\nI just want to call \\_Apple\\_ Swift APIs from Rust. Is there an example for how to do that?","score":11,"comments":[{"body":"There is [https://github.com/SSheldon/rust-objc](https://github.com/SSheldon/rust-objc) which is abandoned.\n\nAs far as I know, [https://github.com/madsmtm/objc2](https://github.com/madsmtm/objc2)  is the most active fork.","score":0,"comments":[]}]},{"title":"How does serde_json work?","not_safe_for_work":false,"locked":false,"body":"Hi guys,\n\nI was using serde_json to implement some stuff, however I was wondering how it worked internally. For example, in here\n\n    #[derive(Serialize, Deserialize)]\n    struct Person {\n        name: String,\n        age: u8,\n        phones: Vec&lt;String&gt;,\n    }\n    \n    fn typed_example() -&gt; Result&lt;()&gt; {\n        let data = r#\"\n            {\n                \"name\": \"John Doe\",\n                \"age\": 43,\n                \"phones\": [\n                    \"+44 1234567\",\n                    \"+44 2345678\"\n                ]\n            }\"#;\n        let p: Person = serde_json::from_str(data)?;\n    \n        Ok(())\n    }\n\nhow does serde_json know what values to put in the struct automatically? I looked on github but I am still a noob so I have no clue where to look.","score":62,"comments":[{"body":"Great question! So the short version is that it takes a look at the struct (specifically the fields and their names) and generates a `Deserialize` implementation that looks for them. It doesn't actually care about the field types, because `Deserialize` operates recursively, so it simply calls `deserialize` on those fields, which in turn take care of deserializing themselves.\n\n`serde` operates in two halves: the rust data type, which implements `Deserialize`, and the external data format, which implements `Deserializer`. Data is read from the data format by connecting these two halves; this means that any\\* Rust type can be read from any\\* incoming data format. I recently gave [a talk](https://www.youtube.com/watch?v=7pZTYdqXfgY) about how Deserializers work, so here I'll talk about `Deserialize`.\n\nWhen you implement `Deserialize`, the most important thing is that you create a `Visitor`. When you're being deserialized, you'll be given a data source (the deserializer), and you will call that data source with a `Visitor` that you custom generate for your type. So it starts like this:\n\n    // Ignore 'de for now\n    impl&lt;'de&gt; Deserialize&lt;'de&gt; for Person {\n        fn deserialize&lt;D: Deserializer&lt;'de&gt;&gt;(source: D) -&gt; Result&lt;Self, D::Error&gt; {\n            source.deserialize_struct(\n                \"Person\",\n                &amp;[\"name\", \"age\", \"phones\"],\n                PersonVisitor,\n            )\n        }\n    }\n\nWe call `source.deserialize_struct`, to let the deserializer know that we are a struct, containing these fields. For some deserializers that's very important, but for formats like json it actually doesn't really matter, because JSON is very self-describing.\n\nSo, what does the `Visitor` look like? A `Visitor` is a place for a data source to *send* data. It has `visit_` methods for the different types of data that it might receive. Most of them have defaults that return errors, so we can just implement the only one we care about, `visit_map`. Again, a `Visitor` is a *destination* for data from the data source, so when it calls `visit_map`, it is *providing* to us the map data that it's parsing from JSON. A JSON object is arbitrary key-value pairs, which we will be able to extract one at a time from the map.\n\n    struct PersonVisitor;\n    \n    impl&lt;'de&gt; Visitor&lt;'de&gt; for PersonVisitor {\n        type Value = Person;\n    \n        // Used in error message creation\n        fn expecting(&amp;self, f: &amp;mut Formatter&lt;'_&gt;) -&gt; fmt::Result {\n            write!(f, \"a Person struct\")\n        }\n    \n        fn visit_map&lt;A: MapAccess&lt;'de&gt;&gt;(self, mut map: A) -&gt; Result&lt;Person, A::Error&gt; {\n            // This is the most interesting part, it's the code\n            // that #[derive(Deserialize)] generates\n            let mut name = None;\n            let mut age = None;\n            let mut phones = None;\n    \n            #[derive(Deserialize)]\n            #[serde(field_identifier)]\n            enum FieldId {\n                name,\n                age,\n                phones,\n            }\n    \n            // This will have newer keys overwrite older keys,\n            // other behaviors are also possible\n            while let Some(field_id) = map.next_key()? {\n                match field_id {\n                    FieldId::name =&gt; name = Some(map.next_value()?),\n                    FieldId::age =&gt; age = Some(map.next_value()?),\n                    FieldId::phones =&gt; phones = Some(map.next_value()?),\n                }\n            }\n    \n            let name = name.ok_or_else(|| de::Error::missing_field(\"name\"))?;\n            let age = age.ok_or_else(|| de::Error::missing_field(\"age\"))?;\n            let phones = phones.ok_or_else(|| de::Error::missing_field(\"phones\"))?;\n    \n            Ok(Person { name, age, phones })\n        }\n    }\n    }\n\nAnd that's it! The key here is that, when the time comes to deserialize a number (for age) or array (for phones) etc, the specific types will *themselves* implement `Deserialize` and know how to load themselves. All we have to do is load them (that's what `next_value()` is doing) and then build the struct!\n\nThe thing you might have noticed is that I partially cheated and used `#[derive(Deserialize)]` on `FieldId`. Suffice it to say that that's very similar to what's happening here, except that instead of deserializing a struct, it will deserialize a string `\"age\"`, `\"phones\"`, or `\"phones\"` and turn it into the enum. The same idea will apply there, where it will generate a `Deserialize` that calls `source.deserialize_identifier` and a `Visitor` that implements `visit_str`.\n\n\\* In theory, at least. In practice, typically data formats will implement some subset of the full data model.","score":78,"comments":[{"body":"Great answer!\nThanks a lot :)","score":4,"comments":[]},{"body":"","score":0,"comments":[]}]},{"body":"`#[derive(Serialize, Deserialize)]` are macros, specifically derive macros. The the serde library provides the compiler with a small program to run that takes your struct as input and outputs bespoke code that knows about your fields. You can actually write these yourself https://serde.rs/custom-serialization.html which is sometimes useful if you have some wierd data format.\n\nI will warn you that since serde both wants to be both generic over all possible data formats and wants to avoid using intermediate data structures for efficency reasons, it's a bit hard to work out what the implementations that serde produces are doing so if you are new, you might want to wait about before trying to grok them.","score":44,"comments":[]},{"body":"Try installing cargo-expand (`cargo install cargo-expand`) and then running it (`cargo expand`) in your example crate, the same way you'd run cargo check or cargo run or stuff. That'll give you an idea behind the \"magic\" of those derive macros.","score":56,"comments":[{"body":"VSCode + rust-analyzer also has this built in.","score":34,"comments":[{"body":"","score":0,"comments":[]}]}]},{"body":"The answer is already here but I'd like add some more detail - that derive macro will call some rust function at compile time, and it receives the full syntax tree of the struct you're annotating. And this is why it knows about your fields.","score":8,"comments":[{"body":"Technically a stream of tokens, right? I don't think it gets a syntax tree","score":8,"comments":[{"body":"Yes, you're right.  But there is a crate that converts that to a syntax tree :)","score":2,"comments":[]},{"body":"That's kind of nitpicking but that's right. I used \"syntax tree\" here because the idea is more striking in context of the question. I wrote procedural macros, in practice you let syn consume the stream and build the syntax tree for you, except in some occasions where it doesn't fit Rust syntax","score":2,"comments":[{"body":"","score":0,"comments":[]}]}]}]},{"body":"I would say an implementation by yourself is much better than just listening to explanations by others.\n\nYou could try this [lab](https://github.com/pingcap/talent-plan/blob/master/courses/rust/building-blocks/bb-3.md) by PingCAP (write a serde implementation for redis serialization protocol) ; you can find answers/seek help in github if you really don't know how to figure it out.\n\nFor example, my own [solution](https://github.com/dreamerlzl/my-pingcap-talent-plan-solution/blob/main/building-blocks-3/mserde/src/de.rs)","score":6,"comments":[]},{"body":"","score":0,"comments":[]}]},{"title":"CoerceUnsized for custom \"fat pointer\" type?","not_safe_for_work":false,"locked":false,"body":"I'm trying to make a custom \"fat pointer\" type. The purpose of this is to have a pointer where if `T: Foo`, then `FatPtr&lt;T&gt;` and `FatPtr&lt;dyn Foo&gt;` will always have the same size, alignment and memory layout, so that it's safe to transmute `FatPtr&lt;T&gt;` into `FatPtr&lt;dyn Foo&gt;`.\n\nThe way I've implemented this is like this:\n\n    #![feature(ptr_metadata, unsize)]\n\n    use std::marker::{PhantomData, Unsize};\n    use std::ptr::{DynMetadata, NonNull};\n\n    #[repr(C)] // this *guarantees* a stable pointer layout\n    struct FatPtr&lt;T: ?Sized + Foo&gt;\n    {\n        _phantom: PhantomData&lt;NonNull&lt;T&gt;&gt;,\n        ptr: NonNull&lt;()&gt;,\n        metadata: DynMetadata&lt;dyn Foo&gt;,\n    }\n\n    impl&lt;T: Foo&gt; FatPtr&lt;T&gt;\n    {\n        fn new(ptr: NonNull&lt;T&gt;) -&gt; Self {\n            let (ptr, metadata) = (ptr as NonNull&lt;dyn Foo&gt;).to_raw_parts();\n            Self {\n                _phantom: PhantomData,\n                ptr,\n                metadata,\n            }\n        }\n    }\n\nThe problem with this approach is that there doesn't seem to be a way to implement pointer coercion from `FatPtr&lt;T&gt;` to `FatPtr&lt;dyn Foo&gt;`, like there would be for other pointer types. `FatPtr&lt;T&gt;: CoerceUnsized&lt;FatPtr&lt;dyn Foo&gt;&gt;` would need to be implemented, but this in turn requires exactly one _non-phantom_ field that depends on `T` (and similarly implements `CoerceUnsized`), but there are none in `FatPtr&lt;T&gt;`, so I can't implement that. I don't know how it would be possible satisfy the requirements of `CoerceUnsized` while keeping the property that the layout is independent of `T`.\n\nIs there a way to work around this issue? Either with the `FatPtr` type presented here, or with some other represetation of a fat pointer that avoids the issue?","score":17,"comments":[{"body":"Is there a reason you need to be able to do `FatPtr::new(foo) as FatPtr&lt;dyn Foo&gt;`? What if you just provided a function that did the conversation manually instead?","score":1,"comments":[{"body":"If you did, you might need to add a similar conversation function for `Pin&lt;FatPtr&lt;T&gt;&gt;` as well, depending on your use case.","score":1,"comments":[]},{"body":"The `FatPtr` I would have would be inside of another pointer, something like `Arc&lt;Mutex&lt;FatPtr&lt;T&gt;&gt;&gt;`. So it would need to do that conversion inside of another container type.","score":1,"comments":[]}]}]},{"title":"Python style annotations?","not_safe_for_work":false,"locked":false,"body":"I'm an intermediate Rust dev and I'm the type that logs religiously to the point where in Python I had developed a logging annotation that did the bulk of my function logging automatically.    \n\nDoes something like this exist in Rust? Is there perhaps a more eloquent manner to perform functions automatically?","score":0,"comments":[{"body":"Like in `tracing` crate with `#[instrument]` attribute? https://docs.rs/tracing/0.1.37/tracing/#spans-1","score":11,"comments":[{"body":"Honesty, i don't know and that is the reason i asked =)  \nMy thanks, I'll try this and report","score":3,"comments":[]}]},{"body":"What do you actually mean? Do you mean a decorator which logs when functions are called (and possibly terminate)?","score":3,"comments":[{"body":"As a start, but in Python , a decorator is a wrapper function about another function - it is this that I seek.  \n\nI gave an example of what I created with such functions in Python. I'd love to recreate such functions but there are so many use cases.","score":1,"comments":[{"body":"If you're looking for something similar to Python's decorators in functionality, the closest equivalent in Rust would be procedural macros (specifically attribute macros). Unlike Python, these run at compile and only deal with syntax, but you can use them to wrap a function in some custom logic, among other things. This is what the `#[instrument]` macro mentioned in another comment does.","score":3,"comments":[]},{"body":"There are procedural macros, which convert the code of a function to something else (perhaps inserting logging calls before and after it runs). There is no direct analogue to a wrapper function because it's not as powerful and not needed.","score":1,"comments":[]}]}]}]},{"title":"Learning Rust from C and Java?","not_safe_for_work":false,"locked":false,"body":"I just got accepted in an internship where I'll have to program in Rust. I told them I only knew C (not C++) and Java, zero experience with Rust, but that I was willing to learn. Now that I got accepted, I'm kind of worried since is my first internship... How long will it take me to learn Rust? where should I begin? I don't want to go there and them to realized I'm incompetent and know nothing","score":60,"comments":[{"body":"First of all, congratulations on getting your first internship. Most companies don't really rely on interns for critical work. Rather, treat it like a long winded interview for a full time position. Learn all that you can, be open and willing to take feedback, try your hardest, and while you're still an intern don't forget to have a little fun too. If you do that, you will almost surely get invited back again.","score":99,"comments":[{"body":"All that \\^\\^ and if you want to get a head start on things start reading through [the rust book](https://doc.rust-lang.org/stable/book/). If you know C that will help a bit with rust - especially if you have come across the concept of ownership before which is very useful in C though not often explicitly taught.","score":29,"comments":[]}]},{"body":"Internships aren't really there to be productive, they're meant for the intern to learn company culture and some basic technical stuff, and for the company to assess the intern for future employment.\n\nSo, don't get stressed if you aren't proficient with Rust immediately, that's not the point. It takes quite a while to get to that level with it, because it requires a way to thinking other programming languages don't, especially concerning ownership of data.","score":13,"comments":[]},{"body":"If you knew C and Java, i think you are best fit to learn rust. C doesn’t have GC and Java do so you will understand how rust resolves some of the memory related problems during compile time. Start with Rust book like others suggested and keep doing hands on. I’m sure you will do good. Good luck and Congratulations.","score":30,"comments":[]},{"body":"You can try some exercises to get a feel for everything. \n\nhttps://github.com/rust-lang/rustlings\n\nhttps://doc.rust-lang.org/rust-by-example/index.html\n\nOr https://exercism.org/tracks/rust\n\nOr just play around on the playground. No need to dive into everything.\n\nhttps://play.rust-lang.org/","score":9,"comments":[]},{"body":"&gt; How long will it take me to learn Rust?\n\nNot long to make changes to the code base.  if statements are if statements.  functions are functions. Match is very similar to switch, traits are similar enough to interface... you'll catch on pretty quickly.  C and Java and Rust are similar enough that only 10% of the syntax will look alien.\n\nRust doesn't have OOP, but neither does C (I mean, you can hack in some OOP like the Linux Kernel does, but its \"not great\"(TM)).  Rust trait system can be thought of as an inbetween between no-OOP like C, and full OOP like Java... you'll eventually realize that this is an incorrect statement, but its a good enough abstraction to get you started and learn the nuance later.\n\n&gt; where should I begin?\n\nAdvent of Code is coming up... I'd suggest doing it in Rust\n\n&gt; I don't want to go there and them to realized I'm incompetent and know nothing\n\nThey already realize you're incompetent and know nothing.  You're an intern, and you explicitly told them you don't know Rust.  They do not expect you to be a 20 year Senior Dev who has written Rust since version 0.9.  Your understanding of C and Java gives them enough confidence to risk that you can catch on quickly enough.","score":8,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"Congrats on the internship! Wish I got to use Rust for mine. \n\nAs a bare minimum, I recommend the following:\n1.\tRead the book: https://doc.rust-lang.org/stable/book/\n2.\tWatch as many [Crust of Rust](https://youtube.com/playlist?list=PLqbS7AVVErFiWDOAVrPt7aYmnuuOLYvOa) videos as you can. These videos are long, but so so worth it for understanding the intermediate to advanced Rust concepts.\n3.\tDo a mini project by translating some code in another language into Rust. Would recommend the first book of https://raytracing.github.io/. Bonus points if you use Rayon.\n\nParts 2 and 3 can be done in parallel if you want to escape tutorial hell, but would recommend going back and improving 3 if you decide to do it before watching Crust of Rust.\n\nRust is a super fun language and will change the way you think about programming. Good luck, and have fun!","score":9,"comments":[]},{"body":"You'll be fine. The best way to learn it is to be thrown into a codebase, so congrats! I would recommend going through the book and then rustlings; that'll get you started, and then you can continue learning by reading and writing code and having your code reviewed.","score":3,"comments":[]},{"body":"As someone who's had interns before and been the onboarding contact for a bunch of junior engineers, don't worry about it.  We're not expecting you to know everything; even if you tried as hard as possible there's always some random things that the company does that isn't written down anywhere even *internally*.  My favorite example: when I was a junior I send a code review that used `open_file` thinking that'd be fine, but no, I was told I needed to use `get_temp_file_byte_stream_2`.  Nobody was mad at or disappointed in me for not knowing that.  The \"well this is kinda silly but you need to ...\" vibe was obvious.\n\nYou're an intern; you're there in large part to learn and we know that.  I *expect* there's lots of stuff that's new to you.  You'll get loads of PR feedback for the first bit, but that shouldn't discourage you.  I promise we don't mind.\n\n(If we have to tell you exactly the same thing in PRs for seven weeks in a row, *then* I start to mind.  But once or twice before you start to grok it is totally normal.)","score":3,"comments":[]},{"body":"The best way to learn is to use it. Well, after having learned the basics from the already linked Rust book.\n\nYou have learned enough when you have rewritten your projectes thrice, always realizing there was a better way to do it ;).","score":5,"comments":[]},{"body":"","score":0,"comments":[]}]},{"title":"Display file with syntax highlighting","not_safe_for_work":false,"locked":false,"body":"Using rocket, I want to display file content with syntax highlighting\n\nTo display the file, I am doing:\n\n    use rocket::tokio::fs::File;\n    #[get(\"/&lt;id&gt;\")]\n    async fn retrieve(id: PasteId&lt;'_&gt;) -&gt; Option&lt;File&gt; {\n        File::open(id.file_path()).await.ok()\n    }\n\nMy idea is to show syntax highlights if the user uploads a script.\n\nHow would I go about doing this?","score":0,"comments":[{"body":"I think there are two ways, but in either case, you will need to send proper html, not just file directly.\n\nOne way is to do it server-side. You would need to somehow parse the file, then generate html with proper structure for syntax highlighting.\n\nOther way is to find and use javascript library that automatically does syntax highlighting. You would then send html with your code and the js library.","score":7,"comments":[{"body":"&gt; One way is to do it server-side. You would need to somehow parse the file, then generate html with proper structure for syntax highlighting.\n\nI recommend this because I hate sites that require JavaScript for things that don't fundamentally need it (unlike, say, an in-browser paint tool using `&lt;canvas&gt;`) and because it means you can do it once and cache it for everyone, saving on resources.\n\nFor doing this, there's the [syntect](https://lib.rs/crates/syntect) crate, which has built-in support for HTML output.","score":3,"comments":[]}]}]},{"title":"Learning Embedded rust","not_safe_for_work":false,"locked":false,"body":"I want to learn embedded rust. My target is to use rust instead of C++ to develop embedded project with Arduino and probably Raspberry Pi in the future. I only have Arduino Uno for now.\n\nMy goal is to make embedded gardening/farming system that will be controlled by F#/C# with dotnet. I am learning F# for now. But I found a promising cross platform UI that I think is easier to code \"AvaloniaUI\".\n\nBut for the embedded systems I want to use rust because it's lightweight and efficient, while I can use dotnet to code a GUI that will be easier for me, I think. I am following some tutorials to get started.\n\n**Long story short,**  \n**Can you point any materials that will help me to learn embedded rust in detail?**\n\nThanks.","score":21,"comments":[{"body":"https://docs.rust-embedded.org/book/","score":14,"comments":[{"body":"Thank you.","score":2,"comments":[]}]},{"body":"Embedded rust for the raspberry pi pico: https://github.com/rp-rs/rp-hal\n\nEmbedded rust for the arduino boards: https://github.com/Rahix/avr-hal\n\nAsync embedded rust: https://github.com/embassy-rs/embassy","score":6,"comments":[]},{"body":"Support for the Atmega328 on the Uno is not great. I’d buy a couple of Raspberry Pi Picos instead.","score":1,"comments":[]}]},{"title":"Hyperpom: An Apple Silicon Fuzzer for 64-bit ARM Binaries, written in Rust","not_safe_for_work":false,"locked":false,"body":"","score":62,"comments":[{"body":"I have nothing of value to add but I read \"hyperporn\" and was curious as to what that could possibly be","score":28,"comments":[{"body":"Same","score":3,"comments":[]},{"body":"Me too.","score":1,"comments":[]}]},{"body":"The advantage over `cargo-fuzz`/`libfuzzer` is that you can fuzz binaries that you do not have the source code for. `afl` can do this via QEMU but at the cost of something like 10x slowdown. \n\n`honggfuzz` has experimented with hardware-assisted fuzzing for black-box binaries at near-native speeds, but only on Intel CPUs.","score":12,"comments":[]}]},{"title":"Rust GUI library for video playback?","not_safe_for_work":false,"locked":false,"body":"I've got an idea for a video editor. There are lots of new Rust GUI libraries out there. Is there anything special I need to consider for video? Any recommendations?","score":26,"comments":[{"body":"[gstreamer](https://gstreamer.freedesktop.org/) is also a mature media processing and integration solution with [excellent rust support](https://lib.rs/crates/gstreamer). \n\n&lt;https://en.wikipedia.org/wiki/GStreamer&gt;","score":13,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"To do video *properly* requires integration with the platform compositor. This is a fiendishly difficult problem, and I know of no serious effort to solve it. I have an [outline of a blog post](https://github.com/raphlinus/raphlinus.github.io/issues/77) on the topic, and hope to publish it before too long.\n\nThere are two workarounds that might do in the mean time. One is to use subwindows rather than the compositor. The other is to decode the video into GPU textures, and do compositing in the drawing library. Neither is especially straightforward, and you still have to deal with synchronization with audio and other similar problems.","score":13,"comments":[]},{"body":"Yes, have fun binding to ffmpeg.\n\nIf you want to import/export as many formats as possible you'll need ffmpeg, and if you want to bind to ffmpeg on as many platforms as possible you'll need luck.\n\nHere's how i did it on windows:\n- Use `ffmpeg-next`.\n- Download &amp; extract the \"full shared\" build of ffmpeg from [gyan.dev](https://www.gyan.dev/ffmpeg/builds/) - yes, **exactly** that one. I've tried a lot of them.\n- Use the MSVC toolchain. It might work on gnu, I haven't tested it.\n- Add the following to your [cargo configuration](https://doc.rust-lang.org/cargo/reference/config.html), for example by creating a file `$PROJECTDIR/.cargo/config.toml`:\n```\n[env]\nFFMPEG_DIR=\"C:/path/to/your/ffmpeg-5.1.2-full_build-shared/\"\n```\n- If it still does not work, also try building from git-bash. Don't ask why, probably some black quotation magics.","score":15,"comments":[{"body":"If you go this way, you'll have to decode video through the FFmpeg API which is not as simple as it is via the ffmpeg CLI. Check out [av-metrics-decoders](https://github.com/rust-av/av-metrics/tree/master/av_metrics_decoders), they have a simple, working decoder implementation.","score":3,"comments":[{"body":"Surprisingly, the CLI is how most app interface with ffmpeg. You'd think that would be a problem, but it's surprising versatile.","score":2,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"I found egui performance to not be great for showing a sequence of frames at 30 or 60fps. You can do it on higher end machines, but it uses a lot more CPU time than other approaches, like direct opengl rendering to a texture.\n\nWhat other requirements does your program have? Egui, iced, and possibly others have a restriction that you can only have one native window per process. You can use something like `ipc-channel` to work around this. And I started to work on a proof of concept but depending on which gui libraries you pick it may turn out to be nearly impossible to coordinate their event loops. I was trying it out with a combo of winit and druid, but I couldn't find a good way to insert messages from the ipc-channel into the druid events. However, I may have given up too soon.\n\nThe thing I'm currently exploring is just using gtk. I have a GLArea hookup to glium (look in the gtk4 examples if you want to see how it's done, I'm just using their example code directly). The major drawback issue to using gtk is distribution. I've been fighting with that for the last week. Trying to build a correct app bundle for macOS and a correct zip file for windows (I haven't started on that yet). The nice thing about gtk is you can develop your UI once and have it work on other platforms, but distributing your app becomes a pain.\n\nThe nice thing about egui is the API. It's really really pleasant to program in. Initially I had a lot of trouble getting things to layout the way I wanted but you eventually figure it out. It helps to read the egui source code as their docs are a bit light still. But the things I didn't like about egui are the performance and the restriction to one native window. The one native window restriction also means when you make a right-click menu it will get clipped to the window and can't be drawn outside of it because it's just being rendering inside that window using some opengl.\n\nI think a bunch of the other ones like iced are similar to egui in that they have the one window restriction as well.\n\nwinit has a lot going for it if you're rendering just tiny bit of UI elements. It has a way to do right-click menus (although, no examples of how to use that API yet). It can do multiple windows as well. And there are examples of how to combine winit with iced. So that way you can use iced to draw some widgets on top of your opengl canvas. So you could do like a volume slider and a scrubber as an iced overlay. These examples might help you:\n\n  * https://github.com/rust-windowing/winit/blob/master/examples/multiwindow.rs\n  * https://github.com/iced-rs/iced/tree/master/examples/integration_opengl\n\nIf you did the work to combine those two examples you could have one window in the app that uses winit and renders opengl (possibly with the widgets I mentioned) and some number of other windows that can be used for showing things like codec details or whatever.\n\nIt's a bit of a pain to learn how to combine them, but if I were in your situation that's probably the path I would go down. In fact, I may scrap this whole gtk endeavor and revisit that myself for the app I'm working on. We'll see.","score":4,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"I used `egui` for a computer vision project, but i had to abuse an image widget by changing image every frame (probably not too different from what happens in a normal video player, i guess), and i didn't have problems. Granted, it was a bit \"manual\", but also pretty short to write, and for all the rest egui was really nice to use. Also consider that i only handled video at smallish resolutions (720p, maybe 1080p), but i don't think there should be problems even at higher resolutions.","score":2,"comments":[{"body":"I tried something like this recently with a speedrun timer I'm making. The livesplit core libraries are written in Rust and have a software renderer. So I call that at some user defined fps like 30 or 60. I found that it was \"fine\" on my dev machine, but when I gave it to friends to run, it really bogged down their computers. I did a bunch of manual profiling with timers and discovered that the way egui (this was egui 0.18, dunno if 0.19 improves it) does images it was doing a bunch of cpu-side image processing and then allocating new copies.\n\nI ended up using some egui backdoors to drop down to the opengl layer and wrote a some code in glow that just copied the image into a texture and put it on a quad. This was a massive speedup. I've since rewritten my app to use gtk for the opengl rendering and it's even faster.\n\nSo while you can do this stuff in egui and while egui is a pleasure to program in, I don't think I can recommend it. egui (which is still pretty new) just doesn't have the performance at the moment.","score":2,"comments":[{"body":"It's not the fault of `egui`!\n\nThis kind of task has to be done by **OpenGL overlays** or similar HW accelerated solutions. Everything else looks more like  amateurish toying around to me.\n\nBut I somehow agree, that `egui` could benefit a lot from some media player related widgets and code examples demonstrating efficient video processing and display.\n\nNevertheless, it's rather hard to realize sufficient video display in a platform independent manner and also hard to maintain over longer periods of time. That's why you usually do not find this kind of components in common GUI libs.\n\nbtw:\n\nThe [embeddable](https://github.com/mpv-player/mpv-examples/tree/master/libmpv) display engine of [mpv](https://mpv.io/) is perhaps one of the most complete solutions to work around all those video related rendering issues on computer monitors. I don't know if anyone already developed nice rust interfaces for it?","score":2,"comments":[{"body":"&gt; It's not the fault of egui!\n\nI understand your point, but I can't fully agree. The gtk opengl canvas version is still about 3x faster than my fastest egui version (which also just renders to an opengl canvas). And that version isn't even rendering egui widgets during my benchmark. There's some non-trivial cost involved with using egui that I personally found unacceptable for my project.","score":2,"comments":[{"body":"","score":0,"comments":[]}]}]}]}]}]},{"title":"What they don't tell you about the diesel crate","not_safe_for_work":false,"locked":false,"body":"MySql is a second-class citizen. You learn that in quite a painful way. Postgres is much easier to implement because it is a first-class citizen. MySql requires a lot of figuring out methods for CRUD and query. None of them are apparent when you start.","score":0,"comments":[{"body":"Diesel in general requires some effort to figure out how things work. If it’s giving you a hard time then why not look for better crates?","score":1,"comments":[]}]},{"title":"Struggling to create a function that receive a Read and return a Peekable&lt;Iterator&lt;Item=char&gt;&gt;","not_safe_for_work":false,"locked":false,"body":"I'm trying to create a function that receive a `Read` and return a `Peekable&lt;Iterator&lt;Item=char&gt;&gt;`.\nBut I'm totally lost how can I satisfy this return type.\n(The purpose is just learning Rust, so I don't want to use any external crate to do the job)\n\nAs `Iterator` is not a `Sized` I need to make it as a reference\n```rust\nfn test1(reader: &amp;mut dyn Read) -&gt; Peekable&lt;&amp;mut dyn Iterator&lt;Item = char&gt;&gt;\n```\n\nBut if I do so, when I create the `char_it` it not lives long enough\n```rust\nfn test1(reader: &amp;mut dyn Read) -&gt; Peekable&lt;&amp;mut dyn Iterator&lt;Item = char&gt;&gt; {\n    let bytes = reader.bytes();\n    let char_it: &amp;mut dyn Iterator&lt;Item = char&gt; = &amp;mut bytes.map(|f| f.ok().unwrap() as char);\n    let char_pk: Peekable&lt;&amp;mut dyn Iterator&lt;Item = char&gt;&gt; = char_it.peekable();\n    return char_pk;\n}\n\n# cannot return value referencing temporary value\n# returns a value referencing data owned by the current function\n```\n\nIf I return by value, I don't have Idea what should be the return type.\n```rust\nfn test1(reader: &amp;mut dyn Read) -&gt; Peekable&lt;&amp;mut dyn Iterator&lt;Item = char&gt;&gt; {\n    let bytes = reader.bytes();\n    let char_it = bytes.map(|f| f.ok().unwrap() as char);\n    let char_pk = char_it.peekable();\n    return char_pk;\n}\n\n# expected struct `Peekable&lt;&amp;mut dyn Iterator&lt;Item = char&gt;&gt;`\n# found struct `Peekable&lt;Map&lt;std::io::Bytes&lt;&amp;mut dyn std::io::Read&gt;, [closure@src/main.rs:13:29: 13:32]&gt;&gt;`\n```\n\nCan someone give me some direction how can I make it work.\nThank you in advance","score":1,"comments":[{"body":"Try changing `&amp;mut dyn Iterator&lt;Item = char&gt;` to `impl Iterator&lt;Item = char&gt; + '_`\n\nBut also, if you're trying to decode utf8 in a stream, this won't work, you're just casting each byte to an extended-ascii char. you'd have to make a custom Iterator with a custom 4-bytr long peek buffer to do that, if that is what you're trying to do.","score":3,"comments":[{"body":"Worked like a charm! Thank you !\n\nI will study about the difference between impl and dyn.\n\n&amp;#x200B;\n\nAbout the decoding, I will only receive ASCII chars, so I don't need to worry about it\n\nThank you once again!","score":1,"comments":[{"body":"Summary:\n\n&amp;#x200B;\n\nTraits: As you surely know already, Structs can implement (0-n) traits. When a struct has a trait, it is guaranteed that it has ertain methods that the trait specifies. However, traits are not instancable by themselves. With a struct S, you can have any number of instances of S, but no instances of a trait T because traits are just \"behaviour contracts\" for structs.\n\n&amp;#x200B;\n\nReferences, just as local variables: Obviously, with a var1 of type S (S being a struct), making references \"&amp;var1\" (type &amp;S) or \"&amp;mut var1\" (type &amp;mut S) is possible. It is important that these references are only usable as lng as var1 itself exists; but in \"safe\" code, it won't happen that you mistakenly keep a reference for longer than the data itself. This also means, when you have a local variable inside of a function, returning a reference of it is bad (error), because as soon as you return the local variable is gone and the reference invalid.\n\n&amp;#x200B;\n\nTrait references (trait objects) as local variables: For this paragraph, S1 and S2 are different struct types that both implement a trait T. As said above, with a trait T, you can't have instances like \"let var1 : T;\", because it is not a struct. However, you can have references of type \"&amp;dyn T\" and \"&amp;mut dyn T\". These can point to any struct instance of a struct that implements T, like instances of S1 or S2. Important, they are just references - there still needs to be an actual instance with actual data somewhere, and there the type must be defined (S1 or S2 clearly spelled out there).\n\nJust as local variables, trait references might not look particularly useful, because we usually know if it is an S1 or S2. They also have some downsides - not all traits can be used for such things (the trait must fulfil some requirements, see \"object safety\"), they use some more runtime and some more bytes of memory than normal references (when you call a method on such a variable, it must look up which stucts method it should call), and of course they only allow accessing methods that the trait T has (even if you know it points to an instance of S2, you are not allowed to directly access the other methods of S2).\n\n&amp;#x200B;\n\nTypes of function parameters (parameters, not return values):\n\nFor a parameter, you might say the type is eg.\n\n* a specific type, like S1 (a struct), or a reference &amp;S1 (reference to an instance of S1). Then you can only pass instances/references of S1\n* a trait object reference for trait T (ie. \"&amp;dyn T\"). Only as reference, not moved instances itself. Here, as expected, for each function call you can pass different struct references as long as they implement T. One call with a &amp;S1, one call with a &amp;S2. Inside of the function you won't know anymore if it was S1 or S2, and can only call what methods T guarantees that the structs have.\n* Generic with a restriction that the type must have at least the trait T. There are several ways to write this, including with &lt; &gt; or with \"impl T\". Again you can pass in either S1 or S2, and only use what T offers, but: Now everything happens at compile time by multiplying the whole function, and adapting it to the needs of each real type. If you call the function one time with a S1 and one time with a S2, and inside call methods on the variable, there won't be any runtime lookup like trait objects do. Instead, the compiler generates one function that works with S1 and uses this one for the first call, and generates a second copy of your function that can handle S2 and uses this for the second call. Btw. with generics, you can have owned (non-reference) data again too.\n\nWhen to use generics vs trait objects depends largely on the situation.\n\n* Generics can increase compile time and binary size, especially if there are hundreds of function copies to make... but usually offer better speed and optimization possibilities than trait objects. Meanwhile trait objects are slower at runtime but don't multiply code.\n* Not all traits can be trait objects\n* Not all situations allow for generics (or not in an useful way). If you want to have vectors of S1 and S2, you could either have two vectors, or a vec&lt;dyn T&gt;. If you then also want to accept any number of other types, possibly from other crates (structs there implement your T from here), then the only way left is the trait object vector.\n\n&amp;#x200B;\n\nTypes of function return values (finally):\n\nAgain you can have a specific struct S, then you only can return such instances. Again you can return trait object references, which are, like before, references with some runtime magic. And again you can say \"it is something that implements trait T, generate the code accordingly\". In the last case here, the compiler looks what type the \"return\"ed values are, and uses this (All returns of one function have to use the same type).\n\n&amp;#x200B;\n\nTypes of structs ... well, here generics exist too. If you use Vec&lt;u32&gt; and Vec&lt;u8&gt;, and call methods on them, the compiler makes copies of these methods as required for u32 and u8, instead of somehow calling the same method for both variants. And with a Vec&amp;u32&gt; and Vec&lt;&amp;dyn Blargh&gt;, you get a third and fourth copy of a vector in your program, here the instances being references to u32 (specific type) and to trait objects of trait Blargh.\n\n&amp;#x200B;\n\nWhen Rust tells you \"Iterator is not Sized\", that might be a bit cryptic first.\n\nIt is important to note that Iterator is a trait, not a struct. Things that can give you iterators, like Vec and whatever, have their own VecIterator structs (name not correct) that fit their needs, and the only common thing between all iterators in std is that the implement the Iterator trait.\n\nSo, when you try to make variable instances of Iterator, or (normal) references &amp;Iterator, that won't work. The only real variable that a trait alone can make is &amp;dyn Iterator, with magic included that finds the right method at runtime.\n\nPeekable&lt;X&gt; is a struct that inside will contain at least a variable of type X (Peekable being generically copied and adapted by the compiler as needed). Peekable&lt;Iterator&gt; would want to have a variable of type Iterator, and that's of course not possible - that's where the \"Sized\" error is coming from.\n\n(More specifically, Iterator is not something the compiler can assign a byte size to, because it can mean many different structs with different sizes. And when the compiler doesn't know the byte size, it can't help you making such an instance on the stack.)\n\n&amp;#x200B;\n\nSo, what can you do to be \"Sized\"? Either use a dyn reference, or tell the compiler that for each real type it should copy and adapt the whole test1 function.\n\n&amp;#x200B;\n\nAs you recognized, when you use a trait object, ie. dyn reference, which is still a reference, you have a problem when you return the reference and want it to exist even after the local variable it referenced stopped existing. So, no references ok here.\n\n&amp;#x200B;\n\nFinally, impl, you just tell the compiler \"it must implement Iterator, tell me if it does not. Otherwise I don't care about the actual type name, figure it out from the return statement\". The compiler adapts test1 to wor with the actual type.","score":5,"comments":[]}]}]},{"body":"&gt; `f.ok().unwrap()`\n\nThere's really no reason to call `ok()` here except making the panic message worse in the case where it is an error.","score":3,"comments":[]}]},{"title":"I created a Lisp interpreter and compiler(WIP) by Rust","not_safe_for_work":false,"locked":false,"body":"[https://github.com/long-long-float/lisp-rs](https://github.com/long-long-float/lisp-rs)\n\nThis is my first post. I created a Lisp interpreter and compiler(WIP) by Rust from scratch (including parser).\n\nIt has following features.\n\n* Basic form and functions (define, if, +, -...)\n* Macros\n* Statically typed with type inference\n* Human readable errors (like rustc)\n* REPL\n* Optimizing tail recursion\n* Generate code for RISC-V (now developing on compiler0 branch)\n\nHere is the result of  mandelbrot example by my interpreter.\n\nhttps://preview.redd.it/f4mhmn6aoq0a1.png?width=600&amp;format=png&amp;auto=webp&amp;s=4eebff58cd5aff81b5c45ee474f39e572afdd423\n\nThe source code is consisted by modules corresponded to compiler steps. It would help in understanding the basic language processing system. Thanks.","score":26,"comments":[{"body":"Cool project! I also feel this could be a great learning resource, thank you so much for sharing.","score":1,"comments":[]}]},{"title":"Community Grantee Spotlight: Sebastian Thiel","not_safe_for_work":false,"locked":false,"body":"","score":95,"comments":[{"body":"This is so cool! Imho, the grant was very well deserved.","score":9,"comments":[]},{"body":"I was surprised to find out that behind GitPython stands the very same author of gitoxide. I used GitPython a lot at my previous job.Thanks!","score":2,"comments":[]},{"body":"I assume this is a complete rewrite of git in Rust. But I haven't come across a mention of a complete rewrite (or maybe I skimmed it because of my ADHD). So I am asking as a confirmation, not as an attack, is this a complete rewrite of git or a wrapper around libgit2?","score":4,"comments":[{"body":"This is a pure-rust implementation as stated in the project's [README](https://github.com/Byron/gitoxide#project-goals), although he uses libgit2 as a source of inspiration.","score":19,"comments":[{"body":"Previously Sebastian Thiel implemented git in Python. I think I know it from README or just from browsing his repos.","score":3,"comments":[{"body":"Yes, that's [GitPython](https://github.com/gitpython-developers/GitPython), he talks about it in the [article](https://foundation.rust-lang.org/news/community-grantee-spotlight-sebastian-thiel/#q%3A-tell-us-about-the-background-of-gitoxide-!-how-did-this-project-come-to-be%3F). It's specifically a library to interact with git repos rather than an ecosystem like gitoxide, which comprises CLIs and an API.","score":3,"comments":[]}]},{"body":"Oh thanks for pointing it out!","score":2,"comments":[]}]},{"body":"&gt; I assume this is a complete rewrite of git in Rust. \n\nIt doesn't actually aim to produce a 1:1 `git` binary, so I wouldn't say that.","score":1,"comments":[]}]}]},{"title":"Suspend keyword, what about implement suspend in RUST like in KOTLIN for blocking operations?","not_safe_for_work":false,"locked":false,"body":"Suspend works like a charm in KOTLIN.","score":0,"comments":[{"body":"I think it already exists: [https://rust-lang.github.io/async-book/01\\_getting\\_started/04\\_async\\_await\\_primer.html](https://rust-lang.github.io/async-book/01_getting_started/04_async_await_primer.html)","score":5,"comments":[]},{"body":"Rust has async/await. `async` doubles as the `suspend` keyword from kotlin: `async fn` is like `suspend fun` (as far as I can tell, I'm not super familiar with kotlin)","score":6,"comments":[{"body":"`suspend fun` huh","score":4,"comments":[]},{"body":"Kotlin has async await too.","score":1,"comments":[]}]},{"body":"Rust's async model is still futures based, whereas in Kotlin, suspend functions return Unit or whatever like a normal function. Then you \\`launch\\` them to get a handle, and the compiler won't let them be called outside of an appropriate context. \n\nWhat I really miss from Kotlin coroutines is something like \\`withContext\\` that lets you jump around between different thread pools/execution contexts within the same coroutine.","score":3,"comments":[]}]},{"title":"Async fn in trait MVP comes to nightly","not_safe_for_work":false,"locked":false,"body":"","score":671,"comments":[{"body":"Oooo this is big. Very cool!","score":121,"comments":[]},{"body":"Great news, would love to get rid of \"async_trait\" (crate) dependency from my code.","score":35,"comments":[]},{"body":"As a newbie that just started learning rust with an actix microservice this month, async fn in traits and no (stable) generators was the only real thing I stumbled upon that I missed from other languages, super stoked that both of them might come out sooner than I thought!\n\nCongrats to the team!","score":87,"comments":[{"body":"I'm curious, what news have you seen regarding generators?","score":14,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"Same. I really started learning Rust while doing a bunch of async with Python at the time. One of the first things I was looking up was how to make async traits/methods in Rust.","score":19,"comments":[]},{"body":"","score":0,"comments":[]}]},{"body":"The [tracking issue](https://github.com/rust-lang/rust/issues/91611) is also tracking `return_position_impl_trait_in_trait`, which allows `impl Trait` in return position in traits.\nThis could be useful even outside of async.","score":9,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"So I've been wondering this for a while now, but these posts keep saying that we can't name the type returned by an async fn and I know that's true now, but what if we had a way of saying whatever type some standalone async function returns is the associated type? That would solve at least the send issue  because the calling code knows an exact type and won't have the limitations that returning an impl trait has.\n\nIt would look something like\n\n    trait Query {\n        type Data;\n        async fn query(&amp;self) -&gt; Self::Data;\n    }\n\nDesugaring it could be something like\n\n    impl Query for Foo {\n        type Data = Bar;\n        type QueryFuture = returnof query;\n        fn query(&amp;self) -&gt; Self::QueryFuture {\n            query(self)\n        }\n    }\n    async fn query(foo: &amp;Foo) -&gt; Bar {\n        // run query\n    }\n\nThat returnof syntax is what is needed but it would make a lot of things work that currently can't be done without dynamic dispatch.","score":6,"comments":[{"body":"This specific example can be written with TAIT as\n\n    type QueryFuture&lt;'a&gt; = impl 'a + Future&lt;Output = Self::Data&gt;\n    where Self: 'a;\n    fn query(&amp;self) -&gt; Self::QueryFuture { query(self) } }\n\n(and as mentioned this is what `async` sugars as) though the general problem of referring to (the output of) function types remains; it's only doable in this case because we can change the return type of `Query::query` and it's returning an opaque `impl Future` anyway.\n\nThe main issue with simple solutions is that function items exist in the *value namespace* but not the *type namespace*. Or in an example, it's valid to have `fn foo` and `struct foo {}` in the same namespace (and this is how tuple struct constructors work^†), or `fn foo` and `mod foo`.\n\n^† Well, tuple struct constructors also work as patterns, so it's more involved, but yes. This is also what allows you to use unit structs as values; `struct Unit;` is roughly just `struct Unit {} const Unit: Unit = Unit {};`.\n\nWhat I think more likely is being able to name function types via some special syntax, then from that using the `Fn*` traits to name the output type. (Strawman syntax `&lt;fn query&gt;::Output`.) Perhaps we could even have function items introduce a \"weak\" entry into the type namespace (can be overridden by defining or importing something else; this would be the same priority (and conflict with) glob imported names), and perhaps strengthen it to prevent doubling up in a future edition (although you'd still need the explicit syntax to refer to the type of a tuple struct constructor function, and we'd probably need a blessed-but-discouraged way to allow emulating tuple struct constructors for the sometimes pattern of defining such a function manually).","score":7,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"If you have a struct generic over T: MyAsyncTrait, can you use the ephemeral type of the future of the method as a field in your struct with this MVP? Or would I have to store a Box&lt;dyn Future&lt;Output…&gt;&gt;?","score":16,"comments":[{"body":"I think I’m general ephemeral types need another look over in rust. In the case trait return impl, perhaps `&lt;T as MyAsyncTrait&gt;::my_method::-&gt;`.","score":12,"comments":[{"body":"","score":0,"comments":[]}]}]},{"body":"","score":0,"comments":[]}]},{"title":"Font rendering and layout crates","not_safe_for_work":false,"locked":false,"body":"I'm making a mini text editor and I want to do my own font rendering, and am thus looking for a (set of) font rendering crate(s).\n\nFontdue looks the nicest to use to me, but doesn't seem to do fancy things like ligatures, emoji's, and bidir text.\n\nab\\_glyph seems to do more emoji rendering and has a bit bigger of a rendering feature set, but doesn't do layout.\n\nWhat I'm looking for is a (set of) crate(s) to get some image to render the glyph with, as well as a way to lay out glyphs and get the character index it used from that string, so I can figure out where the cursor is. Preferably with bidir and ligature support","score":5,"comments":[{"body":"Fontdue is a crate that allows you to render some glyphs and have a layout","score":5,"comments":[{"body":"Yep, I've already looked at it.\n\nI'm also curious about alternatives, as fontdue doesn't do everything I want.","score":2,"comments":[]}]},{"body":"You probably want to take a look at [swash](https://github.com/dfrg/swash).","score":4,"comments":[{"body":"Thanks!\n\nseems to in fact do what I need.","score":1,"comments":[]}]},{"body":"I think harfbuzz is the be-all and end-all of font shaping at the moment. There's a reimplementation for Rust [in rustybuzz](https://crates.io/crates/rustybuzz), but I haven't tried it.\n\nI have used [glyph_brush_layout](https://crates.io/crates/glyph_brush_layout). It works fine for my purposes, but it doesn't do any ligatures or Arabic, because it's not a font shaping crate.\n\nAlso, read [Text Rendering Hates You](https://faultlore.com/blah/text-hates-you/) and [Text Editing Hates You Too](https://lord.io/text-editing-hates-you-too/).","score":3,"comments":[{"body":"Yep I read those as well, seems like using unicode segmentation fixes most issues, besides affinity.","score":1,"comments":[]}]},{"body":"cosmic-text is the most promising crate that combines rustybuzz, swash and more.","score":3,"comments":[]}]},{"title":"Recommendations for pure rust XML parser with XPATH support?","not_safe_for_work":false,"locked":false,"body":"Is there a top rust crate these days for working with XML files and doing xpath queries against them?","score":6,"comments":[{"body":"Unfortunately in rust XML is still kinda a mess.\n\nSome crates aim to squeeze xml through the serde data model and end up being lossy or fail entirely, and others try expose proper xml expressiveness but fall short / are buggy.","score":13,"comments":[{"body":"With this in mind which would you say are the best ones? Quick xml looks pretty great if you want to traverse the tree manually, it doesn’t have xpath support though.","score":1,"comments":[]}]},{"body":"I used `sxd-xpath` (you'll need `sxd-document` as well) a while back. Worked fine for extracting a few paths.","score":3,"comments":[{"body":"How was performance? It needs to read the whole document into memory if I understand it correctly.","score":1,"comments":[{"body":"Can't really say. My documents were quite small.","score":1,"comments":[]}]}]}]},{"title":"Rust in the 6.2 kernel","not_safe_for_work":false,"locked":false,"body":"","score":203,"comments":[{"body":"Is there any info on how this is going to work going forward? I assume currently the plan is that new drivers can be written in Rust, but what happens when the first person rewrites an existing C module in Rust. Is Rust considered an improvement over C or is it just whatever the person who wrote the driver first and its set in stone after that.","score":39,"comments":[{"body":"It probably depends on the maintainer of that part of the kernel and if they judge it to be an improvement or not. Also, it could get vetoed by other kernel maintainers if the rewritten part is used on systems that need to work on platforms not currently supported by rust.","score":59,"comments":[]},{"body":"I think the general flow is:\n- 6.1: basically the build system only. Clippy, rustdoc, rust-analyzer setup, etc., and just enough Rust to do a “Hello World” driver. Basically a proof of concept that allows kernel builders to do setup if they might want to do Rust modules and validate that kbuild works.\n- 6.2: more of the custom alloc data types, a handful more abstractions, enough to make a basic module with some sort of useful functionality.\n- 6.3: (my speculation) traits for device files and other module types, more abstractions for basically everything that could be useful when writing kernel modules. At this point, I feel like we might see consideration of some basic in-tree modules written in Rust - but probably not merged here\n- future: depending on how this all goes, in-tree modules are probably going to be on the table at some point. Kernel maintainers are going to be super cautious about this, but device driver maintainers can make those choices\n- future future: writing core kernel functionality in Rust might eventually wind up on the table (I hope). If this happens, I suspect there will be some larger-ish restructuring of the Rust portion of the project (e.g. not living only in rust/ anymore), and changes will happen at a snail pace","score":48,"comments":[{"body":"I think basic abstractions and functionality adition will go till 6.5. After which rust can be considered good to develop drivers.","score":2,"comments":[]}]},{"body":"&gt; I assume currently the plan is that new drivers can be written in Rust\n\nIt may depend on which platform those drivers are to be used for; I'd expect some opposition to writing a driver in Rust for a device that may hypothetically be used on platforms that are not supported by rustc, for example.\n\n&gt; but what happens when the first person rewrites an existing C module in Rust.\n\nFirst, there's the platform support question. If the module is used on platforms not supported by rustc, it's an automatic no.\n\nOtherwise, Linus left it to each individual maintainer as to whether they were ready to accept Rust code in their own area of the kernel. Some maintainers for low-level kernel functionality did mention that since what they maintain is used throughout the kernel if anyone else wanted Rust, they'd probably need to support it too, but this question wasn't definitely answered AFAIK.","score":3,"comments":[]}]},{"body":"I wonder if the [Inlineable Dyn Extension Traits (IDETs)](https://docs.rs/gdbstub/latest/gdbstub/target/ext/index.html#how-protocol-extensions-work---inlineable-dyn-extension-traits-idets) technique could be relevant at all to the kernel? Seems like it might solve some of the same problems","score":2,"comments":[]},{"body":"Does anyone know why they didn't use `log::*` for logging ? Even with adding missing levels it would have looked more idiomatic.","score":1,"comments":[{"body":"Log is high level logging crate with swappable backends and a couple moving parts, which is completely unnecessary. While useful for typical user-space applications, pulling useless complexity into Linux is not a good idea. Also, Linux build system doesn’t support pulling in external crates, and that’s by design, meaning you’d end up with a vendored dependency.\n\nPlease refrain from stating that use of such-and-such crate is idiomatic while completely disregarding specifics of a very, very specific project that Linux is.","score":13,"comments":[]}]},{"body":"[deleted]","score":-21,"comments":[{"body":"comment about how lwn is fine with it incoming","score":4,"comments":[]}]}]},{"title":"Welcoming Seth Markle to the Rust Foundation Board","not_safe_for_work":false,"locked":false,"body":"","score":11,"comments":[{"body":"&gt;Amazon\n\nOf course.","score":1,"comments":[{"body":"Amazon is replacing their rep on the board so yeah, it makes sense that person would also work at Amazon.","score":11,"comments":[{"body":"... That's exactly what Amazon would say","score":2,"comments":[]}]}]}]},{"title":"`impl Trait` does obstruct compiler optimization","not_safe_for_work":false,"locked":false,"body":"","score":0,"comments":[{"body":"You're measuring the performance of `println!(\"adder: {}\", &amp;*adder);`, is that really intended?\n\nIf I introduce a `let elapsed = begin.elapsed();` prior to `println!` and use that, I get the following output [for the code](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2021&amp;gist=8fe4b0afceafba834749d62cf1397c80):\n\n    adder: 2000000\n    adder: 80ns\n    adder2: 2000000\n    adder2: 50ns\n\nIn which case `adder2` is faster somehow... so at this point I look at the LLVM IR post-optimization and realize that the benchmark is bogus (unsurprisingly):\n\n    ; playground::main\n    ; Function Attrs: nonlazybind uwtable\n    define internal void @_ZN10playground4main17h5d2cbecafd88d176E() unnamed_addr #1 personality ptr @rust_eh_personality {\n    start:\n        ...\n        store i64 2000000, ptr %adder, align 8\n        ...\n    ; call std::io::stdio::_print\n        call void @_ZN3std2io5stdio6_print17h5cbb3fae9e78870cE(ptr noalias nocapture noundef nonnull dereferenceable(48) %_15)\n        ...\n        store i64 2000000, ptr %adder1, align 8\n        ...\n    ; call std::io::stdio::_print\n        call void @_ZN3std2io5stdio6_print17h5cbb3fae9e78870cE(ptr noalias nocapture noundef nonnull dereferenceable(48) %_55)\n        ...\n        ret void\n    }\n\nIn summary: there's no loop, LLVM entirely compiled the loop to storing `2_000_000` straight into the register to print.\n\nI can't say anything about the circumstances that led you to this benchmark, but you're not benchmarking what you think you are.","score":58,"comments":[]},{"body":"I don't think the playground is really able to run benchmarks - I assume in the backend it's some kind of container system, so you're not getting real hardware.\n\nIn addition to that a simple timing using `Instant` isn't going to give accurate results. You need to use something like `criterion` to get significant results for micro-benchmarks.","score":10,"comments":[]},{"body":"If I change the return value from \\`impl Trait\\` to \\`Adder\\`, I get the same performance difference between the two, so this is probably unrelated to \\`impl Trait\\`, but it's still strange though.\n\nI also still get the same performance difference if both benchmarks run \\`get\\_adder\\`, so there is something else strange going on.","score":4,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"For me adder2 is running faster than adder. Have you checked disassembly?","score":4,"comments":[]},{"body":"https://godbolt.org/z/eGfqW7j4M","score":2,"comments":[{"body":"https://godbolt.org/z/rndobKdxo","score":1,"comments":[{"body":"Both `main1` and `main2` are optimized away...","score":2,"comments":[]}]}]},{"body":"Why would you call println!() inside of what you are trying to measure (lines 36 and 44)? Printing to console is I/O and has side-effects.","score":2,"comments":[]},{"body":"https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2021&amp;gist=94cbfb3e9fe9d6612550265d6567eff9\n\nSome results:\n\nadder(with solid type Adder): 4115223022273598432\n\nadder: 2.494131ms\n\nadder2(with impl DerefMut): 4115223022273598432\n\nadder2: 18.285878ms","score":0,"comments":[]}]},{"title":"Function with generic return Type","not_safe_for_work":false,"locked":false,"body":"Context: I am trying to write a lexer for a parser\n\nI have a type `Token&lt;T: Display&gt;` where T is the type of the data that is saved in the Token. T might for example be an  i64 or a String. Also there's a function `pub fn lex&lt;T: Display&gt;(mut code: &amp;str) -&gt; Result&lt;Vec&lt;Token&lt;T&gt;&gt;, &amp;'static str&gt;` that turns a string into a Vector of Tokens.   \nNow when I try to call this function, Rust tells me that it cannot infer the type of the type parameter \\`T\\` declared on the function \\`lex\\`. However I cannot specify it because the type is not uniqie i.e. the Vector will contain Tokens with different types.\n\nHow can I call this function without knowing what Tokens I might have? \n\n&amp;#x200B;","score":1,"comments":[{"body":"You don't want to use generics for this.  What you're looking for are trait objects.\n\nhttps://doc.rust-lang.org/reference/types/trait-object.html","score":8,"comments":[{"body":"That seems to be true.  I now have the Issue that the compiler doesn't know the size at compilation time (how should it).This is my struct at the moment:\n\n`pub struct Token {`\n\n`pub token_type: &amp;'static TokenType,`    \n\n`pub data: dyn Display`\n\n`}`","score":1,"comments":[{"body":"Some types are DSTs (Dynamically Sized Types). The simplest examples are slices (`[T]`), string slices (`str`), and trait objects (`dyn Trait`).\n\nThere are a few rules to handling these:\n\n* You cannot store them on the stack, because the compiler doesn't know how much space to allocate.\n* You cannot store them in a struct, except as the last field, because the compiler doesn't know what the offset of fields after the DST should be.\n* Storing a DST in the last field of a struct makes that struct also a DST.\n* You cannot store them in an enum. This may be subject to change in a future Rust version.\n* You cannot use them in any generic, unless it has a `?Sized` bound.\n* If you ever write unsafe code that becomes concerned with the memory layout of a pointer, note that pointers to DSTs store additional information.\n\nThe easiest way to handle a DST is to use put it behind a pointer (such as a reference or box).","score":5,"comments":[{"body":"Thank you for this good explanation!","score":1,"comments":[]}]},{"body":"&gt;that the compiler doesn't know the size at compilation time\n\nAs a result of this, trait objects must be boxed (ie. `Box&lt;dyn Display&gt;`) or behind a reference (ie. `&amp;dyn Display` or `&amp;mut dyn Display`).\n\nIf you want to avoid the overhead of heap allocation, you'll want to use an additional enum for the data type so they're concrete. Eg:\n\n    enum TokenData {\n        String(String),\n        i64(i64),\n        // etc\n    }\n\nYou'd need to manually implement Display for this enum though.","score":3,"comments":[{"body":"Thanks! I managed to figure out ai have to box it :)","score":2,"comments":[]}]}]}]}]},{"title":"Seeking by lines","not_safe_for_work":false,"locked":false,"body":"Hi, is there a way to seek a text file by lines instead of cursor position?","score":0,"comments":[{"body":"Hand in the cursor to a BufReader and use the .lines() iterator on the BufReader.\n\nThis would, by the way, fit well into the weekly questions thread.","score":10,"comments":[{"body":"See code example here: https://doc.rust-lang.org/std/io/struct.BufReader.html","score":2,"comments":[]},{"body":"Thanks, will do the questions thread.\n\nAlso does .lines() read everything into memory?","score":0,"comments":[{"body":"No. That would rather defeat the point of having it on a file, as you can just read the entire file to memory and use the [`lines` string iterator](https://doc.rust-lang.org/std/primitive.str.html#method.lines) if that’s what you want.","score":3,"comments":[]}]}]},{"body":"I wrote a Rust version of \\`tail\\` that has to seek to the Nth byte/line from the end: https://github.com/kyclark/command-line-rust/blob/master/11\\_tailr/src/lib.rs","score":2,"comments":[]}]},{"title":"sofar crate - allows to read and render HRTF filters from SOFA files (based on libmysofa)","not_safe_for_work":false,"locked":false,"body":"[https://github.com/andreiltd/sofar](https://github.com/andreiltd/sofar)","score":1,"comments":[{"body":"Those formats told me nothing so:\n(From aes site)\n\nBinaural listening is growing fast, because of growing sales in smartphones, tablets and other individual entertainment systems. The lack of a standard for the exchange of head-related transfer functions (HRTF) means each company keeps its binaural capture and rendering algorithms private. 3D audio is arising, and binaural listening could be the very first 3D audio vector with sufficient fidelity of HRTF.","score":1,"comments":[]}]},{"title":"Mutability differ for PartialEq with Option","not_safe_for_work":false,"locked":false,"body":"I have 2 Options:  **Option&lt;&amp;T&gt;** and **Option&lt;&amp;mut T&gt;**\n\nNaturally, I want to compare them for equality (T: **PartialEq**)\n\n    assert_eq!(a, b)\n\nBut I can't due to **types differ in mutability** error.\n\n    assert_eq!(Some(&amp;mut 1), Some(&amp;1))\n\nWhich is translated to: \n\n    PartialEq::&lt;Option&lt;&amp;i32&gt;&gt;::eq(&amp;Some(&amp;mut 1), &amp;Some(&amp;1));\n\nIt's not just about **&amp;mut T** vs **&amp;T** it's when it's wrapped in **Option**\n\nWhat's the **rustc** reasoning about not permitting this? Is this limitation has implications I'm not aware of?\n\nHow woud you go about comparing them easily?\n\nThis comes to mind, but it's super clunky.\n\n    let (Some(a), Some(b)) = (a, b) else {\n        panic!(\"Not equal\");\n    };\n    assert_eq!(a, b, \"Not equal\");\n\nUpdate: fixed formatting.","score":0,"comments":[{"body":"`assert_eq!(a.as_deref(), b);`\n\nhttps://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=6a79e52589fd20f0854f00d9a05d522b","score":4,"comments":[]},{"body":"`&amp;T` and `&amp;mut T` are different types, and implementing all traits for all mut/non-mut combinations would lead to lots and lots of boilerplate trait impls, even with macros, so in general Rust has decided not to do so. The easiest way to make the code compile is to do either\n\n    assert_eq!(a.map(|x| &amp;*x), b)\n\nor\n\n    assert_eq!(a.as_deref(), b)\n\nthe latter of which uses the slightly magical *deref coercion* to change from `&amp;mut` to `&amp;`.","score":4,"comments":[]},{"body":"Huh, I thought I tried `as_deref()` and it didn't work. This is acceptable, I guess. Thanks.\n\nu/Sharlinator This magic is truly magical. I use `as_deref()` quite a lot, but I didn't know it can do `&amp;mut -&gt; &amp;T` \n\nSometimes I wish Rust treated `Option` and `Result` somewhat specially, so in certain contexts it operated on their inner data rather than on the enums themselves. \n\nFor example be able to do `impl From&lt;Option&lt;MyTypeA&gt; for Option&lt;MyTypeB&gt;`","score":1,"comments":[]}]},{"title":"What are Rust’s biggest weaknesses?","not_safe_for_work":false,"locked":false,"body":"What would you say are Rust’s biggest weaknesses right now? And are they things that can be fixed in future versions do you think or is it something that could only be fixed by introducing a breaking change? Let’s say if you could create a Rust 2.0 and therefore not worry about backwards compatibility what would you do different.","score":214,"comments":[{"body":"- compile times. Fixable: no, only improvable.\n- learning curve. Fixable: no, only improvable.\n\nThere is actually a wishlist for rust 2.0 somewhere on github, it's pretty interesting","score":296,"comments":[{"body":"Are you familiar with the WIP cranelift backend? It is supposed to improve compile times to the point that I would consider them “fixed”\n\nI think the general idea is that rust will start having the cranelift backend be the default debug choice, since it’s going to be much faster but can’t do heavy optimizations. Then use the standard LLVM backend (or new GCC backend) for release mode","score":95,"comments":[{"body":"I'm actually going to work on cranelift for my bachelor thesis next semester and I'm super stoked 😃\n\nThat being said, rustc will still be doing the same amount of work to product CLIF instead of LLVM IR. rustc does *a lot* and that's why we love it. Many techniques considered idiomatic in Rust put a lot of pressure on the compiler - compile time generics with monomorphization, deeply nested generic type signatures to tickle as many compile time guarantees out of the type system as possible... I think many of these things cannot be \"solved\" but represent a tradeoff and value judgement the Rust community has made and continues to make. I personally love those values, so I don't complain about the compile times!","score":122,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"the learning curve is the real headache, because it makes it much more difficult to convince other people to try it. So even if you want to use Rust, you are stuck trying to get other people in your team and org to go along with it too and a lot of people dont want to or dont care to invest so much time learning it","score":25,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"The two most important things to do in Rust:\n\n1) Make sure you are linking with lld (edit ~/.cargo/config)\n2) use the 'cargo build --jobs $(nproc)' to use all your cores.\n\nThose two things alone will make your build time go about 20x faster. By default, Rust does the linking with whatever the 'cc' compiler is on your machine and probably will only use a single thread/core.\n\nYou can also put this same content either in #1 or your Cargo.toml file:\n\n```\n[target.x86_64-pc-windows-msvc]\nrustflags = [\"-C\", \"link-arg=-fuse-ld=lld\"]\n\n[target.x86_64-pc-windows-gnu]\nrustflags = [\"-C\", \"link-arg=-fuse-ld=lld\"]\n\n[target.x86_64-unknown-linux-gnu]\nrustflags = [\"-C\", \"linker=clang\", \"-C\", \"link-arg=-fuse-ld=lld\"]\n\n```\n\nYou only need the relevant line and some iteration of lld installed (a clang complete install would have it, but some distros like Ubuntu let you install it by itself.) You only need the relevant targets here that match your architecture on the machine you're building on/for. You can ignore the rest. Personally, I just use the config file setup rather than doing it for every single project.","score":14,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"I've noticed a trend for introducing RFCs that attempt to make Cargo's feature system more complicated. [Here is the most recent one](https://github.com/rust-lang/rfcs/pull/3347) I've seen, but there have definitely been others, and they all seem to be solving problems with `default-features=false`.\n\nThis may be a hot take, but I think the introduction of default features into Cargo's feature system was a bad idea. It leads to well-known problems like the one described in that PR, and the only benefit I can see is that you can split out functionality into features without having to bump the major version. \n\nIMO, we are too scared of bumping major versions. Rather than having these complicated systems to avoid bumping major versions, I think we should embrace the fact that evolving and API is good, and that there is no shame in releasing a breaking change after you've already hit version 1.0.0.","score":60,"comments":[{"body":"&gt;IMO, we are too scared of bumping major versions. Rather than having these complicated systems to avoid bumping major versions, I think we should embrace the fact that evolving and API is good, and that there is no shame in releasing a breaking change after you've already hit version 1.0.0.\n\nYes I was really hoping that was the direction Rust would go in. I don't mind staying on an old version. It might be annoying to upgrade the whole project with breaking changes, but that's the projects problem, not the language's.","score":28,"comments":[]},{"body":"","score":0,"comments":[]}]},{"body":"- Rust is move-heavy which is not something compilers were optimised for.  This results in some unoptimised code.  This is fixable by improving the compilers.\n- Lack of specialisation.  This is fixable without introducing breaking changes.\n- std::ops is a mess when trying to work with generic numeric types.  Writing code in a way where you don’t relay on the type being Copy or without doing unnecessary clones is unreasonably verbose.  I don’t know if this can be fixed without a breaking change.\n- Unsafeophobia by which I mean that some programmers are zealously avoiding unsafe even if it can be shown that the code is safe and noticeably improves performance.  Can this be fixed? Maybe if Rust gets wider spread into areas where people care about performance more.","score":149,"comments":[{"body":"&gt;Unsafeophobia by which I mean that some programmers are zealously avoiding unsafe even if it can be shown that the code is safe and noticeably improves performance. Can this be fixed? Maybe if Rust gets wider spread into areas where people care about performance more.\n\n100% this. I've had people criticize my own libraries for using unsafe code in a few places, despite the fact that I clearly document exactly why and how what I am doing is sound. For some reason, some people don't understand that unsafe does not necessarily mean unsound.","score":33,"comments":[{"body":"Unsafe code is okay sometimes and I agree that people are against it too much, but it must be said that _a lot_ of unsafe code out there is buggy, so the fear does not come from nowhere. If you can reasonably avoid unsafe, you should.","score":21,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"AI testing environment","not_safe_for_work":false,"locked":false,"body":"Is there any library to create/manage worlds to help test AGIs or ASIs in rust? Something like a testing grounds, with some prepared problems, as well as their solutions.","score":1,"comments":[]},{"title":"Use rug crate on windows 10","not_safe_for_work":false,"locked":false,"body":"I want to use rug crate for integers bigger than u128. The thing is gmp-mpfr-sys (dependency of rug) doesn't compile on windows. I followed instructions in the docs to compile on windows. I installed MSYS2, ran those 2 commands to install packages. Then I proceeded to try to cargo run, got message cargo not recognizer as command, no problem, I went to MSYS2.ini, uncommented that one line to inherit path programs. Now when I enter cargo run in MSYS2 it finds cargo, but still can't compile (I get the same error as when running from CMD).\nTLDR - followed docs instructions, but still won't work","score":1,"comments":[]},{"title":"Which do YOU prefer? String literal to owned String","not_safe_for_work":false,"locked":false,"body":"When you want a String, for example in a Default impl, which is your preferred way of converting a string literal to an owned String? I couldn't find any clear indication which is the \"best\" or idiomatic way.   \n\n\nEdit: If you don't have a preference, please click \"I just want to see the results\"\n\n[View Poll](https://www.reddit.com/poll/yxqji8)","score":194,"comments":[{"body":"I'm with [dtolnay here](https://users.rust-lang.org/t/to-string-vs-to-owned-for-string-literals/1441/6?u=rofrol). `.to_owned()` expresses the intent most clearly: there's a reference, and I want an owned thing.\n\n`.to_string()` is coming from the `ToString` trait which requires `Display`; even if the compiler optimizes it away, it's a slight abuse in my opinion. But it's what the compiler keeps suggesting, so it can't be that bad :)","score":242,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"you forgot about these\n\n    let s: String = \"🦀\".parse().unwrap();\n    let s: String = \"🦀\".replacen(\"\", \"\", 0);\n    let s = format!(\"{:?}\", \"🦀\");\n    let s: String = \"🦀\".lines().flat_map(|l| l.chars()).collect();\n    let s: String = {\n        let mut s = String::new();\n        s += \"🦀\";\n        s\n    };","score":198,"comments":[{"body":"I came from Java and C# so...\n\n    let s = {\n       struct S;\n          impl std::fmt::Display for S {\n             fn fmt(&amp;self, f: &amp;mut std::fmt::Formatter&lt;'_&gt;) \n             -&gt; std::fmt::Result {\n             std::write!(\n                f, \n                \"{}\", \n                std::format!(\"{}\", \n                std::format_args!(\"🦀\"))\n             )\n          }\n       }\n       S\n    };","score":153,"comments":[{"body":"Now this is enterprise code. Although you forgot to get the format args from the crab emoji factory","score":103,"comments":[{"body":"It also needs more XML with dependency injection","score":33,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"`to_owned` expresses the purpose best, `to_string` is a `Display` method, so it’s kind of like doing `format!(“{}”, s)`  which is kind of an abuse. Like, it expresses a different goal. I am somewhat guilty of using .into() a lot, but it’s usually clear which type is meant.","score":48,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"Devil’s advocate, but I think that the best way is to look at what you’re doing. In most cases, I really prefer `String::from` and here’s my rationale. \n\n1.\tString sucks in some specific cases, and I really want the freedom to swap it out for e.g. a SmallStr or an in-house immutable string to do profiling. Neither `to_string()` nor `to_owned()` are particularly ergonomic for that. \n2.\tString tells you two things at once: it’s an owned type and it’s converting a literal. The only reason you’d use a `from` and not `as`, is because of the heap allocation, so now you have the benefits of to_owned and to_string in one. \n3.\tThe prefix function call looks ugly. So you want to get rid of it. Refactor to accepting slices with lifetimes. \n4.\tHave you tried moving to no_std? If you have `to_owned` cargo has no idea what to suggest to you. `to_string` and `String` both have obvious solutions: import alloc. \n5.\tAFAIK, to_ string is a blanket impl. I have no idea whether or not it gets optimised, but I know that the language feature to do that is not yet stable (specialization). So it’s a coinflip in terms of performance. **EDIT** Thanks to u/darth_chewbacca, we know that there's no difference between `to_string()` and `to_owned()`. There was back in 2016, so clippy keeps suggesting it. \n6.\tHave you had Rust analyzer give up on your project, because it has too many crates? I have. This makes the type inference much simpler and therefore the probability of you ending up with {unknown} goes to zero. \n7.\tThis is a gut feeling, but given that you don’t need to do the type inference to figure out the function, it might compile faster. Might be my imagination. Nothing compared to compiling syn, but it might add up for smaller projects.\n8.\tString isn’t special. It isn’t supposed to be special. Do you have a `to_my_custom_type()` conversion? Me neither. This makes the usage more uniform and more in line with it’s place in the hierarchy.","score":34,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"I change my mind just about every time I sit down at my keyboard.\n\nSometimes I justify using to_string() or to_owned() by convincing myself that the *content* of the string matters most, so I rather see the literal first and then the transform to a specific type is just \"details\".\n\nBut, other times I convince myself to use String::from() because I know that I am constructing a new instance of a specific type, so I should just call the constructor like I would for 99% of the structs I define, e.g., `Foo::new(arg)`.","score":52,"comments":[]},{"body":" to_owned usually. Intentions are important.","score":12,"comments":[]},{"body":"If left side is typed, then use into. If left side is implicit use String::from. People who don't code in rust often should be able to understand your code and these two ways are the best to communicate your intent without requiring additional comments. In the rust by example book they used String::from. As for into; I read it as [convert] x into y.","score":20,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"what ORM should I use / how should I use diesel.rs for operations from multiple thread","not_safe_for_work":false,"locked":false,"body":"What is the standard process for communicating with, say, a postgres database through an ORM when actions can be performed from multiple threads simultaneously? Is there a standard for using tokio with diesel?","score":0,"comments":[{"body":"Check sea-orm. After trying  diesel for several hours I switched to sea-orm. Perfomance is not so good, but async is build-in and the queries are much more flexible and (for me as a rust-beginner) better to understand.","score":3,"comments":[]},{"body":"SQLx","score":2,"comments":[]},{"body":"You want to use a connection pool in such situations. For async use-cases you might want to use [`deadpool_diesel`](https://crates.io/crates/deadpool-diesel), otherwise have a look at the built in r2d2 support in diesel itself.","score":3,"comments":[]}]},{"title":"What's a good project to learn rust?","not_safe_for_work":false,"locked":false,"body":"Hello folks,\n\nI am a C / C++ coder and I am planning to learn rust. I think the best way to learn a language is to implement a project using such language so what do you guys think would be a good project for this?\n\nThanks\n\nEdit: Thanks everyone for your answers.","score":0,"comments":[{"body":"I find it's helpful to recreate a simple project you've already completed in another language. That way you can focus less on the program logic and more on the language mechanics.","score":7,"comments":[]},{"body":"Read the Rust book first: https://doc.rust-lang.org/book/\n\nThen this is a good second step to learning Rust: https://picklenerd.github.io/pngme_book/introduction.html","score":4,"comments":[{"body":"What a cool way to do an intermediate project!  \nA problem, docs to read, and tests to verify.  \n\n\nThe large suite of tests to compare your work against really makes it look like it would work great as an early project -- if I were the one writing that I'd have highlighted their inclusion in the first page (I only noticed them by jumping around).","score":1,"comments":[]}]},{"body":"I can suggest Hands-on Rust if you like video games. This book shows you how to write a console program, then a flappy bird clone and after that a roguelike 2D dungeon crawler with rust. 😎\n\nHere is a link with more info: \nhttps://pragprog.com/titles/hwrust/hands-on-rust/","score":4,"comments":[{"body":"Thanks,\n\nThis sounds really interesting!","score":1,"comments":[]}]},{"body":"I like to write interpreters. Write a Forth. Write a Lisp. Exercises all the CS fundamentals.","score":1,"comments":[]},{"body":"Some people I know followed the ray tracing challenge, that exercises some of the parallel part of rust via rayon/crossbeam, and so highlights some strengths.","score":1,"comments":[]},{"body":"I made snake using rust's sdl2 bindings as my first super simple miniproject :) (1 file, &lt;400 lines of code)","score":1,"comments":[{"body":"This one sounds particularly interesting to me.\n\nThanks!","score":1,"comments":[]}]}]},{"title":"A rust crate that lets you compress ASCII text to a single Unicode \"character\"","not_safe_for_work":false,"locked":false,"body":"","score":80,"comments":[{"body":"This is my port of the [incredible python code](https://github.com/DaCoolOne/DumbIdeas/tree/main/reddit_ph_compressor) by /u/\\_DaCoolOne\\_. It lets you convert ascii text, e.g. python or rust code, to a single Unicode character in a reversible way.  \nThis also lets you refactor your code into a single line! Imagine the readability!\n\n~~I don't know enough about Rust macros to know if it would be possible to create a macro that decodes a character like this and then passes the result on to the compiler. Does anyone know if this is feasible?~~\n\nContext: https://www.reddit.com/r/ProgrammerHumor/comments/yqof9f/the_most_upvoted_comment_picks_the_next_line_of/ivrd9ur/\n\nEDIT: escaped the underscores in the username\n\nEDIT: Thanks to the work of /u/alexiooo98 the crate now defines the macro `zalgo_embed!` that lets it also do to Rust what it previously could only do to Python.","score":42,"comments":[{"body":"This is definitely not the most disquieting thing I've seen written in Rust so it has that going for it.\n\n&gt; I don't know enough about Rust macros to know if it would be possible to create a macro that decodes a character like this and then passes the result on to the compiler. Does anyone know if this is feasible? \n\nIt should be possible using proc macros, you couldn't do it with declarative macros though.","score":22,"comments":[{"body":"Woop! Time to learn proc macros. Then we will finally have the ability to convert all Rust source code to a single line.","score":15,"comments":[{"body":"Here's a few links to get you started (you'll probably be using all three of these crates if you write a proc macro):\n\n1. https://crates.io/crates/proc-macro2\n2. https://crates.io/crates/quote\n3. https://crates.io/crates/syn\n\nProc macros are generally kind of hard to debug, but the nice thing about using `proc-macro2` is you can just write it as a library (or program) for testing and print out the results (or use tests).","score":14,"comments":[{"body":"","score":0,"comments":[]}]}]},{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"A single unholy grapheme cluster. Very cute idea. Thanks for crediting the Python code.","score":15,"comments":[]},{"body":"This is absolutely an abomination. I admire it.","score":15,"comments":[]},{"body":"A similar thing is actually practical in JavaScript which mandates that all strings are UTF-16. You can cram more data into strings in memory if you use [base-327168](https://github.com/qntm/base32768) encoding, and it serializes to equally compact JSON.\n\nIt is of course a horrible hack just to work around the fact that JavaScript is terribly designed, but it is useful for people who have to build things with it anyway because that's the only thing that runs in the browser (until WASM gets reference types in production).","score":10,"comments":[]},{"body":"Your error handling is not idiomatic. Don't return an `Error` turned into a string; either return the original error or a new error type you define in your own library.\n\n(Also I don't understand why this is restricted to ASCII. Surely with a slight extension the encoding can cope with any char sequence...)","score":24,"comments":[{"body":"As the person who created the original encoding, I can speak to this. The reason it's restricted to ascii was because in the original encoding I needed to make the decoder super code-golfable. The range of combining characters used ([Latin combining diacritic marks](https://www.unicodepedia.com/groups/combining-diacritical-marks/), U300 - U36F) can only encode 96 code points, so I needed to pick which characters would be encodable. Since I was encoding code, I decided to use 0x20 (SPACE) through 0x7E (\\~), and map 0x7F to newline, which is all that you need to encode the vast majority of scripts in any language.\n\nI'm open to updating the specification. However, I'd ideally like to avoid making ascii text any larger than it is (2x byte size increase isn't great, lol), but the other characters can probably be added using other combining characters outside of the range I used.","score":22,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"Does that get around the Twitter character limit?","score":3,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"Building Robust Server with Async Rust and Tokio","not_safe_for_work":false,"locked":false,"body":"","score":23,"comments":[{"body":"Hey, just wanted to share this thing I wrote, I hope the new account isnt a problem, I can pm my regular account ( just trying to stay mostly anonymous hah) Hope this content is good, a little nervous about blogging about technical stuff. Love any feedback!","score":10,"comments":[{"body":"It's great! I appreciated your efforts to reveal the real-but-seldom-tutorialized practical concerns and provide insight into the dark corners of API's. Please feel encouraged to continue.","score":7,"comments":[{"body":"Thanks for letting me know! I really appreciate this response.","score":4,"comments":[]}]}]},{"body":"This is a very informative article! Well written and explained too. \nWould you be interested in expanding this into series maybe?","score":5,"comments":[{"body":"Thanks! Yeah could be interesting. I need to think about some topics that I feel are underserved and I know about too","score":2,"comments":[]}]},{"body":"great article. personally I have never used #[tokio::main], glad to find a like-minded articulation of why. (there are dozens of us! jk)","score":2,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"I just skim through the post and I got one question: Why does the code create multiple runtimes?","score":1,"comments":[{"body":"Heh so that was the core topic I was trying to write about in this. The goal is to keep everything the server does separate, like reporting stats wont effect requests which could happen if you just use one big runtime","score":1,"comments":[{"body":"Is that really necessary?\n\nP.S. for logging, you can use tracing-appender which flushes the log on a separate thread.","score":2,"comments":[{"body":"They run on a thread pool and yes it's possible.\n\nBack in my java days it's why you have a seperate threadpool for DB which could block requests.","score":5,"comments":[]},{"body":"","score":0,"comments":[]}]}]}]},{"body":"","score":0,"comments":[]}]},{"title":"The Fundamental Design of PhotonDB","not_safe_for_work":false,"locked":false,"body":"","score":4,"comments":[{"body":"It's a KV store?\n\nWhy might I choose this over Sled or RocksDB? Is there a comparison somewhere?","score":2,"comments":[]}]},{"title":"We are happy to announce graph v0.3.0 - The crate ships with parallel graph algorithms and APIs to implement your own algorithms - Now on stable and with Python bindings.","not_safe_for_work":false,"locked":false,"body":"","score":64,"comments":[{"body":"How do you compare it with petgraph?","score":8,"comments":[{"body":"In contrast to petgraph, we focus on parallel implementations for all the available algorithms and the graph creation of the CSR data structure via the graph builder is also done in parallel.   \nFrom my understanding, petgraph takes a similar approach like networkx, which is providing text book implementations for a lot of algorithms, which is totally fine if the graphs you want to run on, are rather small. Also, in petgraph, graphs are mutable, which is not the case for the graph crate, at least at the moment.","score":4,"comments":[{"body":"Petgraph will outperform up to a certain size graph, correct?  What is that threshold size that one would benefit by adopting this library?","score":1,"comments":[{"body":"I don't think that this is generally true, although, I haven't run benchmarks on petgraph. I imagine that in petgraph, it also depends on the graph representation that you use. If you'd like to compare execution times based on their CSR representation, I'd be interested in the results.","score":1,"comments":[]}]}]}]},{"body":"In order to use this graph library in my application, I will need to import tonic?","score":1,"comments":[{"body":"No, if you only want to use the graph crate (algorithms + graph builder), you don't need tonic. It's required if you are using the server crate, which uses Arrow Flight as communication framework which in turn depends on tonic (among other things).\n\n&amp;#x200B;\n\nSee [https://github.com/s1ck/graph/blob/main/crates/algos/examples/usage-demo.rs](https://github.com/s1ck/graph/blob/main/crates/algos/examples/usage-demo.rs) for an example on how to integrate it in your application.","score":1,"comments":[{"body":"I'm not working in data science.  What is gained by using Arrow Flight, which uses grpc, and not just a standard grpc client?","score":1,"comments":[{"body":"The arrow memory layout/format is understood and implemented by a lot of other languages and tools (spark being just one major example) so implementing the flight API means that any of them can read/write data to anything else that implements it, basically out of the box. That’s supremely useful if you’re shipping around a lot of data and need to integrate with the existing ecosystem.","score":1,"comments":[]}]}]}]},{"body":"Awesome!","score":1,"comments":[]}]},{"title":"Experience using crates to generate \"dot\" graphs?","not_safe_for_work":false,"locked":false,"body":"In a project or mine I \"manually\" generate files in \"dot graph\" (.dot files) for graph visualization of data structures it handles, and then use graphviz tools to render them.\n\nI'd like to improve them and reduce the code in my project to generate them by using a crate. I've seen a few on crates.io.\n\nIf you have any experience using any of them, could you share it in a reply?\n\nI find the dot format, and the layout tools a bit clunky, and hard work to get nice, correct, graphs....so....If you have a suggestion for an alternative, with good crate support for creating the graph files and good rendering (to SVG preferably as it can support clickable links on elements ..) i would be interested too. I haven't found one to date.\n\nThanks","score":1,"comments":[{"body":"I know [petgraph](https://docs.rs/petgraph/latest/petgraph/dot/struct.Dot.html) can output to Dot.","score":6,"comments":[{"body":"I recently did a project and ended up using petgraph. It worked well enough for my needs. As far as I could tell it can't generate the SVG/PDF/etc output only the dot text. I ended up using a second grate that linked to graphviz (not in front of my computer and can't recall the name at the moment). I would have oetgraph generate the dot text as a string and pass it to the second library to generate my SVG.\n\nThere were some limitations I haven't solved with petgraph yet, but they are minor, and I haven't dug too deep yet. Such as if I want my graphviz output to use circo or ortho instead of the default I couldn't see a way to do it. When I get a chance, If can't find a way I was going to add in some manual editing of the string dot output before generating the SVG. Its just been a low priority so I haven't done it yet.","score":4,"comments":[]}]},{"body":"I [added graphviz](https://github.com/chc4/samsara/blob/3318c548dec73760ab612443533c99ce1d95ab83/src/collector.rs#L227) printouts to help debug a garbage collector library just a few days ago using graphviz_rust. It make it really easy - I'm outputting pdf just because it's easier to pull up in mupdf than an svg, but doing svg instead is just changing the enum variant. It basically is just the dot language, though being able to programmatically generate it easier than text munging helps a lot, so if your problem is just the dot language itself I don't know if there's a better alternative.","score":5,"comments":[]}]},{"title":"futures-concurrency v7.0.0 released!","not_safe_for_work":false,"locked":false,"body":"","score":109,"comments":[{"body":"How does this compare to the `futures` crate? Is the goal to get a rational subset of widely used operations directly into std?\n\nFor example the merge operation seems similar to [select_all](https://docs.rs/futures/latest/futures/stream/select_all/fn.select_all.html).","score":15,"comments":[{"body":"&gt; How does this compare to the futures crate? Is the goal to get a rational subset of widely used operations directly into std?\n\nThat's right. I've been working for several years now on defining the right set and shape of operations to propose for inclusion in the stdlib. If you want the full explainer of every decision made along the way, I've written what's now a five-part series on \"futures concurrency\" [on my blog](https://blog.yoshuawuyts.com/).","score":19,"comments":[]}]},{"body":"Hey all, we just published a new release of `futures-concurrency`; a library we're using to prototype `async/.await`-based concurrency operations in intended for inclusion in the stdlib.\n\nWe've done a lot of work overhauling the internals, and made it an actual priority to enable people to actually use it in production applications - rather than just serving as a prototyping ground for the stdlib APIs. I'll be publishing a new post in my [futures-concurrency](https://blog.yoshuawuyts.com/futures-concurrency-4/) series about this soon as well. But until then: I hope you enjoy this release!","score":37,"comments":[{"body":"So is this for mocking some sort of `select!` functionality that would be runtime agnostic?","score":4,"comments":[{"body":"Not only `select!` also: `join!`, `join_all`, `race`, `try_race`, `try_join`, and more. The goal has been to define a coherent set of concurrency primitives we can use to implement all other modes of concurrency with.\n\nThe only (intentional) limitation right now is that we're only sticking to _static_ async concurrency. Meaning that we're not yet defining any operations which deal with dynamically growing/shrinking sets. But we'll get to that eventually!\n\nIf you're interested in learning more, I [published a recording](https://www.youtube.com/watch?v=NbGQGfEzg58) of a talk I gave on the topic at CPH.rs about a month ago. Or else you can find the \"futures concurrency\" series [on my blog](https://blog.yoshuawuyts.com/).","score":8,"comments":[{"body":"Functionality that I'm not sure how to implement with the `futures` crate is to repeatedly await a cancellation future (C), as well as a series of newly created worker futures (W). So for example like this:\n```rust\nlet cf = (externally created future that may complete when cancellation is requested, for example if the server is shutting down);\nfor i in 0..N {\n    let wf = new_worker_future_for_dataset(i);\n    match either!(wf, cf).await {\n        Worker(w) =&gt; {\n            process_worker_result(w);\n        },\n        Completion(c) =&gt; {\n            graceful_shutdown();\n        }\n    }\n}\n```\n\nThe `either!` macro above means:\n1. Return when either of the passed futures completes\n2. Somehow allow me to determine which future it was that completed (represented here as an enum match but maybe it should be a struct field?)\n3. Don't cancel the futures that didn't complete, so that they can be awaited or passed to a new `either!` call in the future\n\nAs an aside, maybe it should actually be called `any!` and allow passing of more than 2 futures.\n\nOr, maybe someone can tell me which of the existing primitives in the `futures` or `futures-concurrency` crates allow me to implement this?\n\n\nThe `race` trait on [this page](https://docs.rs/futures-concurrency/7.0.0/futures_concurrency/vec/struct.Race.html) says \"Wait for the first future to complete.\" but on the [linked page](https://docs.rs/futures-concurrency/7.0.0/futures_concurrency/future/trait.Race.html#tymethod.race) it says \"Awaits multiple futures simultaneously, returning the output of the futures once both complete.\" which is identical to the description of `join!`.\n\nSo maybe `race` could be used to implement this but the docs are broken, and of course there are no simple examples embedded in the docs, only links to extremely long-winded external blog posts that get way off in the weeds.","score":1,"comments":[{"body":"&gt; The race trait on this page says \"Wait for the first future to complete.\" but on the linked page it says \"Awaits multiple futures simultaneously, returning the output of the futures once both complete.\" which is identical to the description of join!.\n\nI think there's just a mistake in the documentation, since the implementation of `Race` for `Vec&lt;T: IntoFuture&gt;` indeed [waits for the first future to complete](https://docs.rs/futures-concurrency/7.0.0/src/futures_concurrency/future/race/vec.rs.html#59).","score":4,"comments":[{"body":"","score":0,"comments":[]}]}]}]}]}]},{"body":"Huh. From the [repo page](https://github.com/yoshuawuyts/futures-concurrency), the [docs link](https://docs.rs/futures-concurrency) redirects to [https://docs.rs/futures-concurrency/latest/futures_concurrency/] which displays 6.0.1, and 7.0.0 isn't in the version drop-down. If I search for `futures-concurrency`, I get to a [7.0.0 link](https://docs.rs/futures-concurrency/7.0.0/futures_concurrency/). Maybe a caching thing. /shruggie","score":6,"comments":[{"body":"I'm not sure what's going on there. We don't hard-code any of the version numbers except on the release notes. Maybe it was a stale entry in a cache somewhere?","score":5,"comments":[{"body":"Probably, except *is*, not *was*; it's still happening. fwiw, the response headers say `date: Thu, 17 Nov 2022 00:56:29 GMT` and `x-cache: Hit from cloudfront`.\n\nedit: https://github.com/rust-lang/docs.rs/issues/1913","score":3,"comments":[]}]}]}]},{"title":"[Help] Distributing many slices of a same vector in structures","not_safe_for_work":false,"locked":false,"body":"Hello,\n\nI'm starting a new toy project and want to use Rust. My goal is to be able to edit pokemon save files.\n\nTo do so i want to be able to edit many different part of the same array across many nested classes by cutting the array down in smaller slices.\n\nHere is what i would like to do ideally:\n\n    use std::fs;\n    \n    #[derive(Debug)]\n    pub struct Section&lt;'a&gt; {\n        raw: &amp;'a mut [u8],\n    }\n    \n    impl&lt;'a&gt; Section&lt;'a&gt; {\n        pub fn new(raw: &amp;mut [u8]) -&gt; Section {\n            Section { raw: (raw) }\n        }\n    }\n    \n    #[derive(Debug)]\n    pub struct Save&lt;'a&gt; {\n        raw: &amp;'a mut [u8],\n        section_a: Section&lt;'a&gt;,\n        section_b: Section&lt;'a&gt;,\n    }\n    \n    impl&lt;'a&gt; Save&lt;'a&gt; {\n        pub fn new(raw: &amp;mut [u8]) -&gt; Save {\n            Save {\n                raw: raw,                                           //\n                section_a: Section::new(&amp;mut raw[0..0xE000]),       // &lt;-- Problems\n                section_b: Section::new(&amp;mut raw[0xE000..0x1C000]), //\n            }\n        }\n    }\n    \n    fn main() {\n        let mut content = fs::read(\"save.sav\").expect(\"File not found\");\n    \n        let save = Save::new(&amp;mut content[0..]);\n    \n        // Do save manipulation stuff...\n    \n        fs::write(\"new_save.sav\", content); // I don't have to \"reconstruct\" the content\n    }\n\nThe problem here is in `Save::init`, i can't borrow `raw` as mutable more than once. Which makes sense to me but there should be a way to work around this right ? In C/C++ i would be able to do this easily with pointer arithmetic for example, but i can't see how to do something similar in rust.\n\nPlease note that the whole point of what I'm trying to do is that by editing the slices in my structs, the original content array would also be edited. So that i don't need to \"reconstruct\" the whole save file from the many nested structs the project will eventually have.\n\nMy question here is: Is there any way to do this safely and properly ? I'm starting to think that my approach cannot be possibly safe and maybe rust is just not suited for my use case, or that i would need a whole new approach on how to do stuff.\n\nI tried looking on internet but did not find anything very helpful.\n\nI've tried fiddling around with `std::cell` and `std::rc` but i don't have enough understanding of the language to come up with my own solutions yet.","score":2,"comments":[{"body":"I am pretty confident in saying this is a bad path to follow and instead you’re better off deserialising this tiny data set to a comfortable rust api and then having a serialiser to dump it all out again.","score":7,"comments":[{"body":"Yeah that is what i was starting to think. If it is not idiomatic to rust maybe it is simply a bad design.  Parsing and Serializing the data again will be a pain with all the structs the program will eventually have but it is probably a better way to do it.","score":1,"comments":[]}]},{"body":"If you really want to go down this route you can use [`slice::split_at_mut()`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_at_mut). However using indices instead of references typically results in simpler code in Rust.\n\nEDIT: This only works for the `Section` slices, not the overlapping `Save` slice.","score":3,"comments":[{"body":"I'll look into it, thanks !","score":1,"comments":[]}]},{"body":"I'm pretty sure this will end badly. Just create your own meaningful struct that abstracts this data into a meaningful object and de/serialize into it","score":3,"comments":[]},{"body":"What do you exactly need `raw` for? In your snippet you can just use `content` after `save` is no longer used, and any change made by `save` to its subslices will be reflected in `content`.","score":2,"comments":[{"body":"Well, idk, it was just to illustrate the problem. The real issue here is that i can't initialise `section_a` and `section_b` because they both borrow `raw` anyway so problem stays the same.","score":1,"comments":[{"body":"Ah right, you can split `raw` into `section_a` and `section_b` by using the `split_at_mut` method.","score":3,"comments":[]}]}]}]},{"title":"Is there a crate to search and replace a string but with dynamic input?","not_safe_for_work":false,"locked":false,"body":"Hi,\n\nI'm trying to make a function that takes a bunch of arbitrary text, mostly HTML, and replaces all \\`Read{/tmp/text.html}\\` snippets with the file contents of the inside (\\`/tmp/text.html\\`).\n\nIs there a way to do this in stable rust? I found the [Searcher](https://doc.rust-lang.org/std/str/pattern/trait.Searcher.html#) API but it's nightly only.","score":0,"comments":[{"body":"surely you actually want a templating library","score":22,"comments":[]},{"body":"You could use the regex crate ([playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=24d131679cd594b32a319950b2410007)):\n\n    let regex = Regex::new(r\"Read\\{([^}]*)\\}\").unwrap();\n    let output = regex.replace_all(&amp;input, |captures: &amp;Captures| {\n        let capture = captures.get(1).unwrap().as_str();\n        fs::read_to_string(capture).unwrap() // proper error handling is a bit annoying here.\n    });\n\nBut I agree with /u/combatzombat that a proper html templating engine is usually a better choice.","score":8,"comments":[{"body":"[sigh](https://stackoverflow.com/a/1732454)","score":-6,"comments":[{"body":"The OP is not trying to parse html. The OP's idea is a primitive form of a templating engine / macro processor. [Server side includes](https://en.wikipedia.org/wiki/Server_Side_Includes) are a similar approach, though the SSI syntax might actually require parsing html to implement correctly.","score":6,"comments":[{"body":"True, but anytime \"HTML\" and \"regex\" appear in the same comment, this stackoverflow post is almost mandatory.","score":-1,"comments":[]}]}]}]},{"body":"If you can change the syntax of \\`Read(...)\\` you can also use [text macro processor](https://github.com/simhyeon/r4d). Yet if you need a scalable solution, I too recommend templating.","score":1,"comments":[]}]},{"title":"☘️ Good luck Rust ☘️","not_safe_for_work":false,"locked":false,"body":"As an Ada user I have cheered Rust on in the past but always felt a little bitter. Today that has gone when someone claimed that they did not need memory safety on embedded devices where memory was statically allocated and got upvotes. Having posted a few articles and seeing so many upvotes for perpetuating Cs insecurity by blindly accepting wildly incorrect claims. I see that many still just do not care about security in this profession even in 2022. I hope Rust has continued success, especially in one day getting those careless people who need to use a memory safe language the most, to use one.","score":581,"comments":[{"body":"Ada is such a cool language and it’s really a huge shame it didn’t become more commonplace - I can’t for the life of me understand why somebody would rather write MISRA C instead of SPARK. Rust takes a ton of influence from a lot of other languages, Ada is a big one.\n\nI know at a time the Rust team was trying to find people who know Ada to comment on some language design, Tucker Taft (Ada founder) and the Rust team were in touch for a while, and Graydon (Rust founder) was a fan of Ada’s spec. At least according to something I read in the past. If you know Ada well, that sort of feedback is still super valuable if you’re ever thinking of picking up some Rust.\n\n(Intro for the rustacians who don’t know Ada - it’s a pascal-derived language invented in the 80s that, like Rust, aims to strongly guard against UB. It is used in the most safety-critical embedded systems like aerospace, rail, satellites, and government stuff (I think svd2rust was heavily inspired by Ada’s tool). No raw pointers, access types instead. Absolutely killer language for embedded stuff and almost ahead of its time, unfortunately the DoD start, limited dynamic memory support at first, and “freemium“-ish compiler choices kind of hampered its chances of overtaking C)","score":96,"comments":[{"body":"Ada is a language I'm really curious about and want to give a try someday. It's funny how the first impression because of its readability is that it's fuzzy and dynamic when really it's anything but.\n\nI also love when Ada tutorials take a deep breath and start talking about why there is more than one type of string. Meanwhile my reaction is like \"well of course there is, that's just good sense\"","score":25,"comments":[]},{"body":"&gt;\tI can’t for the life of me understand why somebody would write MISRA C.\n\nThere, I fixed that for you 😂","score":14,"comments":[]},{"body":"","score":0,"comments":[]}]},{"body":"&gt; don't need [safety] on embedded devices]\n\nHa, I worked on the BE team for a fitness wearable and we had a forever bug (it was never solved) where the device would upload just hot garbage. Data packets had a technically well-formed header, but the values were bonkers. (E.g., the data was recorded on 1 Jan 1970, my favorite date.) Then the rest was just random unparseable bytes.","score":34,"comments":[{"body":"We had a similar type bug where a particular message would rarely get it's data bytes corrupted and the receiving server would detect it and drop our connection. We tracked the bug for 2-3 years. Turns out, a year or two before first (reported) detection we had split a task into two and forgot to add a mutex lock. One line fix, bug went away.\n\nTook 8-10 hours to reproduce but since it was in an agricultural application 8-12 hour runs were the normal use case for about a week a year. No fear concurrency would have been pretty darn nice.","score":27,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"I don't want to break you, but there always will be people who don't give a f\\* about everything, independent of language and year. And partially this is even encouraged by the environment.\n\n&amp;#x200B;\n\nNot rust, but: I remember a certain coworker in a SAAS backend environment. He always was the fastest in the team. However...\n\n* preventing SQL injection? Nah, too much work. If a reviewer dared to mention a problem, the reviewer was seen as the problem\n* transactions for data integrity? Nah. Followed by multiple cases of real customer data loss/corruption.\n* \"undefined variable\" in feature Z? Tell management \"that cannot be fixed, we have to live with it\"\n* Login code? Receives password there, but doesn't care to check anything, because again this is too much work. Yes I'm serious.\n\nConsequences? He got the largest salary increases and the first promotion that I've seen in that company. Problems that he caused were often mitigated by others, but they were not rewarded with anything.\n\nYes that company was bad, at least in that regard. But such people and companies will continue to exist.\n\n&amp;#x200B;\n\nAnother factor is the amount of genuinly incompetent people that feel threatened by good developers. When there are upvotes for someone saying \"memory safety isn't needed\", a few of them are people that often make relevant errors, and someone basically saying \"it's fine, don't worry, you don't need to be able to do this\" makes then feel better.","score":281,"comments":[{"body":"I think there are two groups of programmers: one care for the quality and love rust (or have not tried it); the others don't give shit about quality. This 2nd group is loved by management as they get things faster to the user. They (pm) usually thinks a few glitches are fine and can be fixed later but they never really understand the cost of it.\n\nWe were working on a multi game where it was simpler to run some validation on the client and communicate the result on REST api to a server. Dispite of any warnings of some experts, that it cannot be fixed later without another technology they pushed this useless solution to market. When they created a few challenges with real money reward they were surprised that some results were impossible and there is no tool to distinct cheaters from real users. Now we are back to the design and many things have to be restarted loosing more than a years work...","score":66,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"My day job is C - we have a big code base and we aren’t going to switch off of C any time soon. But. We have had multiple security critical bugs that would have been caught by a safe language. What really prevents us beginning to use Rust at the moment is tooling, there are certain things we can do with C for servicing that we couldn’t do in Rust today - such as hotpatching.","score":13,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"I mostly agree but with the caveat that Rust is currently not suitable for all tasks that it could theoretically be useful for. For example, many embedded devices don't have HAL libraries for Rust and avoiding huge binary bloat requires a lot of care.\n\nWhile the borrow checker and zero-cost abstractions are really, really nice, sometimes the downsides outweigh the benefits. That does not necessarily mean someone is careless; maybe they are making the best choice for their hardware or application.\n\nBut I still believe that Rust excels as a memory-safe language and should take over most of the world one day. ;D","score":47,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"I’ve been programming 20 years now, I can’t help but feel the days are numbered for C/C++ — which were my primary “favorites” until I started with Rust only a few years ago.\n\nFirst, most programmers these days just aren’t learning them and for almost any task they aren’t the best choice—excepting legacy codebases or really specific usages. And in many cases it would still be easier to just write in Rust and export C interfaces. Even UIs are going the way of Electron/etc over Qt or wxWidgets. (Maybe one day usurped by tauri? 😬)\n\nSecond, while things improved now that C++ updates more often than every decade, languages like Rust, Go, etc move much faster, and C++ *still* doesn’t have a great common build system, package management, etc. Always a joy trying to pull in dependencies that are built with a mix of makefiles, CMake, Bazel, gn, …and then try to bundle up a library targeting C++11 or C++14 if you’re really frisky because you want to make it compatible for other codebases. And the standard lib impls for things are often not the best either, because they’re just stuck with them. (regex? hash maps?)\n\ntl;dr C++ has been around longer and is playing catch-up at a snail’s pace (C++23 finally gets &lt;expected&gt;, only a decade behind Rust!), and C programmers will probably just age-out and the newer generation won’t learn C—good riddance. Rust doesn’t need luck, it just needs time. :)","score":94,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"Future of Rust, 2023 and beyond?","not_safe_for_work":false,"locked":false,"body":"Hey /r/rust. I've been a big Go fan for the past 2 years of so, but more recently have been using Rust for some personal projects over the last month and have been really enjoying it! \n\nI do have some questions about both the language and it's future in the coming years that I was wondering if the community here would have informed answers to. \n\n#1. Popularity &amp; general usage / use cases\nWhen comparing Rust vs. Go the argument is always made that Rust is better used on embedded projects or instances where you need to be particular about memory management. However my understanding is that anything you could want to build in Go you could build in Rust but not vice versa? With this in mind, is there a likelihood that Rust passes a language like Go in general usage statistics in the coming years? With the rapid rise in popularity this wouldn't surprise me, but I'm not sure if the steeper learning curve will hold Rust back from being readily accepted.\n\n#2. Cross compilation\nOne of the biggest selling points for me when I started to use Go is cross compilation; I develop on a Mac, but run a lot of my code on a Linux EC2 instance (or been doing dev work on a Windows+WSL machine) and Go's cross compilation options (either via the built in tool or via something like [gox](https://github.com/mitchellh/gox) are braindead easy. Rust's cross compilation however makes me want to drive my head thru my monitor... there are no easy ways to build a binary for Linux, Windows, AND Mac without having to dip my toes into CI services and with that comes an expense that for a hobby dev I'd prefer to not incur. Is there a brighter future for easy cross compilation with Rust?\n\n#3. Compile times\nThis is less of an issue as usually I don't mind the compile times, however when building on a local machine takes &lt;30 seconds but building on an EC2 instance takes 4+ minutes, I do wonder whether this is an improvement that we can look forward to in the future. I know the compiler is doing a lot of heavy lifting to help prevent errors so I get that I should expect it to take more time than something like Go, but 4 minutes per compile vs the way smaller time with Go means that developing on a remote machine that might not have the same specs as my PC will end up taking much longer.\n\n&amp;nbsp;\n\nOn the whole I'm very quickly appreciating and enjoying all of the intricacies Rust has to offer and am looking forward to seeing this language and community continue to grow! Error handling, an amazing type system, enums, macros, matching &amp; more are all such amazing features that I wish I could take with me when I need to do work in Go and sorely miss every time I type out \"if err != nil\" for the hundredth time in the same file. Thanks in advance for the answers, help, and guidance as I continue my Rust journey!","score":43,"comments":[{"body":"&gt;Rust's cross compilation however makes me want to drive my head thru my monitor... there are no easy ways to build a binary for Linux, Windows, AND Mac without having to dip my toes into CI services\n\nHave you seen [cross](https://github.com/cross-rs/cross)? I don't normally do multi-platform builds, but I've used it for compiling for different arches\n\nFor me if there's nothing major dynamically linked then it \"just works(TM)\". If you do need to link to something like SQLite then you can setup your own base image that provides it (the \"Custom Docker image\" section)","score":38,"comments":[{"body":"I have tried, however I haven't been able to get it to work reliably (e.g. building on windows + linux on WSL works, Mac is a lot more involved; tried building for windows + linux on Mac and I couldn't get it to work at all); I've had some luck using [zigbuild](https://github.com/messense/cargo-zigbuild) but that too doesn't seem to work for Mac.","score":8,"comments":[{"body":"If you give a concrete example then people may be able to help you get things sorted out, and it could improve documentation for the future\n\nI've used `cross` to cross compile basic web servers and the likes for Windows on Linux before. Anything more involved, and I normally already have CI running, so building in CI is the easy way already.","score":8,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"Can you please create an issue on the cross repo with the issue and what you tried?","score":3,"comments":[]}]},{"body":"For sqlite and other external crates, opt-in the \"static\" feature is the way-to-go as the sys crate would then build the external crate for you and statically linked it so that it's ultra portable.","score":6,"comments":[]}]},{"body":"For cross compilation, `rustc` can compile any rust code to any target easily once you added that target via `rustup`.\n\nIt's when you have a external C/C++ dependency that is tricky, usually requires you to install cmake, gcc, clang, pkg-config and other softwares.\n\nI recommend you to use `cross` for that, which uses a docker image that includes all built tools necessary and enables \"static\" feature on any external crate (e.g. bzip).","score":37,"comments":[]},{"body":"1. Rust is better than Go for embedded, but I would not say that that is Rust's _main_ use. It is a good use, but it is great for other uses too. For popularity it is hard to say. I think in the long run Rust will be more popular than Go, but not because people start writing projects in Rust instead of Go. Go is popular for web applications and services because it is easy to pick up and fast to write something in, and I expect that to continue. Rust's popularity will likely come from people writing Rust instead of C or C++, and there's _way_ more C++ code out there than Go.\n2. I guess you've never written C++ then, because Rust's cross-compilation is _super_ easy compared to that. Go has probably the best cross-compilation of native binaries in recent (or longer) history so it is hard to compete, though the way Go does this is by eschewing using anything other than pure Go libraries, and by not using native platform tooling. Both these can actually take away from a Rust selling point of being able to interop well with existing C infrastructure.\n3. Rust compilation will never be as fast as Go, it just won't. The reason why Go compilation is fast is because the language is simple to parse and compile, and doesn't have many static analysis checks. The whole point of Rust is that it has advanced type-level features and analysis checks built-in (e.g. lifetimes) which means \"compiling\" actually is _doing_ a lot more things than Go compiling does.","score":11,"comments":[]},{"body":"&gt; is there a likelihood that Rust passes a language like Go in general usage statistics in the coming years?\n\nI'd say so, but it's hard to predict language/tool popularity, so far from a certainty.\n\n&gt; there are no easy ways to build a binary for Linux, Windows, AND Mac without having to dip my toes into CI services and with that comes an expense that for a hobby dev I'd prefer to not incur. \n\nYeah, it definitely gets harder as you link to C/C++ dependencies, particularly to build for Windows/Mac from something else. (For Linux, if nothing else you can do it in a Docker container, well-supported on all platforms.) And I'd say linking to C/C++ deps is more common in Rust than in Go. It's probably *possible* to cross-compile, but it's hard to say more without knowing what your project's deps are, and I can't confidently say this will improve in general.\n\nfwiw, GitHub Actions is free for public repositories. CI services can be a pain but not necessarily an expense in dollars/euros/whatever.\n\n&gt; This is less of an issue as usually I don't mind the compile times, however when building on a local machine takes &lt;30 seconds but building on an EC2 instance takes 4+ minutes, I do wonder whether this is an improvement that we can look forward to in the future. \n\nIt has improved, and I think it will continue to improve, although I doubt it'll ever be as fast as Go.\n\nYou might be able to do better than 4+ minutes now. E.g., by figuring out how much is in the linking stage to see if using `lld` or `mold` is worthwhile, getting good crate boundaries to minimize how much is rebuilt (check out `cargo build --timings`), and using non-optimized builds and/or `cargo check` in development. (You can even change optimization settings crate-by-crate. I [do this](https://github.com/scottlamb/moonfire-nvr/blob/d509d3ff40160a58e4fbdd01be240f2be474b693/server/Cargo.toml#L73) in one of my projects.)","score":5,"comments":[]},{"body":"I just want a better status for async :(","score":4,"comments":[{"body":"I agree, but remember it could always be worse LOL","score":2,"comments":[]},{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"[Code Review] Brainf**k Interpreter by fresh Rust beginner","not_safe_for_work":false,"locked":false,"body":"Hi,\nA few days ago I started looking into Rust to have some fun with a  (for me) fresh language. I wanted to build a simple Brainf**k interpreter and I'm almost done (only key input is missing) but I'm sure it can be improved massively. My previous experience with low level languages was only a little bit of c/c++ and I feel like Rust could enable me to write some things in a different and clearer/easier (?) way. If anyone has time to look into it and would like to give some constructive criticism please feel free to check out the repository. Thank you 🙂\n\nhttps://github.com/pointermess/rust-brainfuck","score":10,"comments":[{"body":"[Some change suggestions](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=a5a6329be6d991af25b21387959ae022) marked with `// ******`, otherwise pretty good :)","score":4,"comments":[{"body":"Wow, thank you so much for taking the time! All suggestions are exactly what I was hoping to get, to get more familiar with the Rust concepts and how it's done \"the Rust way\". Its such a cool language, cant wait to dive deeper into it. :)","score":2,"comments":[]}]},{"body":"That's pretty good.\n\nA few nitpicks that haven't been mentioned, mostly things that you learn as you get used to the language:\n\nI was a little confused why run was recursive. You can write it as:\n\n    pub fn run(&amp;mut self) {\n        while self.step() {}\n    }\n\nor\n\n    pub fn run(&amp;mut self) {\n        loop {\n            if !self.step() {\n                break;\n            }\n        }\n    }\n\nIt doesn't matter now, but it might if you want to add anything to your run function like printing the state at certain times or limiting the number of steps to prevent infinite loops. In Rust, tail call optimization is not a guarantee and the compiler historically isn't great at it. So if you have a long running program, you might blow out the stack if the compiler isn't able to apply the optimization.\n\nincrement and decrement can panic if you run in debug mode (or if you enable overflow checks in release mode) because of integer overflow. Try running your program in debug mode with the (legal) bf program `+[+]` it will panic. You can use wrapping\\_add and wrapping\\_sub instead to avoid that.\n\n    fn decrement(&amp;mut self) {\n        self.memory[self.memory_pointer] = self.memory[self.memory_pointer].wrapping_sub(1);\n    }\n\nand the same for increment.\n\nYour print\\_state function is pretty good, it could be a `Debug` implementation too. A minor nitpick would be in the mem state printing code, instead of\n\n    let mut c = 1;\n    for byte in &amp;self.memory {\n       ...\n       c += 1;\n    }\n\nyou could do\n\n    for (index, byte) in self.memory.iter().enumerate() {\n        let index = index + 1;\n        ...\n    }\n\nbut since you are just trying to print the vec in 'chunks', you can ask just ask the vec to give you chunks in the size you want.\n\n    for chunk in self.memory.chunks(16) {\n        for byte in chunk {\n            print!(\"{:02x} \", byte);\n        }\n        println!();\n    }\n\nIf you want to be fancy, you can detect if the entire chunk is all 0s AND the previous chunk was all 0s, so you can skip or abbreviate that chunk similar to how hexdump works when printing files with large sections of repeated 0s. I leave that as an exercise to you, if you like the idea.\n\nOverall, not bad at all!\n\nEdit:\nAdd tests! You can have some sample programs, run them and inspect the program and memory state. And if you make an input and output API that uses u8/str/String instead of using `print!` you can assert the output of the interpreter as well.","score":4,"comments":[{"body":"Wow, thats a lot of useful feedback and information, thank you so much! :) I have re-implemented the loops and bug-fixes as you suggested, the fibonacci example now runs for as long as the memory allows. \\^\\^\n\nYour suggestion with the improved memory output is great, I will try to implement this very soon. I could easily do it the C/C++ way but I will look if Rust has something to offer or a \"way to go\" for this case. (which im sure it does) Some things in Rust still feel very strange to me (especially Vec and Slice) but I'm slowly getting there \\^\\^\n\nI have also started adding unit-tests as you suggested and (surprise, surprise) found a bug in the move\\_right function which I was able to fix as well. I'm surprised how easy unit testing in Rust is. No additional libraries and only minimal setup was required. :)\n\nAgain, thank you so much for your help and time, you helped me a lot! =)","score":1,"comments":[]}]},{"body":"Next you could try implementing the trait From&lt;char&gt; for Operation instead of using from_char :)","score":2,"comments":[{"body":"Perfect, thank you so much, I didnt know that trait yet and have just implemented it. Its much cleaner that way. :)","score":1,"comments":[]}]},{"body":"Also consider modelling your operations differently: rather than having +++ be 3 separate Operation::Increment you could have a lexing stage where you group those to a Operation::Increment(3) for example.","score":2,"comments":[{"body":"Yeah, thats something I have considered already by completely parsing the program at startup and creating some kind of model.\n\nIt should also speed up the the looping commands as I can save their start and end locations while parsing. :)\n\nI will probably do that as soon as I am finished with the current code. =)","score":1,"comments":[]}]}]},{"title":"We are glad to announce RustSBI 0.3.0, a RISC-V bootloader environment framework in pure Rust","not_safe_for_work":false,"locked":false,"body":"RustSBI is an implementation of the SBI standard under RISC-V, it amis to provide good SBI environment support for bare-metal RISC-V platforms, virtualization and simulator software. It organically combines the Rust embedded ecosystem and RISC-V system software to speed up development while ensuring the good security and operational performance of the Rust language.\n\nThe version 0.3.0 mainly include instant based SBI interface support and related constructor structures, compile in stable Rust, remove the dependence on heap memory and global variables, improve related documents, and several minor fixes. The 0.3.0 version update will provide good support for RISC-V virtualization software and RISC-V simulators written in Rust, and further improve the practicability of bare-metal RISC-V development. It can start mature operating systems such as Linux and research operating systems including zCore, etc.\n\nWith the release of the official version of RustSBI 0.3.0, the ecological chain project of RustSBI has matured, and the brewing \"RustSBI prototyping system\" is also under active development. The kernel running tool `sbi-rt`, the constant and structure package `sbi-spec`, and the specification test set `sbi-testing` have all been finalized, released a preview version, and entered the dependency options of the actual project. \"RustSBI prototyping system\" does not focus on prototyping only, but provides a rapid development solution. After development completed, it will allow manufacturers to adapt the SBI interface to their own RISC-V motherboards and platforms in the shortest possible time. And directly obtain advanced functions such as Penglai TEE, @dramforever's software simulation virtualization and Raven firmware debugger. At the same time, contributors and user groups have also responded to RustSBI and its new version.\n\nActive community contributor @YdrMaster believes that RustSBI software is the expression of community power in the RISC-V SBI ecosystem. \"RustSBI helped me explore 'below the kernel (M state)' and 'before the kernel (bootloader)'; compared to OpenSBI, its implementation is more concise and clean, and its construction method is more modern, which can provide a better development experience and operating space \", YdrMaster said, \"In addition to having all the advantages of Rust, it also has the abstraction of library + implementation. It is not necessary to stuff all implementations into one warehouse, and there are different implementations for different requirements for a piece of hardware. If you need a new implementation, You can redo only the parts you care about, and reuse the rest. Plus, it runs fast, which is evident during continuous kernel testing.\"\n\nDaniel Maslowski, a longtime contributor to the Oreboot project, says RustSBI simplifies the development of a complete bootloader. \"RustSBI is the SBI implementation in the Rust ecosystem, it helps to remember what (the SBI service) needs in RISC-V, and has all the constants and structures defined\", Daniel said, \"Rust is one of its specialties , (in bootloader development) I don't need additional components or code libraries. This way, for quite a few SoCs, we can provide a single initialization stage for the firmware, as long as it fits into SRAM, like what I did for the JH7100 (128K).\"\n\n@LoanCold of the UltraOS team believes that, in terms of its contribution to the RISC-V SBI ecosystem, RustSBI can continue to flourish and give developers more choices. \"The UltraOS team I participated in implemented the operating system written in Rust and used the RustSBI project. From the perspective of the project, better developer support and more powerful K210 development board support are the biggest benefits for me,\" said LoanCold \"Our team has also changed RustSBI to achieve better functions. This is the benefit of open source or further open source, or the benefits of RustSBI's more complete annotations. It also enables us to better support the K210 platform This is what OpenSBI cannot do. In the future, RustSBI can achieve vertical integration, attract stable users, improve platform support and automated testing, and ensure long-term stable operation of system-level applications.\"\n\n\"Comparing with the past two years, the RustSBI ecosystem and users are further expanding this year. In addition to research and educational uses, we are happy to see more companies from the industry contributing to the RustSBI ecosystem,\" Luo Jia said, \"BL808's official Rust support The library is a good start. Small and large core support, virtualization and emulator support, and security features, these are the parts that RustSBI is good at. Whether users choose the innovative full-stack Rust implementation or take into account the traditions such as U-Boot, UEFI or EDK II For the realization of software, RustSBI can well support and cooperate with the development of industrial software. In the performance test we applied to the simulator, RustSBI showed extraordinary performance, and some performance indicators reached several times that of competitors. We hope Share the excellent features of RustSBI with all bootloader software, whether it is C or Rust - ecosystem participants can work together to improve the security and stability of the bootloader industry.\"\n\nKey contributors to this update are @duskmoon314, @OrangeCMS, @YdrMaster and @luojia65.\n\nProject link: [https://github.com/rustsbi/rustsbi](https://github.com/rustsbi/rustsbi)\n\nRelease page: [https://github.com/rustsbi/rustsbi/releases/tag/v0.3.0](https://github.com/rustsbi/rustsbi/releases/tag/v0.3.0)\n\nSource: [https://rustcc.cn/article?id=18318ed2-d6b3-461c-a599-fe140ef41713](https://rustcc.cn/article?id=18318ed2-d6b3-461c-a599-fe140ef41713)","score":86,"comments":[]},{"title":"Unreachable match statement, but reachable return value directly after, in the same scope","not_safe_for_work":false,"locked":false,"body":" I am creating a terminal chess game, and working on taking user input for moves using standard chess notation.\n\n \n\n`fn player_move(&amp;self) -&gt; Result&lt;i8, Box&lt;dyn Error&gt;&gt; {`  \n `let mut user_move = String::new();`  \n `println!(\"Make a move.\");`  \n `let mut piece = user_move.substring(0, user_move.len() - 2);`  \n `let mut new_pos;`  \n `while piece.len() &lt; 2 {`  \n  `let stdin = io::stdin();`  \n  `stdin.read_line(&amp;mut user_move);`  \n  `piece = &amp;user_move.substring(0, user_move.len() - 2).to_lowercase();`  \n  `new_pos = &amp;user_move.substring(user_move.len() - 2, user_move.len()).to_lowercase();`  \n `}`  \n `let mut pos = match new_pos.chars().nth(0).unwrap() {`  \n  `'a' =&gt; 1,`  \n  `'b' =&gt; 2,`  \n  `'c' =&gt; 3,`  \n  `'d' =&gt; 4,`  \n  `'e' =&gt; 5,`  \n  `'f' =&gt; 6,`  \n  `'g' =&gt; 7,`  \n  `'h' =&gt; 8,`  \n  `_ =&gt; 0,`  \n `};`  \n `pos += match new_pos.chars().nth(0).unwrap() {`  \n  `'1'`  \n  `'2'`  \n  `'3'`  \n  `'4'`  \n  `'5'`  \n  `'6'`  \n  `'7'`  \n  `'8'`  \n `}`  \n `Ok(1)`  \n`}`\n\nThe second match statement is being regarded by VSCode as unreachable, but I cannot seem to figure out why.  Even stranger, the returning of Ok(1) is marked as reachable.","score":0,"comments":[{"body":"Well, I see two problems with the second match statement; no match arms and it isn't semicolon terminated.  There's a third logical problem where you want nth(1) for extracting the numeric part of chess notation.","score":2,"comments":[]}]},{"title":"I made a randomizing link shortener using Yew and daisyUI","not_safe_for_work":false,"locked":false,"body":"","score":30,"comments":[{"body":"For an event at https://hellopaint.io we needed something that forwards to a random url from a list of urls (We created multiple drawing rooms and wanted people to evenly distribute across them during a twitch stream).  \nSince I couldn't find any such service, I made one myself. (later I found this: https://randurl.com/ but it doesn't provide any statistics)  \n\n\nHurlurl could also be used to forward to a random Website or a random YouTube video, but I'm thinking if I should limit it so all links have to redirect to the same domain, to limit the potential of abuse.\n\n  \nUsing Yew with daisyUI was a really nice experience, I can recommend it if you want to use Yew. Although I probably would have been much faster if I had used React for the UI.\n\nhttps://github.com/lucasmerlin/hurlurl","score":12,"comments":[]},{"body":"Neat project, mate.\nThank you for sharing it.","score":3,"comments":[]},{"body":"OP, quick question.\nDo you intend to leave the public instance up and running for long? If so then I'd add a donation section at the top/bottom.\n\nThis definitely has use cases for some but maybe not everyone will try to self-host.","score":3,"comments":[{"body":"I intend to keep it running, as long as it's affordable I'll pay from my own pocket but should it become really popular I might add a link to my patreon to the site (I already have one for some other projects).\nBut for now I'm rather wondering how I'd get anyone to use the site.","score":3,"comments":[{"body":"I tried spreading word about it in my personal circles but I doubt word of mouth is enough.\n\nMy suggestion is posting about it on HN and Reddit. (r/selfhosted) \n\nAlso if the public instance doesn't log the visitor's IP or any other info and  if the server has no knowledge of the URLs i.e. has zero-knowledge properties then you can rope in people from r/privacy as well.","score":3,"comments":[{"body":"Thanks for spreading the word!","score":1,"comments":[]}]}]}]},{"body":"OP, I think a video walkthrough of the project will be greatly appreciated.","score":1,"comments":[{"body":"You mean like a tutorial video of how I made the project? I'll think about it!","score":2,"comments":[]}]}]},{"title":"Are multiplayer browser games a good use-case for Rust ?","not_safe_for_work":false,"locked":false,"body":"I don't know Rust yet, and I have a project in mind which would be the opportunity to learn it. I know I'm on a Rust subreddit so people will be biased to answer yes, but I would highly appreciate to know if the ecosystem is mature enough yet for such thing, I'll probably learn Rust either way haha\n\nI want to make a multiplayer game running in the browser, something like [agar.io](https://agar.io) [diep.io](https://diep.io) . For such game you need a server using websockets, a frontend using canvas, and to prevent cheating the game logic must be verified server-side (see [this article](https://www.gabrielgambetta.com/client-server-game-architecture.html) ). This means that if you use different languages for the server and the frontend, the game logic must be duplicated. So my idea was to write the game engine a single time in Rust, and use it both on the server and the frontend, with the frontend running in wasm, and then using canvas/webgl for rendering. To summarize:\n\nRust server &lt;----websockets----&gt; Rust wasm frontend &lt;-------&gt; WebGL / Canvas \n\nHowever I've also read that interactions between wasm and webgl could be slower than native code: [this thread](https://www.reddit.com/r/rust/comments/qg258e/comment/hi3gi78/?utm_source=share&amp;utm_medium=web2x&amp;context=3)\n\nSo what do you think ? Is this use-case well supported by Rust yet ? (websockets, wasm, canvas)","score":9,"comments":[{"body":"I'm kind of trying the same thing and use rust+bevy ecs.\n\nThe Headless (no gui) simulation of the game is run on the server, and gui / input stuff on the client. Common code is shared.\n\nFor the server infrastructure I am planning to use naia.rs because this enables WebRTC communication, which is kind of like UDP but has much less overhead than websockets (TCP) and higher throughput. Much more suitable to the Realtime games you described!\nThe downside to this is transport reliability, deal with this by sending lots of data.\n\nThere's also another project (forgot its name..), that enables true peer-to-peer from the browser. its essentially a rendezvous-Relais.\n\nMight be an option for you if you want to save on cost. \n\nKeep us updated in r/rust_gamedev!\n\nedit: the project i meant is called matchbox https://github.com/johanhelsing/matchbox","score":11,"comments":[]},{"body":"I'm not aware of any current use/case scenarios but I grew up on runescape if you want to look towards that as an example of them just using JavaScript/java.","score":1,"comments":[]},{"body":"&gt; This means that if you use different languages for the server and the frontend, the game logic must be duplicated\n\nNot quite. The whole point is as client and server play different roles, so you'd rarely be able to reuse much regardless of language.\nThis shouldn't be the motivation to pick Rust.\n\nIf you haven't made anything similar before, I suggest you don't get too adventurous with your stack. There's not going to be a whole lot og resources or similar projects to learn from.\n\nMultiplayer games are one of the projects that beginners  most commonly and most severely underestimate the difficulty of. It's easy to get over ambitious when you just have this cool concept and vision in mind.\n\nAppreciate what you're getting yourself into and make things easy for yourself by picking tools that are well documented for the task and where there's plenty of similar work to study. I'd at least stick to making the backend in Rust.\n\nIn short:  \nWould it be possible? Yeah.  \nWould it be cool af? Absolutely!  \nWould I do it in your shoes? Probably not.","score":-1,"comments":[{"body":"Thanks for the feedback, I'll start with Rust only for the backend then","score":1,"comments":[]},{"body":"&gt; The whole point is as client and server play different roles, so you'd rarely be able to reuse much regardless of language.\nThis shouldn't be the motivation to pick Rust.\n\nJust about any multiplayer game is going to represent the game logic on both ends. Sharing that code not only saves time but also prevents bugs from client-side logic not matching server-side.","score":1,"comments":[]}]},{"body":"Yes, Rust is a good choice for this (I'm experimenting with a similar game architecture myself). Of course the more program logic and data structures you share between client and server the higher benefits are of using the same language for both.\n\nThe main benefit of using Rust compared to using JavaScript, Kotlin, Scala, C# etc. is that the server will be really efficient, and issues like GC pauses are eliminated. On the client side the performance benefit of using Rust is probably quite low because you're typically limited by graphics performance.","score":1,"comments":[]}]},{"title":"&amp;dyn Fn doesn't always act like a function?","not_safe_for_work":false,"locked":false,"body":"hi,\n\nI've been learning rust for a couple months now, and I recently tried to write a tree walker using dynamic dispatch against &amp;str values instead of the visitor pattern.  It seems like &amp;dyn Fn doesn't work like fn or &amp;impl Fn when type parameters are involved, and this freaks me out.\n\nHere's a real world example of dyn Fn's unfunction-like behavior that I've simplified as much as possible:\n\n    pub struct BorrowedString&lt;'r&gt;(&amp;'r mut String, );\n    impl Write for BorrowedString&lt;'_&gt; {\n        fn write_str(&amp;mut self, s: &amp;str) -&gt; fmt::Result {\n            Write::write_str(self.0, s)\n        }\n    }\n    pub mod example2 {\n        use super::*;\n        \n        trait Func&lt;T: Write&gt; = Fn(&amp;ElementRef, &amp;mut T);\n        trait DynFunc&lt;'r&gt;: 'r {}\n        impl&lt;'r, T: Write&gt; DynFunc&lt;'r&gt; for &amp;'r dyn Func&lt;T&gt; {}\n        \n        struct Dispatcher&lt;'r, F: DynFunc&lt;'r&gt;&gt;(HashMap&lt;&amp;'r str, F&gt;, );\n        impl&lt;'r, F: DynFunc&lt;'r&gt;&gt; Dispatcher&lt;'r, F&gt; {}\n        fn generic_method(input: &amp;ElementRef, out: &amp;mut impl Write) {\n            write!(out, \"using {}\", input.value().name()).unwrap();\n        }\n\nIf I attempt to build a dispatcher then use it with ElementRef and Write BorrowedString instances like so:\n\n        #[test]\n        pub fn bs_output() {\n            type BsDispatcher&lt;'r&gt;\n                = Dispatcher&lt;'r, &amp;'r dyn Fn(&amp;ElementRef, &amp;mut BorrowedString)&gt;;\n            let mut d: BsDispatcher = Dispatcher(HashMap::new());\n            d.0.insert(\"html\", &amp;generic_method);\n\nI start getting type errors like this:\n\n    error: implementation of `example2::DynFunc` is not general enough\n      --&gt; src/junk.rs:91:20\n       |\n    91 |         let mut d: BsDispatcher = Dispatcher(HashMap::new());\n       |                    ^^^^^^^^^^^^ implementation of `example2::DynFunc` is not general enough\n       |\n       = note: `example2::DynFunc&lt;'_&gt;` would have to be implemented for the type `&amp;dyn for&lt;'a, 'b, 'c, 'd&gt; Fn(&amp;'a scraper::ElementRef&lt;'b&gt;, &amp;'c mut junk::BorrowedString&lt;'d&gt;)`\n       = note: ...but `example2::DynFunc&lt;'_&gt;` is actually implemented for the type `&amp;dyn for&lt;'a, 'b, 'c&gt; Fn(&amp;'a scraper::ElementRef&lt;'b&gt;, &amp;'c mut junk::BorrowedString&lt;'0&gt;)`, for some specific lifetime `'0`\n\nI don't see how this is an error.  In particular, I don't see how any specific lifetime can satisfy 'd but not '0, so given that functions are functions, I don't see the problem.  I also don't see how this is an error, because code that refers to BorrowedString directly rather than through the type parameter F works just fine.  I'm at a loss to explain why rust treats this pattern as an error and how rust programmers live with it.  \n\nAlso, having skimmed The Rust Language, The Rust Reference, The Rustonomicon, and Rust Design Patterns multiple times, and I continue to be surprised that this issue and the related issue of false data dependencies and lifetime inversions (eg parameterizing Dispatcher on W: Write) isn't talked about anywhere.  Is there a better source of reading material I'm not finding?\n\nHere's the working simplification if you are curious:\n\n    pub mod example0 {\n        use super::*;\n        pub trait Func = Fn(&amp;ElementRef, &amp;mut BorrowedString);\n    \n        pub struct Dispatcher&lt;'r&gt;(HashMap&lt;&amp;'r str, &amp;'r dyn Func&gt;, );\n        impl&lt;'r&gt; Dispatcher&lt;'r&gt; {\n            pub fn generic_method(input: &amp;ElementRef, out: &amp;mut BorrowedString) {\n                write!(out, \"using {}\", input.value().name()).unwrap();\n            }\n        }\n    \n        #[test]\n        pub fn bs_output() {\n            let mut d: Dispatcher = Dispatcher(HashMap::new());\n            d.0.insert(\"html\", &amp;Dispatcher::generic_method);\n            with_dispatcher(&amp;d);\n    \n            fn with_dispatcher(d: &amp;Dispatcher) {\n                let doc = Html::parse_fragment(\"\");\n                let elt = doc.root_element();\n                let f = d.0.get(elt.value().name()).unwrap();\n                let mut inner = String::new();\n                let mut o = BorrowedString(&amp;mut inner);\n                f(&amp;elt, &amp;mut o);\n                assert_eq!(\"using html\", o.0);\n            }\n        }\n    }","score":13,"comments":[{"body":"I notice that you have a `&amp;mut` to something that has a lifetime, essentially `&amp;'x mut SomeType&lt;'y&gt;`.  Be _extremely careful_ about this because `&amp;mut` is _invariant_.  You _would_ end up needing to put separate lifetimes to each `&amp;mut` reference, plus other lifetimes to what they point to (i.e. `'x : 'y`).\n\n`&amp;mut` is a pain.\n\nUsually when the compiler complains that your function is not general enough, you're equating a lifetime that you pass on to `&amp;mut` with something other lifetime, in which case the two must _equal_.  One cannot even wrap the other, because `&amp;mut` is invariant.\n\nSo the moral of the story is, if you see `&amp;mut`, be prepared not to mix its lifetime with anything else.  Or you gotta put in a `for&lt;'a&gt;` trick.\n\nEither way, again, `&amp;mut` is a pain.  Good luck.","score":9,"comments":[{"body":"&gt;  I notice that you have a &amp;mut to something that has a lifetime, essentially &amp;'x mut SomeType&lt;'y&gt;. Be extremely careful about this because &amp;mut is invariant. You would end up needing to put separate lifetimes to each &amp;mut reference, plus other lifetimes to what they point to (i.e. 'x : 'y).\n\nDo you have any idea of why &amp;mut is invariant by edict, instead of through inference on lifetime variables?  For a long time, I was assuming the latter and interpreted this problem as a shortage of lifetime variables (one per generic invocation instead of one per type parameter reference).  I still think so, and I don't see why rust insists on expanding lifetimes of type parameters when applying a generic instead of when it sees a type parameter reference.  Anyone have a clue of what would happen (in terms of both correctness and compile time) if it was more lazy in terms of lifetime elision?","score":1,"comments":[{"body":"Yes, it is really hard to get.  Try this:\n\nhttps://www.youtube.com/watch?v=iVYWDIW71jk&amp;t=64s\n\nBasically, `&amp;mut` needs to support both read and write, so the lifetimes must match exactly as read and write require different variances...","score":1,"comments":[]}]}]},{"body":"I'm not sure if this is what you're looking for, but adding a couple more lifetimes makes it compile at least.\n\nhttps://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2021&amp;gist=9c6fddf5edff77777139f78b94d5f48d\n(I had to mock some data structs and stuff too since I have no idea where some of your types are coming from)","score":5,"comments":[{"body":"That compiles because you changed the type of BsDispatcher&lt;'r&gt; from\n\n    Dispatcher&lt;'r, &amp;'r dyn Fn(&amp;ElementRef, &amp;mut BorrowedString)&gt;;\n\nto\n\n    Dispatcher&lt;'r, &amp;'r dyn Fn(&amp;ElementRef, &amp;mut BorrowedString&lt;'r&gt;)&gt;;\n\nwhich is what I'm trying to avoid.  Functions in the dispatch table are always going to outlive any value of the output argument that is eventually passed in.  Another way to state my problem is \"lifetime elision for &amp;dyn Fn generic types doesn't work the same as lifetime elision for other function types (making it impossible to use fully use functions in the normal way).\"\n\nBut even with your change, the full unit test still fails because the lifetimes are now explicitly wrong: https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2021&amp;gist=0e23a3fa9a549684e6f7822ea69f1253\n\nWhile the non-generic version works with your rendition of ElementRef: https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2021&amp;gist=4b9d7dc6abb5852d5de2b1dc67c5bfdf","score":4,"comments":[]}]}]},{"title":"Rust Challenge: write a function that takes a generically sized array of keys (K) and a mut ref Vec&lt;(K, V)&gt;, and returns an array of mut ref Values","not_safe_for_work":false,"locked":false,"body":"More precisely, your function signature is this:\n\n    pub fn get_muts_or_default&lt;const LEN: usize&gt;(&amp;mut Vec&lt;(K, V)&gt;, keys: [&amp;K; LEN]) -&gt; Result&lt;[&amp;mut V; LEN]&gt;\n\nIf the key is not found, it should push the vec with default, and return a mut ref to that new entry. Bonus points if you want to use macros and tuples to accomplish the same functionality\n\nHere's my solution! Far from perfect but I think it's decent!\n```rust\n    pub fn get_muts&lt;const LEN: usize&gt;(&amp;mut self, keys: [&amp;K; LEN]) -&gt; CommonResult&lt;[&amp;mut V; LEN]&gt;\n    where\n        V: Debug,\n    {\n        let mut refs = self.iter_mut();\n        let vec = keys\n            .iter()\n            .map(|key| refs.find(|elem| key == &amp;&amp;elem.0).map(|x| &amp;mut x.1))\n            .collect::&lt;Option&lt;Vec&lt;&amp;mut V&gt;&gt;&gt;()\n            .ok_or_else(|| CommonError::KeyNotFound(String::new()))?;\n        Ok(vec.try_into().unwrap())\n    }\n\n    pub fn get_muts_or_default&lt;const LEN: usize&gt;(&amp;mut self, keys: [&amp;K; LEN]) -&gt; CommonResult&lt;[&amp;mut V; LEN]&gt;\n    where\n        V: Debug + Default,\n    {\n        // add a default if it doesn't exist\n        for key in keys {\n            if self.iter().all(|x| &amp;x.0 != key) {\n                self.insert((key.to_owned(), V::default()));\n            }\n        }\n        self.get_muts(keys)\n    }\n```\n\nWould love to see an unsafe implementation that makes the inserting defaults faster.","score":0,"comments":[{"body":"why vec instead of e.g. hashmap?","score":3,"comments":[{"body":"Was just my original use case, could totally be a hash map","score":1,"comments":[{"body":"","score":0,"comments":[]}]}]},{"body":"What are the bounds on `K`? `Eq`? Or `Eq + Hash`/`Ord`? What happens if more there's more than one occurence of a key in `Vec`?","score":2,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"In safe code, it should be sorting the keys according to their positions in the vec and split_at_mut all the way down","score":2,"comments":[]},{"body":"Here's my solution! Far from perfect but I think it's decent!\n\n```rust\n    pub fn get_muts&lt;const LEN: usize&gt;(&amp;mut self, keys: [&amp;K; LEN]) -&gt; CommonResult&lt;[&amp;mut V; LEN]&gt;\n    where\n        V: Debug,\n    {\n        let mut refs = self.iter_mut();\n        let vec = keys\n            .iter()\n            .map(|key| refs.find(|elem| key == &amp;&amp;elem.0).map(|x| &amp;mut x.1))\n            .collect::&lt;Option&lt;Vec&lt;&amp;mut V&gt;&gt;&gt;()\n            .ok_or_else(|| CommonError::KeyNotFound(String::new()))?;\n        Ok(vec.try_into().unwrap())\n    }\n\n    pub fn get_muts_or_default&lt;const LEN: usize&gt;(&amp;mut self, keys: [&amp;K; LEN]) -&gt; CommonResult&lt;[&amp;mut V; LEN]&gt;\n    where\n        V: Debug + Default,\n    {\n        // add a default if it doesn't exist\n        for key in keys {\n            if self.iter().all(|x| &amp;x.0 != key) {\n                self.insert((key.to_owned(), V::default()));\n            }\n        }\n        self.get_muts(keys)\n    }\n```","score":2,"comments":[]},{"body":"Definitely needs unsafe because uniqueness of keys cannot be proven by compiler, so non-alias rule for &amp;mut V cannot be guaranteed. Is uniqueness of keys ensured by contract?","score":0,"comments":[{"body":"You can actually do this with safe rust (although I think the generated byte code is far from optimal)","score":1,"comments":[{"body":"it'd probably be abusing split_at_mut right?","score":2,"comments":[{"body":"You can do it that way, you can also do it in two passes. The first you extend the collection with missing keys, then in the second you can use iter_mut to push out the refs.","score":2,"comments":[]}]}]},{"body":"","score":0,"comments":[]}]},{"body":"I recently cam across this problem and thought it might be interesting for others to try. My solution is also non optimal so I'm hoping someone comes up with something even better!","score":1,"comments":[]},{"body":"","score":0,"comments":[]}]},{"title":"[Media] I love the match auto complete most of the time, but today it made me laugh and shake my head.","not_safe_for_work":false,"locked":false,"body":"","score":413,"comments":[{"body":"How do you have time to post here with such a long todo list? :)","score":209,"comments":[]},{"body":"Monster match statement isn't real, he can't hurt you.\n\nMonster match statement:","score":45,"comments":[{"body":"(He did the match) He did the monster match 🎶","score":36,"comments":[]}]},{"body":"When you need a Karnaugh map to streamline your match arms","score":79,"comments":[{"body":"Damn, I hadn't heard of those in a while..","score":5,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"me when `Quick Fix...`","score":17,"comments":[]},{"body":"the marvels of modern technology","score":15,"comments":[]},{"body":"Cross product do be big sometimes","score":126,"comments":[{"body":"\\*cartesian product","score":105,"comments":[{"body":"Thanks for correcting me. That's how I learn.","score":31,"comments":[{"body":"","score":0,"comments":[]}]}]}]},{"body":"","score":0,"comments":[]}]},{"title":"GitHub - facebook/sapling: A Scalable, User-Friendly Source Control System.","not_safe_for_work":false,"locked":false,"body":"","score":0,"comments":[{"body":"2 of it's 3 components aren't available to the public. It seems like that would make it unusable. Why even publish it then?","score":4,"comments":[]}]},{"title":"Cloning an array of structs in wasm is much slower than on native","not_safe_for_work":false,"locked":false,"body":"Running the exact same code\nOn wasm, it takes around 10 seconds to complete\nOn native (macbook pro), it takes only around 500ms\n\nI am not communicating between js and rust for the wasm test, just start the benchmark after js called rust.\n\nDoes anybody know if memory allocation on wasm is much slower than on native? Or is there other explanation for this?\n\nEdit:\nReran the test on firefox, it is near native speed, it is only slow on chrome.","score":23,"comments":[{"body":"There's necessarily some overhead with WASM for JIT-compilation and runtime checks, but it shouldn't be on the order of a 20× slowdown.\n\nBasic checklist:\n\n* Which WASM runtime or browser are you using?\n* Which allocator are you using on WASM?\n* Were both examples compiled in release mode?","score":19,"comments":[{"body":"I thought the point of WASM was built exactly to not rely on a JIT, and that instead it was compiled ahead-of-time in the browser?","score":3,"comments":[{"body":"Wasm software is deployed in a bytecode format. The browser/runtime then may compile the Wasm bytecode to machine code, or interpret it. So this is comparable to the Java model.\n\nWhether this is JIT or AOT compilation depends on perspective. From my perspective it is JIT, because machine code is only generated after we load the Wasm into the runtime, if at all.\n\nAt least on Chrome/V8, Wasm is definitely executed with a JIT compiler. There's a fast “Liftoff” assembler, and a concurrent “TurboFan” optimizing JIT compiler that compiles the module function by function and then patches the optimized functions into the already-running Wasm module. But by default compilation+optimization is eager, not lazy as in the JVM. Source: https://v8.dev/docs/wasm-compilation-pipeline","score":33,"comments":[{"body":"Very interesting, thanks for the explanation :)","score":2,"comments":[]},{"body":"&gt; Whether this is JIT or AOT compilation depends on perspective. From my perspective it is JIT, because machine code is only generated after we load the Wasm into the runtime, if at all.\n\nIt's AOT if it compiles the entire translation unit before running it, with no PGO-esque feedback for which machine instructions to emit.\n\nIt's JIT if it compiles code paths during execution in response to gathered metrics on which paths are hot enough to justify the compilation cost. That's the whole *point* of the term \"Just In Time\".\n\nOtherwise, you conflate the meaning of JIT with things like the \"compiled programs are arch-independent object code which get transparently compiled by the OS on the machine\" approach of IBM mainframes to the point of useless.","score":1,"comments":[{"body":"I understand where you're coming from, but limiting the concept of JIT only to on the fly reoptimization would go against industry understanding. Maybe a more actionable definition would be that JIT happens if the compiler shares the address space into which the compiled code will be linked?\n\nI think a better solution is to see interpreted vs compiled and JIT vs AOT not as a binary, but as a gradient. On the extremely JITish side of things we have self-modifying code and Hotspot-style profile-guided reoptimization. On the extremely AOTish side of things we have classical C compilers.\n\nWhile V8 is clearly a JIT engine, its Wasm parts don't seem to do re-optimization.\n\n&gt; Otherwise, you conflate the meaning of JIT with things like the \"compiled programs are arch-independent object code which get transparently compiled by the OS on the machine\" approach of IBM mainframes to the point of useless.\n\nNo, I think it's extremely useful to say that such approaches use JIT techniques. Not just IBM mainframes, JIT is also mainstream for state of the art emulation technologies like QEMU or Apple's Rosetta.","score":5,"comments":[{"body":"&gt; I understand where you're coming from, but limiting the concept of JIT only to on the fly reoptimization would go against industry understanding. Maybe a more actionable definition would be that JIT happens if the compiler shares the address space into which the compiled code will be linked?\n\nI'm not saying it's limited to on-the-fly reoptimization so much as \"piecemeal, on-demand compilation\".\n\nPiecemeal and on-demand being the opposite of Ahead Of Time.\n\n&gt; I think a better solution is to see interpreted vs compiled and JIT vs AOT not as a binary, but as a gradient. On the extremely JITish side of things we have self-modifying code and Hotspot-style profile-guided reoptimization. On the extremely AOTish side of things we have classical C compilers.\n\nThat's fair.\n\n&gt; While V8 is clearly a JIT engine, its Wasm parts don't seem to do re-optimization.\n\nWhy is it necessary for it to be only \"a JIT engine\"?\n\n&gt; No, I think it's extremely useful to say that such approaches use JIT techniques.\n\nAgain, my understanding is that IBM mainframes don't do piecemeal, on-demand compilation.\n\nLikewise, AOT compilation of WebAssembly is generally more like the at-install-time bytecode-to-machine code compilation that Android does for apps these days... so you could think of WebAssembly as obscuring an \"install time\" vs. \"run time\" distinction between ISA-independent AOT and JIT.","score":2,"comments":[]}]},{"body":"","score":0,"comments":[]}]}]}]},{"body":"1. I am testing it on browser\n2. I am not sure what does it mean by allocator, in my case, I am just doing the same operation (basically doing a .clone on a vector)\n3. The code is compiled in release mode for both test\n\nSome additional notes: \nI added a Instant::now() before calling the clone, and console.log the elapsed time as millis immediately after the clone, so it shouldn’t be affected by anything else","score":1,"comments":[{"body":"","score":0,"comments":[]}]}]},{"body":"WASM memory is allocated by the WASM engine aka the web browser for 99% of the cases so it doesnt share the same speed or specs as Rust\n\nWeb assembly is a name which focus on portability accross platforms while also having a decent performance, it wont be as fast as real ASM because it has ASM on the name, marketing can call things whatever but reality is what it is","score":7,"comments":[]},{"body":"Can you show the code? You may want to activate bulk memory.","score":3,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"State of the art of isomorphic webapps?","not_safe_for_work":false,"locked":false,"body":"I'm basically asking the same question as [https://www.reddit.com/r/rust/comments/t4x6lm/state\\_of\\_the\\_art\\_of\\_isomorphic\\_webapps/](https://www.reddit.com/r/rust/comments/t4x6lm/state_of_the_art_of_isomorphic_webapps/), but since that one is 9 months old at the time of writing I'm curious to see if any other players have entered the scene or if there have been any major steps forward.","score":6,"comments":[]},{"title":"We just launched Jetty: a Rust CLI tool to visualize cross-stack permissions for data teams","not_safe_for_work":false,"locked":false,"body":"Data teams use a lot of tools and understanding how access is configured across the growing stack is complex and exhausting. \n\nJetty is a tiny peek at our broader vision of simplifying data privacy and we'd love you to give it a try and offer any feedback. It's free to use and available via \\`pip\\`! You heard that right, our pure Rust tool is distributed with Python tooling. It's familiar with the data community, and thanks to Maturin getting it all to work was not a huge deal.\n\nHere's our first blog post about why we're tackling this problem, including why we chose to go against the Python/JVM patterns of typical data tooling: [https://docs.get-jetty.com/blog/2022/11/17/hello-jetty](https://docs.get-jetty.com/blog/2022/11/17/hello-jetty)\n\nThe code isn't available (yet) but I will follow up when we open the repository for others to check out!","score":4,"comments":[]},{"title":"Public methods returning private structs","not_safe_for_work":false,"locked":false,"body":"Hello everyone,\n\nI’ve been playing with actix-web recently, but you read the title : when I want to delegate the App creation to a function, the type is private. I can’t put it in the return type. (For example, the `App::new().service…`)\n\nFor example, you can do this :\n\n`let app = App::new().service(yes)`\n\nBut can’t do :\n\n    let app = webapp();\n\n    fn webapp() -&gt; ???? {\n        App::new().service(yes)\n    }\n\nDo you have any workaround to this ? Thanks !","score":4,"comments":[{"body":"If a function is public, all types in its signature (arguments, return type) must also be public. So, you just need to make the returning type public.\n\nYou aren’t required to make any fields or methods on that struct public, but if you do, any related types also need to be public.","score":10,"comments":[{"body":"Well, that's not strictly true since it can be public, but the module private meaning you have no way to reference the type.\n\nThat's the situation they're referring to: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=299820a355021982d874264a4b7231c1](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=299820a355021982d874264a4b7231c1)\n\nAnd the issue is if you don't control these types - ie. it's an external crate like actix-web.","score":6,"comments":[{"body":"Honestly kind of surprising that there really seems to be no way to get at that type. I'd have thought that it should be possible to get at it via `FnOnce`'s `Output` type but apparently, functions can't be used as types even though they really are their own types.\n\nThe best I was able to come up with is\n\n    fn f&lt;T&gt;(f: fn() -&gt; T) -&gt; impl Fn() -&gt; T {\n        move || { f() }\n    }\n\nwhich kinda allows you to write a function that returns the type though you have to call it with `f(a::a)()`.\n\nIt's also not possible to assign it to a constant (`const ff = f(a::a)`) since you need to name the type of the constant.\n\nI wonder if impl trait in type aliases would somehow make it possible.","score":1,"comments":[]}]}]},{"body":"If `app` implements a trait `WebApp`, then you can do:\n\n```\nfn webapp() -&gt; impl WebApp {\n    App::new().service(yes)\n}\n```","score":8,"comments":[]},{"body":"&gt; Do you have any workaround to this ? Thanks !\n\nCreate a trait, for manipulating the type, e.g. `MyTrait` and change to \n```\nfn webapp() -&gt; impl MyTrait {\n    App::new().service(yes)\n}\n```\n\nthat's it.","score":1,"comments":[]}]},{"title":"Newbie learning and coding Rust trying to call two methods of reqwest","not_safe_for_work":false,"locked":false,"body":"Hi, I have problems to understand how coding in Rust.\n\nI want to use `reqwest::blocking::get` that returns a `reqwest::blocking::Response` that doesn't implement trait Copy or Clone.\n\nI need to get the status code, the body of the response, the headers, but I can't call to the methods.\n\nIn this example code:\n```\nlet response: reqwest::blocking::Response = reqwest::blocking::get(url.as_str()).unwrap(); // -------- move occurs because `response` has type `reqwest::blocking::Response`, which does not implement the `Copy` trait\nlet body: ImmutableString = response.text().unwrap().into();\n```\n\nI've tried to call other method but I can't\n```\nlet response: reqwest::blocking::Response = (move || reqwest::blocking::get(url.as_str()).unwrap())();\n    |             -------- move occurs because `response` has type `reqwest::blocking::Response`, which does not implement the `Copy` trait\n    |         let body: ImmutableString = response.text().unwrap().into();\n    |                                              ------ `response` moved due to this method call\n    |         let code:u16 = response.status().as_u16();\n    |                        ^^^^^^^^^^^^^^^^^ value borrowed here after move\n```\n\nI can't find how to fix things as simple as accessing two methods. Is that possible in Rust?","score":2,"comments":[{"body":"Move `.status()` line before `.text()` one. If you look at the docs, [`.text()`](https://docs.rs/reqwest/0.11.13/reqwest/blocking/struct.Response.html#method.text) method takes `self` which means it consumes the `Response`, while [`.status()`](https://docs.rs/reqwest/0.11.13/reqwest/blocking/struct.Response.html#method.status) method takes `&amp;self` which means it only temporarily borrows it.","score":7,"comments":[{"body":"Oh my god! thanks, now I can see what the correct order of the calls!! now I understand where the docs refers to self or &amp;self","score":1,"comments":[]}]}]},{"title":"This Week in Rust #469","not_safe_for_work":false,"locked":false,"body":"","score":74,"comments":[{"body":"I really hope that hyper takes the “Hyper Polish period” opportunity to include some Easter eggs. Some Polish flags here and there, occasional Polish language strings in the examples, etc","score":15,"comments":[{"body":"Dobrzy pomysł.","score":7,"comments":[{"body":"Dziekuje :)","score":5,"comments":[]}]}]}]},{"title":"I've made a Game Boy emulator using Rust and WebAssembly 🎮🕹️","not_safe_for_work":false,"locked":false,"body":"","score":493,"comments":[{"body":"Hey, good work and cool UI! That said, while most games will work just fine in your emulator, your PPU logic isn't 100% correct.\n\nI tested it with the classic [dmg-acid2](https://github.com/mattcurrie/dmg-acid2) test rom and another rom called `sprite_priority.gb` which is part of the [Mooneye Test Suite](https://github.com/Gekkio/mooneye-test-suite).\n\nBoth show you that your PPU still needs some work, off the top and going off the error list of the dmg-acid2 test, I see:\n\n- bg/window tile data bit isn't correctly implemented\n- 8x16 sprites are either missing or incorrectly implemented\n- no window internal line counter\n- no sprite priority\n- no 10 object (sprites) per line limit (hence the missing exclamation mark)\n\nYou can see the sprite priority issue for example in Tennis where in your emulator, the tennis ball is always in front of the player whereas it should actually disappear behind the player sprite.","score":60,"comments":[{"body":"Thanks for the tip! Definitely need to save some time to implement the changes required to make the PPU pass those tests.","score":23,"comments":[{"body":"One checked - the easy one of course hehe\n\nhttps://github.com/joamag/boytacean/commit/40a9edbbb1b5dfcdd416969e39ac20968762b74f","score":13,"comments":[]}]},{"body":"Got everything working now. DMG-ACID2 is now passing since version 0.5.5 of Boytacean.\n\nAgain, thank you very much for your support!","score":10,"comments":[]},{"body":"","score":0,"comments":[]}]},{"body":"Working emulator @ [https://boytacean.joao.me](https://boytacean.joao.me)\n\nGitHub repo @ [https://github.com/joamag/boytacean](https://github.com/joamag/boytacean)","score":28,"comments":[]},{"body":"Awesome! I want to build one myself one day for learning. \n\nI really love the UI on the website!","score":19,"comments":[{"body":"Thanks!\n\nI'm thinking about making the UI (built using TS + React.js) a separate library so that it can be used for the creation of other emulators. I'm calling it EmuKit :)","score":13,"comments":[]}]},{"body":"Holy crap this is amazing","score":5,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"I've been wanting to play around with building an emulator, but I've never done that before. How did you go about building this?","score":4,"comments":[{"body":"I'd recommend looking through his Github first.\n\nHe has a pretty good doc here:\n\nhttps://github.com/joamag/boytacean/blob/master/doc/inspiration.md","score":5,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"I created a Solana Tic-Tac-Toe game in Rust. I would love to hear feedback about my code","not_safe_for_work":false,"locked":false,"body":"","score":0,"comments":[{"body":"God i fucking hate crypto","score":1,"comments":[]}]},{"title":"Understanding Rust Compile Errors","not_safe_for_work":false,"locked":false,"body":"","score":17,"comments":[]},{"title":"Blog post about smart pointers","not_safe_for_work":false,"locked":false,"body":"What are smart pointers? How do smart pointers work in C++ and Rust?   \n\nIf you ever asked, find your answer in this blog -&gt; [https://3327.io/smart-pointer-rust-vs-c/](https://3327.io/smart-pointer-rust-vs-c/)","score":0,"comments":[{"body":"Thank you for this!!!","score":0,"comments":[]}]},{"title":"Architecting a web application with Rust: where is the service layer?","not_safe_for_work":false,"locked":false,"body":"I've recently started migrating an old C# web application to Rust in order to learn more about the language and the ecosystem, but I'm having a hard time adjusting to the Rust way of doing things and I believe I could use some feedback and direction from the community.\n\nBeing a Java/C# guy, I'm used to separating my code into layers. For a traditional monolithical web application, I have the I/O layer, composed of the Controller classes, View classes, as well as Form/Input validation. Then I have the Service layer, where I have my Repository classes that talk to the DB, the Service classes that perform actions (such as registering a user and then sending an email).\n\n* How does that fit into an Axum or Actix Rust web application? Or does it not fit at all?\n* How do I isolate the service layer from the controllers? I could not find a dependency injection framework, so I'm injecting my services inside the context. That does make things complicated, since now my context has a bunch of services injected, even though not all routes use: EmailService, NotificationService, UserService (for register(), enable(), disable()), AnalyticsService...","score":6,"comments":[{"body":"With Axum, I find it preferable to use multiple `Extension` layers:\n\n    Router.new()\n        .route(“/”, get(index))\n        .layer(AddExtensionLayer::new(email_service))\n        .layer(AddExtensionLayer::new(user_service))\n\nThen your endpoint functions can pull in just the dependencies they need:\n\n    async fn index(users: Extension&lt;UserService&gt;) -&gt; Html&lt;Thing&gt; {\n        // etc.\n\nI also break up the app into modules which just export a `fn router() -&gt; Router` function, which allows the tests in those modules to only mock out the specific dependencies they require instead of having every test require a mock version of all dependencies.","score":8,"comments":[{"body":"Tip: `Extension` is a layer so you can just do `.layer(Extension(foo))`. No need for `AddExtensionLayer` though it works identically.","score":7,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"How would you handle a service that depends on another service?","score":2,"comments":[{"body":"Pass it as an argument when constructing it; pass it as an argument when using it. Depends.","score":7,"comments":[{"body":"That turns to spaghetti quickly, hence the dependency injection container.","score":2,"comments":[{"body":"I guess we disagree then.","score":4,"comments":[]}]}]}]},{"body":"","score":0,"comments":[]}]},{"body":"I would suggest:\n\n- Mapping C# classes to Rust functions and modules.\n- Mapping C# dependency injection to a simple concrete `use` import. If you need mocking for testing (you probably don't?) then you can use a type alias with a conditional compilation.\n\nSo your service layer is just going to be a module containing plain functions. You may want to have the endpoint handler pass a database connection / database transaction to the functions in your repository module. That way you can let your web framework handle the database pool, and you get the control to perform multiple actions in same transaction.","score":3,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"I've struggled with it too. The MVC doesn't translate to Rust well from classic OOP languages. And definitely no dependency injection as we know it.\n\nPersonally, I still organize logic into layers and while using Actix I just do \"data injection\" instead (by passing object states and handles through \\`web::data\\` construct in controllers) for layer states.\n\nI recommend Zero To Production book ([https://www.zero2prod.com](https://www.zero2prod.com)), because it helped me a lot with translation of these concepts (though from Typescript/nodejs background).","score":1,"comments":[{"body":"Thank you for the book recommendation, from the sample it does look quite complete. I'm curious about how it covers Scalability (in terms of code, not runtime) and modularity.","score":1,"comments":[{"body":"It covers modularity, but doesn't go into scalability too deep.","score":1,"comments":[]}]}]},{"body":"","score":0,"comments":[]}]},{"title":"To neovim users, what kind of rust specific plugins/settings do you guys use?","not_safe_for_work":false,"locked":false,"body":"For example: \nTurning on inlay hints, rustfmt on save, auto close {} brackets, rust-tools plugin etc.","score":2,"comments":[{"body":"Try out lunar vim… It is basically neovim with a lots of defaults.. and Rust seemed to be supported out of the box","score":4,"comments":[{"body":"Lunarvim is neovim but with a bunch of plugins. Imagine a linux distro.","score":1,"comments":[]}]},{"body":"Neovim LSP, nvim lsp-config, treesitter, nvim-cmp, crates (plugin for Cargo.toml), rust-tools and telescope","score":2,"comments":[]},{"body":"coc-nvim + coc-rust-analyzer + rust-analyzer + clippy instead of check = best combo ever!\nI keep rustfmt with default settings that are already good because I want to keep the code readable by other rustaceans.","score":1,"comments":[{"body":"Correct me if im wrong but coc seems the old way of doing things especially since neovim has its own lsp now","score":1,"comments":[{"body":"I didn’t know Neovim has its own lsp and didn’t have a look at it. Anyway it’s working good even if it may be old, and I can manage and update all coc plug-ins very easily.","score":1,"comments":[]},{"body":"Both ways work perfectly fine and have their advantages and disadvantages. Also coc is more than just an lsp-client and has a vast ecosystem of plugins.","score":1,"comments":[{"body":"True....Ive never looked into it because of the nodejs dependency","score":1,"comments":[{"body":"","score":0,"comments":[]}]}]}]}]},{"body":"I just think it’s forward thinking. Something new, like the Warp Terminal. That’s what I like about Rust community, the fact that it is so open to innovation.","score":1,"comments":[]},{"body":"Here is my [full vimrc](https://github.com/drbrain/vimrc) which uses [mason](https://github.com/williamboman/mason.nvim) to [set up lsps](https://github.com/drbrain/vimrc/blob/main/lua/plugins/lsp.lua) and [nvim-cmp](https://github.com/hrsh7th/nvim-cmp) for [completion](https://github.com/drbrain/vimrc/blob/main/lua/plugins/completion.lua) and uses the [rust-tools and crates](https://github.com/drbrain/vimrc/blob/main/lua/plugins/rust.lua) packages.\n\nOne of the lsp plugins enables inlay hints, format-on-save is an [autocmd](https://github.com/drbrain/vimrc/blob/f364468d45fc9e3e789c5197b0eb2db675ee743c/autocmd.vim#L58) using the lsp support. (I’ve never had a pleasant experience with delimiter auto-close when editing code so I can’t help you there.)\n\nI need to make some changes to improve completion after I switched to Packer and organized my plugins into groups.","score":1,"comments":[]},{"body":"","score":0,"comments":[]}]},{"title":"Panel: Rust in reality - EuroRust 2022","not_safe_for_work":false,"locked":false,"body":"","score":10,"comments":[]},{"title":"How do i connect to BigQuery and Snowflake in Rust?","not_safe_for_work":false,"locked":false,"body":"\\[BQ/Snowflake/less popular databases\\] looks like Rust have foundational support for Postgres, MySQL, Mongo but not the less popular databases? How do ya'll do it in Rust (or you guys use Go/TS/Java for database connections)?","score":0,"comments":[{"body":"Checkout [lib.rs](https://lib.rs), I found crates for BigQuery and Snowflake on it.","score":3,"comments":[{"body":"Are you sure about snowflake? Because all I see are crates for Twitter's Snowflake - ID generation, not Snowflake - database.","score":1,"comments":[{"body":"Well you are right, all snowflake I found on lib.rs is for the ID generation, nto the database.","score":1,"comments":[]}]}]},{"body":"I managed to connect to Snowflake through ODBC successfully, although I didn't test it thoroughly.\n\nDriver - [https://docs.snowflake.com/en/user-guide/odbc.html](https://docs.snowflake.com/en/user-guide/odbc.html)\n\nCrate - https://docs.rs/odbc-api/latest/odbc\\_api/","score":1,"comments":[]}]},{"title":"[media] Onefetch v2.13 is typically 2x faster and now supports ~100 programming languages","not_safe_for_work":false,"locked":false,"body":"","score":280,"comments":[{"body":"&gt;[Onefetch](https://github.com/o2sh/onefetch) is a command-line Git information tool written in `Rust` that displays project information and code statistics for a local Git repository directly to your terminal.\n\nRelease notes: [https://github.com/o2sh/onefetch/releases/tag/v2.13.0](https://github.com/o2sh/onefetch/releases/tag/v2.13.0)\n\nedit: fix link","score":43,"comments":[{"body":"Github link is broken, there is a typo in it (fecth instead of fetch)","score":9,"comments":[{"body":"fixed, sorry","score":5,"comments":[]}]}]},{"body":"My boys Ralf, aleksey and brian all put a total of 45,000 lines of code each into this project\n\nChads","score":16,"comments":[]},{"body":"Noob question:\nCan I use it as a zsh extension to run when terminal opens?","score":3,"comments":[{"body":"Here is a little function to put in your `.zshrc` (or `.bashrc`) to run onefetch whenever you `cd` into a repo while making sure that it's different from the last one you were in:\n\n    LAST_REPO=\"\"\n    cd() { \n        builtin cd \"$@\";\n        git rev-parse 2&gt;/dev/null;\n    \n        if [ $? -eq 0 ]; then\n            if [ \"$LAST_REPO\" != $(basename $(git rev-parse --show-toplevel)) ]; then\n            onefetch\n            LAST_REPO=$(basename $(git rev-parse --show-toplevel))\n            fi\n        fi\n    }","score":13,"comments":[{"body":"Thank you so much.\n\nI’m stepping into the unix world right now, and have been putting a lot of effort in customizing my dev experience.","score":4,"comments":[]},{"body":"","score":0,"comments":[]}]},{"body":"Just add it to your .zshrc, but I’d advise against it.","score":6,"comments":[]}]},{"body":"GitHub project link: https://github.com/o2sh/onefetch\n\nNice tool but what I liked the most was the multilingual translations of the README. That has inspired me, and I hope other projects also follow suit.","score":9,"comments":[]},{"body":"This is a neat tool, but I'm a bit confused by how it counts the lines of code. If I go to one of my projects and run it, it says the project has 728 lines of code. `wc -l **/*.c` gives me 828 LOC in C files. I also have a python script in the directory as a part of setting up the environment to run it, so if I run `wc -l **/*.py` I get another 800 LOC from that. Not to mention the 52 LOC in shell scripts. How does onefetch end up counting so few lines?","score":2,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"Easiest Way to Understand Rust Modules Across Multiple Files","not_safe_for_work":false,"locked":false,"body":"","score":5,"comments":[]},{"title":"How does uutils compare to fd and ripgrep?","not_safe_for_work":false,"locked":false,"body":"Do anyone have know if the uutils performance increase will be anything close to that of fd and ripgrep? From the github it sounds like they are trying to match the gnu coreutils preformance, but programs like fd and ripgrep are several times faster than their gnu counterparts. If they opt to not use fd and ripgrep, what are their reasons to do so? I know that ripgrep and fd dont exactly match the gnu coreutils behavior, but it feels like that could be fixed easily.  \n\n\nIt would be great to have something like ripgrep installed on all computers. Right now when you script you have to use the much slower grep since you cannot assume everyone has ripgrep","score":11,"comments":[{"body":"gnu grep and gnu find aren’t part of coreutils, and some people doing a rust implementation of basic unix tools won’t help get ripgrep installed anywhere.  fortunately package management is ubiquitous in the unix world now so you can just install it.\n\nout of interest: how often do you write shell scripts, that you distribute, that use grep, and are significantly faster using ripgrep instead?\n\nEdit: for context, there’s already multiple implementations of grep and find and “coreutils” - even on Linux, Debian had several grep versions packaged and available.  I think someone got the FreeBSD userland to work on Linux once, too?  It’s just that as Linux basically took over the server market, and almost every Linux distribution is based around GNU, coreutils and GNU find and GNU grep became almost ubiquitous and people started to think of them as “the” find and “the” grep","score":8,"comments":[]},{"body":"(My knowledge is almost a year out of date.)\n\nSome utilities are already quite a bit faster than coreutils (off the top of my head that includes `wc`, `cat`, and `yes`). Sometimes all it takes is plugging in the right library or using platform-specific syscalls.\n\nSome utilities are slower than coreutils, and some don't really work that well in the first place. The quality is pretty uneven.\n\nCompatibility is a higher priority than performance.\n\nTo make ripgrep grep-compatible you wouldn't just have to adjust behavior, you'd have to add support for grep's regex syntaxes. And those include backreferences, which the regex crate doesn't support (though ripgrep can use PCRE for those). So I think it's possible but it's not that easy. uutils has no grep implementation but maybe it'll get one in the future.\n\nfd isn't as similar to find as ripgrep is to grep, because find is a bit of a strange and unwieldy tool to begin with. uutils does implement it, in a separate repository: https://github.com/uutils/findutils (I'm not sure there's a good reason to separate it like that, it seems like an artifact of the way GNU happens to organize things.)\n\nGNU grep is fast ([and known for it!](https://lists.freebsd.org/pipermail/freebsd-current/2010-August/019310.html)), even if ripgrep is faster. And I don't think grep is the bottleneck in most shell scripts that use it. If you've already measured it and you know you could use the speedup then you can try using ripgrep only when it's available:\n\n    if which rg &gt; /dev/null; then\n        grep=rg\n    else\n        grep=grep\n    fi\n    \n    $grep ...\n\n(Make sure the commands you write work with both!)\n\nBut first ask yourself: is it worth the trouble? How much faster is it going to run this way? If it saves ten seconds of runtime then maybe it's worth it, but if it only saves 10 milliseconds, don't bother.","score":5,"comments":[]}]},{"title":"GreptimeDB: a new open source database designed for large-scale time-series data storage and processing, written in rust","not_safe_for_work":false,"locked":false,"body":"","score":248,"comments":[{"body":"How is the performance compared to TimescaleDb?","score":16,"comments":[{"body":"GreptimeDB is still in its early stage and under heavy development, we will do the performance benchmark when it's ready.","score":14,"comments":[{"body":"That’s awesome. Timescale uses Rust for their toolkit extension too. Very keen to find out more, looking forward!","score":6,"comments":[]}]}]},{"body":"edit: all good now!\n\n~~FYI quad9, a public dns provider, is (was?) [blocking your domain](https://i.imgur.com/ru5Hsha.png) from being resolved by their dns servers: https://www.quad9.net/result/?url=greptime.com~~\n\n~~I submitted a false positive report, but you might want to too~~","score":13,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"I just had a quick glance through the docs and I couldn't really find anything about full text searching/regex. What's the reason for the \"grep\" part of the name? Are `LIKE` queries especially efficient?\n\nedit: I've realised that OP isn't necessarily involved in this tool, so this question extends to anyone","score":30,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"Any chance that we're one step closer to the rust alternative to prometheus?","score":9,"comments":[{"body":"We plan to implement PromQL natively in GreptimeDB. Once it's done, we should be much closer.","score":11,"comments":[]},{"body":"","score":0,"comments":[]}]},{"body":"Building databases in Rust, so hot right now.\n\nNot a criticism, just noticed how there's a huge trend toward people building DB systems in Rust like crazy.","score":8,"comments":[{"body":"It's a type of software where performance is among the top priorities. Given how little people seem to enjoy working in the high performance alternatives, it is no surprise that Rust is seeing a surge in the space.","score":11,"comments":[{"body":"","score":0,"comments":[]}]}]},{"body":"Cool.\n\nSomething I noticed: why does everyone focus on making cloud/distributed focused DBs? Why doesn't anyone want to make an embedded DB akin to sqlite? I think there is a big opening for embedded time series DBs, and embedded DBs in general.\n\nI am currently writing a desktop app that visualizes time series data from microcontrollers and ECU's and when I was looking for time series DB's that I can embed, the options are scarce. I hope someone one day can address this potential market.","score":7,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"Clippy may ignore #![deny(warnings)] in lib.rs","not_safe_for_work":false,"locked":false,"body":"Hello!\n\nSeeing quite strange behavior of clippy:\n\n    warning: adding items after statements is confusing, since items exist from the start of the scope\n      --&gt; src/chain/mod.rs:73:5\n       |\n    73 |     use sfw::SoftFloat;\n       |     ^^^^^^^^^^^^^^^^^^^\n       |\n    note: the lint level is defined here\n      --&gt; src/lib.rs:1:9\n       |\n    1  | #![deny(warnings)]\n       |         ^^^^^^^^ \n       = note: `#[warn(clippy::items_after_statements)]` implied by `#[warn(warnings)]`\n       = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#items_after_statements\n\nPlease note clippy sees global warning denial for whole crate, yet it still works in `warn(warnings)` mode. Funny enough, this turns into proper error on CI, with \n\n       = note: `#[deny(clippy::items_after_statements)]` implied by `#[deny(warnings)]`\n\nAny ideas why?\n\nThanks","score":2,"comments":[{"body":"You might have `--cap-lints=warn` set locally somewhere. I have it myself to workaround just this sort of situation where crates have committed `deny(warnings)` in their source code, it provides a horrible developer experience when you’re hacking on some code and want to test changes without fixing all warnings.","score":2,"comments":[{"body":"Thanks for idea, though almost definitely no. I'm working in isolated dev env, with only that project repo. And I checked user-wide cargo config.","score":1,"comments":[]},{"body":"For the case when you're already modifying a crate, commenting out deny warnings line seems as convenient","score":1,"comments":[]}]}]},{"title":"Use up N amount of CPU cores at X% usage","not_safe_for_work":false,"locked":false,"body":"Hi!   \nI am currently working on a CLI for load testing a Linux VM. Particularly, I want to load test CPU usage. \n\nFor example, if my VM has 8 cores, I want to run a single CLI on that machine that manages to get N cores to, lets say, X% usage.\n\nI read up on some shell scripts that attempt to do this, but I was wondering if there are \"cleaner\" ways to do it in Rust.","score":8,"comments":[{"body":"Doing throttling like that anything close to properly is a function of the kernel, since it's got final say on CPU scheduling, so what you want to look into is the cleanest way to interact with the Linux kernel cgroups APIs.\n\nThat's what the shell scripts would be doing.","score":16,"comments":[{"body":"Have a look at the [core_affinity](https://lib.rs/crates/core_affinity) crate to pin each thread/process to a specific CPU.","score":6,"comments":[]}]}]},{"title":"Clap 4.0 - How to make the sub-command selection be before arguments?","not_safe_for_work":false,"locked":false,"body":"Hi,I'm making a simple static site generator and I want a mode selection between \\`watch\\` and \\`build\\`, something like \\`cargo run ...\\` or \\`cargo build ...\\`.\n\nHere's the source code:\n\n    #[derive(clap::Subcommand, Clone, Debug)]\n    enum Action {\n    \tBuild,\n    \tWatch,\n    }\n    \n    #[derive(Parser, Debug)]\n    #[command(author, version, about, long_about = None)]\n    struct Args {\n    \t#[command(subcommand)]\n    \taction: Action,\n    \n    \t#[arg(\n    \t\tshort,\n    \t\tlong,\n    \t\trequired = true,\n    \t\thelp = \"Directory (or directories) of markdown files and configuration files\",\n    \t\tdisplay_order(1)\n    \t)]\n    \tmarkdown: Vec&lt;PathBuf&gt;,\n    \n    \t#[arg(short, long, default_value_os_t=PathBuf::from(\".\"), help=\"Output of files\", display_order(2) )]\n    \toutput: PathBuf,\n    \n    \t#[arg(short, long, default_value_os_t=PathBuf::from(\"./template\"), help=\"Location of templates\", display_order(3) )]\n    \ttemplate: PathBuf,\n    \n    \t#[arg(\n    \t\tshort,\n    \t\tlong,\n    \t\tdefault_value_t = false,\n    \t\thelp = \"Overwrite files if they exist\"\n    \t)]\n    \tforce: bool,\n    \n    \t#[arg(short, long, default_value_t = false, help = \"If to export a sitemap\")]\n    \tsitemap: bool,\n    }\n\nWhen I run \\`binary build -m .\\` it errors out.\n\n    error: Found argument '-m' which wasn't expected, or isn't valid in this context\n    \n    Usage: thales --markdown &lt;MARKDOWN&gt; build\n    \n    For more information try '--help'\n\nIt says I need to provide the command AFTER the arguments, but I want it to be the opposite, providing the command BEFORE the arguments.\n\n&amp;#x200B;","score":1,"comments":[{"body":"I don't recall the naming of Clap 4, but currently your argument is global for the whole application. You'd want to use subcommands and add arguments to them.","score":5,"comments":[]},{"body":"Any arguments passed after a sub command are passed to the sub command. In this case it’s saying you need to use the arguments first as they are defined at the root level and not the sub command (ie arguments specifically for the build sub command). \n\nIf an argument belongs to a sub command then it goes after, if not, it does actually go before a sub command so it can be correctly parsed.","score":2,"comments":[]},{"body":"If you'd like arguments at the top level to be able to be provided after the subcommand too, then mark them `#[arg (global=true)]`\\[1\\]. They'll then have to be unambiguous to any subcommand-specific arguments you provide, of course.\n\n\\[1\\] https://docs.rs/clap/latest/clap/builder/struct.Arg.html#method.global","score":1,"comments":[]},{"body":"You need to put the args on the subcommand enum. Check out the git-derive example in the clap cookbook on docs.rs to see what a large-ish app might look like.","score":1,"comments":[]},{"body":"Not exactly an answer to your question but I would strongly recommend using the Clap builder instead of the derive implementation. It makes it a lot easier to be explicit when adding arguments and the code is easier to write. \n\nFor a command line project I was doing I started with derive and had to switch because some things became prohibitively complicated (or impossible) to add. Also it’s not easy to debug issues in the derive macro representation.","score":-1,"comments":[]}]},{"title":"GraphQXL, a new language written in Rust that compiles down to plain GraphQL.","not_safe_for_work":false,"locked":false,"body":"","score":80,"comments":[{"body":"Thanks for sharing.","score":8,"comments":[{"body":"you're welcome!","score":3,"comments":[]}]},{"body":"Nice. Are there any embeddable graph db's in Rust that support GraphQL? I know of Indradb but it doesn't support any query languages.","score":7,"comments":[{"body":"Not that I know of, the idea of GraphQXL is more about defining GraphQL schemas in a more scalable way. As it compiles to common GraphQL, it does not matter much what technology you end up using in your stack (backend programming language or database)","score":7,"comments":[]},{"body":"I don't think there is a strong connection between graph databases and GraphQL. The 'graph' in GraphQL is implicit in the relationship between API endpoints, but the data model that it surfaces is dissimilar to how a graph database looks at the world. \n\nDon't get me wrong, GraphQL is amazing at what it does. It's just the naming is confusing.","score":6,"comments":[]}]},{"body":"Oh this is a really neat idea! Transpilers like this are cool, and I really appreciate the approach of using this to actually augment the target language. If I wrote a lot of GraphQL this is the sort of tool I'd be looking to use.","score":1,"comments":[]}]},{"title":"Looking at Servo, the first web browser engine written in Rust","not_safe_for_work":false,"locked":false,"body":"","score":50,"comments":[{"body":"Biggest problem with Servo right now is that the embed API is unstable.","score":1,"comments":[]},{"body":"Tried to play with this project the other day but it looks like compiling it on MacOS is broken due to a python update which has been unresolved for months.","score":1,"comments":[{"body":"I'm hopeful that https://github.com/servo/mozjs/pull/318 will allow us to finally build with python 3.10.","score":1,"comments":[]}]}]},{"title":"derive-tokio-io: Derive AsyncRead and AsyncWrite.","not_safe_for_work":false,"locked":false,"body":"[Crates.io Page](https://crates.io/crates/derive-tokio-io)\n\nDerive macros for tokio io traits to make your life a little bit easier.  \n\nUnfortunately when attributes are required, it doesn't work with `pin-project-lite` crate because of a bug in it. Works well with `pin-project` crate.","score":5,"comments":[]},{"title":"Experienced rustaceans, teach me it","not_safe_for_work":false,"locked":false,"body":"It's difficult for me understand the \"type transitions\" in collections. You know: iter(), collect(), etc. had given me many errors. I 'm going to change them until: \"oh, yes, it works!\". A part of solution was into_inter(). Do you explain me?","score":0,"comments":[{"body":"I think we need a general example here to help explain exactly what you need. But in general, you tend to have three options to start iterating:\n\n- x.iter(), which iterates references to values, e.g. &amp;T (in 2021 edition it just copies small things like numbers instead, no references)\n- x.into_iter() will actually consume (move) x, so x won’t work any longer after calling this.\n- x.iter_mut() gives you mutable references to the things in x\n\nThen .collect() is just a way to turn an iterator into a collection like Vec, HashSet, or your own thing (more specifically, anything that implements FromIter). It’s a generic function that figures out the correct return type based on type annotations, or turbofish syntax.\n\nThen the other things you see like .map(), .filter(), .fold() etc are “iterator adapters” or “combinators” and basically turn one iterator into another. These can help make code a lot cleaner than some messy `if` statements","score":10,"comments":[{"body":"Thank you","score":2,"comments":[]},{"body":"Yeah, it was (iter() gives immutable and I didn't know)","score":1,"comments":[]}]},{"body":"Here is a blogpost about iter and into_iter\n\nhttps://www.geekabyte.io/2022/08/rust-iterator-pattern-with-iter.html","score":3,"comments":[{"body":"Thanks!","score":2,"comments":[]}]}]},{"title":"GATs in dynamic traits - CGlue 0.2.12 Release","not_safe_for_work":false,"locked":false,"body":"Hello there,\n\nThis is a pretty small, but monumental release of CGlue - limited GAT support! For those unacquainted, CGlue is a C ABI compatible code generator based around Rust traits - a set of procedural macros you can apply to make your trait functions wrapped in `#[repr(C)]` enabling creation of plugin systems.\n\nGATs support is fairly limited and currently I've tested single generic lifetime within a trait. This allows defining borrow types without ugly higher-ranked trait bounds.\n\nI have to stress that there is no way to enable type parameters within associated types, because every type instantiation would require a vtable and, well, we don't have infinite space for infinite possibilities of types supplied. However, I still think lifetimes within dynamic traits is one of the key features that enables significant flexibility in API design.\n\nYou can grab CGlue from [my GitHub](https://github.com/h33p/cglue).","score":16,"comments":[]},{"title":"Unresolved import within storage","not_safe_for_work":false,"locked":false,"body":"Hi there, i am new to Rust and trying to create a page with redis session.  \nBut already running into problems loading redis-session.   \n\n\nHave read several articles but have not yet found a clear solution what they mean by this.   \n\n\nThis is my Toml file:\n\n`[package]`  \n`name = \"rustnew\"`  \n`version = \"0.1.0\"`  \n`edition = \"2021\"`  \n`# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html`  \n`[dependencies]`  \n`actix-web = \"4\"`  \n`actix-session = { version = \"0.7.2\", features = [\"redis-actor-session\"] }`  \n`serde = { version = \"1.0\", features = [\"derive\"] }`  \n`serde_json = \"1.0\"`  \n`qrcodegen = \"1.8.0\"`  \n \n\nBut when I wanna import the libraries with the following code:\n\n`use actix_web::{get, post, put, delete, web, App, HttpRequest, HttpResponse, HttpServer, Responder, ResponseError};`  \n`use actix_session::{`  \n `config::PersistentSession, storage::RedisSessionStore, Session, SessionMiddleware,`  \n`};`  \n`use actix_web::http::header::ContentType;`  \n`use actix_web::http::StatusCode;`  \n`use actix_web::body::BoxBody;`  \n`use actix_web::cookie::Key;`\n\n&amp;#x200B;\n\nI get the following error:\n\n `|     config::PersistentSession, storage::RedisSessionStore, Session, SessionMiddleware,`\n\n  `|                                ^^^^^^^^^-----------------`\n\n  `|                                |        |`\n\n  `|                                |        help: a similar name exists in the module: \\`SessionStore\\``\n\n  `|                                no \\`RedisSessionStore\\` in \\`storage\\``\n\n  \nSo if I understand this correct, there is already a similair name but at the same time there is no RedisSessionStore?","score":0,"comments":[{"body":"you need to also add `redis-rs-session` feature","score":4,"comments":[]}]},{"title":"Zig planning bootstrap chain via WASM","not_safe_for_work":false,"locked":false,"body":"","score":81,"comments":[{"body":"Rather than maintaining a C++ compiler for bootstrapping, the zig project is looking at compiling their self-hosted zig compiler to WASM, and using a small wasm interpreter written in C to bootstrap.\n\nThought this might be an interesting option for Rust too, although I know Rust doesn't currently run in wasm.","score":50,"comments":[{"body":"It could be an interesting idea to distribute the bootstrap compiler in WASM, as this would allow easier bootstrapping on uncommon systems.\n\nHowever the great difference between Zig and Rust is that the Zig compiler can or is planned to self compile itself into C code, which doesn't exist for Rust.","score":22,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"I'm unclear what the objective is. Is it to bootstrap the compiler on new platforms? If so, why not cross-compile to produce the initial compiler?","score":18,"comments":[{"body":"I think it's similar to C compiler bootstrapping, the idea that you can start with just a C compiler and some sources and build your way up from there.\n\nI don't necessarily the usefulness of it, but some people do appreciate it.","score":9,"comments":[]},{"body":"A use case mentioned on the zig issue tracker was linux distributions wanting to bootstrap Rust from source. It could replace the need for mrustc.","score":7,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"body":"Interesting, but I don't think this solves the problem for rustc.\n\nAs I understand that PR, Zig still need a binary blob of the compiler, just not as a native ELF/EXE file, but as WASM. I assume the Zig people plan to rarely upgrade that blob, just like GCC rarely upgrades its bootstrap requirements. So it works for them.\n\nThis would mean that Zig can't use the latest and greatest language features in the compiler itself (I don't know if that also applies to the standard library). I assume that tradeoff is worth it for them. Also, Zig releases every six months instead of every six weeks like Rust, so the bootstrap chain would be way shorter anyway.\n\nThe problem is that rustc does almost the opposite: The latest nightly sources need the latest beta compiler to build; even the latest stable won't suffice. Combined with the faster release schedule, this would mean a new WASM binary blob every 6 weeks.\n\nIn conclusion, I think the WASM approach may make porting to a new architecture slightly easier, but that's about it. It doesn't solve the \"Trusting Trust\" issues that \"bootstrapping from source\" people usually care about.","score":11,"comments":[{"body":"&gt; The latest nightly sources need the latest beta compiler to build;\n\nIs it true tho? I remember stage0 blob was super rarely updated when I kept rust nightly in freebsd ports up to date.\n\n\nI would love stage0 to be wasm though, at least it solves the issue of building it for different platforms and make keeping it in-sync easier.","score":5,"comments":[]}]},{"body":"Are there systems which support wasm but are not trivial to compile or distribute to?","score":10,"comments":[{"body":"It seems they're planning on maintaining their own C WASI implementation so they should be able to compile for pretty much every system.","score":10,"comments":[]}]},{"body":"Basically they are rediscovering why Niklaus Wirth created P-Code for porting Pascal compilers.\n\nhttps://en.wikipedia.org/wiki/P-code_machine","score":18,"comments":[{"body":"","score":0,"comments":[]}]},{"body":"","score":0,"comments":[]}]},{"title":"Help needed with async implementation of simple token system","not_safe_for_work":false,"locked":false,"body":"He guys,\n\nI have been using rust for a good amount of time, rust's async is newer to me. As a first project I am trying to make a async Token system which nicely limits the number of unacked messages. \nSo when a token is spent, a message is send. In the case that a message is acked, a token comes available. I would like to do this with futures but I am having a really hard time writing my own implementation of this concept.\n\nMy current code is pretty simple:\nhttps://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=1c36570454bdc9b2bfbae628136f0524\n\nThe TokenGenerator is basically what controls the current state and where you can get a new token and indicate that a new token becomes available (which is sometimes directly spent on an awaiting token).\n\n    pub struct TokenGenerator{\n        max_inflight: u16,\n        inflight: Arc&lt;AtomicU16&gt;,\n        waker: Arc&lt;Mutex&lt;Option&lt;Waker&gt;&gt;&gt;,\n    }\n    \n    impl TokenGenerator{\n        pub fn new(max_inflight: u16) -&gt; Self{\n            Self{ \n                max_inflight, \n                inflight: Arc::new(AtomicU16::new(0)), \n                waker: Arc::new(Mutex::new(None)) \n            }\n        }\n    \n        pub fn get_token&lt;'a&gt;(&amp;'a self) -&gt; Token{\n            token(self.max_inflight, self.inflight.clone(), self.waker.clone())\n        }\n    \n        pub fn release_token(&amp;self){\n            self.inflight.fetch_sub(1, Ordering::AcqRel);\n            let guard = self.waker.lock().unwrap();\n            if let Some(waker) = guard.as_ref(){\n                waker.wake_by_ref();\n            }\n        }\n    }\n\n\nBelow is the token and future implementation.\n\n    pub struct Token{\n        max_inflight: u16,\n        inflight: Arc&lt;AtomicU16&gt;,\n        waker: Arc&lt;Mutex&lt;Option&lt;Waker&gt;&gt;&gt;,\n    }\n    \n    pub(crate) fn token(max_inflight: u16, inflight: Arc&lt;AtomicU16&gt;, waker: Arc&lt;Mutex&lt;Option&lt;Waker&gt;&gt;&gt;,) -&gt; Token{\n        Token{\n            max_inflight,\n            inflight,\n            waker,\n        }\n    }\n    \n    impl Future for Token{\n        type Output = u16;\n    \n        fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Self::Output&gt; {\n            if self.inflight.load(Ordering::Acquire) &lt; self.max_inflight{\n                Poll::Ready(self.inflight.fetch_add(1, Ordering::AcqRel))\n            }\n            else{\n                let mut waker = self.waker.lock().unwrap();\n                *waker = Some(cx.waker().clone());\n                Poll::Pending\n            }\n        }\n    }\n\n\nThe problem with this is that you can only have one token await because the waker is an Option&lt;Waker&gt; which only holds one waker. If two tokens are waiting the first waiting Token's Waker is lost(forever?).\n\nMaybe I am complicating things, but I don't see/know another way to implement this. Can someone help me figure this out?\nThank you.","score":1,"comments":[{"body":"You can use [`tokio::sync::Notify`](https://docs.rs/tokio/latest/tokio/sync/struct.Notify.html) instead of `Option&lt;Waker&gt;`, which supports arbitary amount of wakers without heap allocation.\n\nInternally it maintains an intrusive list where each [`Notified`](https://docs.rs/tokio/latest/tokio/sync/futures/struct.Notified.html) is a node.\n\nSince `Notified` must be pinned (it does not implement `Unpin`) and `Notified` only add itself to the linked list after the first poll or call to `Notified::Enabled`, the implementation is sound.","score":3,"comments":[{"body":"Thank you, I didn't know that existed. I googled the wrong things :p","score":2,"comments":[]}]}]}]}